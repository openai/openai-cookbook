


Research Manager, Superalignment







CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit Research Manager, SuperalignmentSan Francisco, California, United States â AlignmentApply nowAbout the TeamOpenAIâs Superalignment Team is working on technical approaches to ensure that superintelligenceâan AI system vastly smarter than humansâfollows human intent.Â Through scientific experimentation, we explore the scalability of alignment techniques and identify potential breaking points. Our approach to alignment research includes a range of different projects; some of these will help us improve the alignment of our models and others will allow us to validate how aligned our models actually are:Scalable oversight: How can we best leverage AI systems to assist evaluation of other AI systems on difficult tasks?Generalization: Can we understand and control how our models generalize from easy tasks that humans can supervise to hard tasks that humans cannot?Automated interpretability: Can we use AI to explain how LLMs work internally?Robustness: How can we train our models to be aligned in worst-case situations?Adversarial testing: If we deliberately train deceptively aligned models as testbeds,Â  can our oversight techniques, interpretability tools, and evaluations detect this misalignment?We want to figure out how to spend vast amounts of compute to solve this problem, in particular by automating alignment research itself. About the RoleWe are seeking a seasoned research leader to spearhead a research team in our newly formed Superalignment efforts. In this position, you will oversee and grow a team of Research Scientists and Research Engineers dedicated to designing and implementing experiments for aligning superintelligence.Â One of our research areas is studying generalization, especially in the setting of weak supervision. Through scientific experimentation, we aim to understand when models can be trustworthy on hard tasks for which humans cannot easily understand outputs.Â Â In this role, you will:Work closely with individual contributors and tech leads to build, communicate, and execute a research strategyBe responsible for the overall planning, execution, and success of technical projects; help develop a team roadmap and lead OKR planningGive mentorship to researchers and engineers, helping them perform at their peak and advance their careersCreate a diverse and inclusive culture that encourages open dialogue and challenges groupthinkYou might thrive in this role if you:Have leadership experience in a research setting, ideally 2+ years. We look forward to considering researchers who have prepared to transition into a management role as well.Are excited about OpenAIâs mission of building safe, universally beneficial AGI and are aligned with OpenAIâs charter.Have relevant research experience in alignment, generalization, scalable oversight, robustness, anomaly detection, or interpretability.Possess a strong curiosity about aligning and understanding ML models, and are motivated to use your career to address this challenge.Thrive in ambiguous and rapidly changing environments, viewing changes as opportunities to implement structure and order when needed.Have an intrinsic desire to learn and fill in missing skills, coupled with an aptitude for sharing knowledge succinctly with others.Are deeply thoughtful about culture, DEI, and team structure, with a track record of improving these areas.About OpenAIOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.Â At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.Compensation, Benefits and PerksThe annual salary range for this role is $420,000 â $500,000. Total compensation also includes generous equity and benefits:Â Medical, dental, and vision insurance for you and your familyMental health and wellness support401(k) plan with 4% matchingUnlimited time off and 18+ company holidays per yearPaid parental leave (20 weeks) and family-planning supportAnnual learning & development stipend ($1,500 per year)We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.Â We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via thisÂ link.OpenAI US Applicant Privacy PolicyApply nowResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
