


Solving (some) formal math olympiad problems











CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewCustomer storiesSafety standardsPricingSafetyCompanyAboutCareersBlogCharterSearchMenu Mobile Navigation CloseSite NavigationResearchProductSafetyCompanySearch Submit Solving (some) formal math olympiad problemsWe built a neural theorem prover forÂ LeanÂ that learned to solve a variety of challenging high-school olympiad problems, including problems from theÂ AMC12Â andÂ AIMEÂ competitions, as well as two problems adapted from theÂ IMO.February 2, 2022More resourcesRead paperLanguage,Â Reasoning,Â Transformers,Â PublicationWe built a neural theorem prover forÂ LeanÂ that learned to solve a variety of challenging high-school olympiad problems, including problems from theÂ AMC12Â andÂ AIMEÂ competitions, as well as two problems adapted from theÂ IMO.[^footnote-1] The prover uses a language model to find proofs of formal statements. Each time we find a new proof, we use it as new training data, which improves the neural network and enables it to iteratively find solutions to harder and harderÂ statements.We achieved a new state-of-the-art (41.2% vs 29.3%) on theÂ miniF2FÂ benchmark, a challenging collection of high-school olympiad problems. Our approach, which we callÂ statement curriculum learning, consists of manually collecting a set of statements of varying difficulty levels (without proof) where the hardest statements are similar to the benchmark we target. Initially our neural prover is weak and can only prove a few of them. We iteratively search for new proofs and re-train our neural network on the newly discovered proofs, and after 8 iterations, our prover ends up being vastly superior when tested onÂ miniF2F.Formal mathematics is an exciting domain to study because of (i) its richness, letting you prove arbitrary theorems which require reasoning, creativity and insight and (ii) its similarity to gamesâwhere AI has been spectacularly successfulâin that it has an automated way of determining whether a proof is successful (i.e., verified by the formal system). As demonstrated in the trivial example below, proving a formal statement requires generating a sequence of proof steps, each proof step consisting in a call to a tactic.[^footnote-2]These tactics take mathematical terms as arguments and each tactic call will transform the current statement to prove, into statements that are easier to prove, until nothing is left toÂ prove. Problem 1Adapted from AMC12 2000 Problem 5Prove that if â£xâ2â£=p|x - 2| = pâ£xâ2â£=p, where x<2x < 2x<2, then xâp=2â2px - p = 2 - 2pxâp=2â2p.FormalInformaltheorem amc12_2000_p5      -- â theorem name  (x p : â)                -- â the statement we want  (hâ : x < 2)             --   to prove  (hâ : abs (x - 2) = p) :  x - p = 2 - 2 * p :=begin                      -- â formal proof starts here  -- This first tactic requires that the prover invent  -- the term: `abs (x - 2) = -(x - 2)`.  have hâ : abs (x - 2) = -(x - 2), {    apply abs_of_neg,    linarith,  },  rw hâ at hâ,  -- At this stage the remaining goal to prove is:  -- `x - p = 2 - 2 * p` knowing that `p = -(x - 2)`.  linarith,endWe observe that the capability to generate original mathematical terms required as arguments of tactics, which cannot be done without a neural language model, emerges from our training procedure. The proof below is an example of it: the proof stepÂ use n + 1Â (entirely generated by our models) proposes to useÂ n + 1Â as a solution, the rest of the formal proof relying on theÂ ring_expÂ tactic to verify that it is indeedÂ valid. Problem 2Adapted from AMC12B 2020 Problem 6For all integers nâ¥9n â¥ 9nâ¥9, prove that ((n+2)!â(n+1)!)/n!((n + 2)! â(n + 1)!) / n!((n+2)!â(n+1)!)/n! is a perfect square.FormalInformal
theorem amc12b_2020_p6
  (n : â)
  (h0 : 9 â¤ n) :
  â x : â, (x:â)^2 = 
    (nat.factorial (n + 2) - nat.factorial (n + 1))
    / nat.factorial n :=
begin
  -- The model directly proposes `n + 1` as solution.
  use n + 1,
  field_simp [nat.factorial_ne_zero, pow_succ'],
  ring_exp
end

We also observe that our models and search procedure are capable of producing proofs that chain multiple non-trivial reasoning steps. In the proof below, the model starts by using contraposition leading to the existential statement (â (x : â), f x â  a * x + b). It then generates a witness for it withÂ use (0 : â)Â and finishes the proof by leveraging theÂ norm_numÂ tactic. Problem 3Adapted from the MATH datasetLet f(x)=Ax+Bf(x) = Ax + Bf(x)=Ax+B and g(x)=Bx+Ag(x) = Bx + Ag(x)=Bx+A, where A<br/>eBA <br />e BA<br/>eB. If f(g(x))âg(f(x))=BâAf(g(x)) - g(f(x)) = B - Af(g(x))âg(f(x))=BâA, prove that A+B=0A + B = 0A+B=0.FormalInformal
theorem mathd_train_algebra_217
  (a b : â)
  (f g : â â â)
  (hâ : â x, f x = a * x + b)
  (hâ : â x, f x = b * x + a)
  (hâ : a â  b)
  (hâ : â x, f (g x) - g (f x) = b - a) :
  a + b = 0 :=
begin
  revert hâ hâ hâ hâ,
  -- Initial contraposition.
  contrapose!,
  rintro â¨hâ, â¨hâ, hââ©â©,
  -- The model proposes `0` as witness for the current
  -- goal that consists in `â (x : â), f x â  a * x + b`.
  use (0 : â),
  simp only [sub_eq_iff_eq_add, hâ, mul_zero, zero_add],
  norm_num at hâ,
end

Our models, trained withÂ statement curriculum learning, were able to close a variety of problems from training textbooks as well asÂ AMC12Â andÂ AIMEÂ competitions, and 2 problems adapted from theÂ IMO. We present below three examples of such generatedÂ proofs. Problem 4Adapted from IMO 1964 Problem 2Suppose aaa, bbb, ccc are the sides of a triangle.Prove that a2(b+câa)+b2(c+aâb)+c2(a+bâc)â¤3abca^2(b + c â a) + b^2(c + a â b) + c^2(a + b â c) \leq 3abca2(b+câa)+b2(c+aâb)+c2(a+bâc)â¤3abc.FormalInformal
theorem imo_1964_p2
  (a b c : â)
  (hâ : 0 < a â§ 0 < b â§ 0 < c)
  (hâ : c < a + b)
  (hâ : b < a + c)
  (hâ : a < b + c) :
  a^2 * (b + c - a) + b^2 * (c + a - b) + c^2 * (a + b - c) 
    â¤ 3 * a * b * c :=
begin
  -- Arguments to `nlinarith` are fully invented by our model.
  nlinarith [sq_nonneg (b - a),
             sq_nonneg (c - b),
             sq_nonneg (c - a)]
end

 Problem 5Adapted from AIME 1984 Problem 1Prove that a2+a4+a6+a8+...+a98=93a2 + a4 + a6 + a8 + ...+ a98 = 93a2+a4+a6+a8+...+a98=93 if a1a1a1, a2a2a2, a3...a3...a3... is an arithmetic progression with common difference 111, and a1+a2+a3+...+a98=137a1 + a2 + a3 + ... + a98 = 137a1+a2+a3+...+a98=137.FormalInformal
theorem aime_1984_p1
  (u : â â â)
  (hâ : â n, u (n + 1) = u n + 1)
  (hâ : â k in finset.range 98, u k.succ = 137) :
  â k in finset.range 49, u (2 * k.succ) = 93 :=
begin
  rw finset.sum_eq_multiset_sum,
  dsimp [finset.range] at hâ,
  simp [hâ],
  ring,
  norm_num at hâ,
  norm_num,
  apply eq_of_sub_eq_zero,
  { simp only [*, abs_of_pos, add_zero] at *, linarith },
end

 Problem 6Adapted from IMO Longlist 1990 Problem 77For a,b,ca, b, ca,b,c reals, prove that (a2+ab+b2)(b2+bc+c2)(c2+ca+a2)â¥(ab+bc+ca)3(a^2 + ab + b^2)(b^2 + bc + c^2)(c^2 + ca + a^2) \geq (ab + bc + ca)^3(a2+ab+b2)(b2+bc+c2)(c2+ca+a2)â¥(ab+bc+ca)3.FormalInformal
theorem imo_longlist_1990_p77
  (a b c : â) :
  (a * b + b * c + c * a)^3 â¤
    (a^2 + a * b + b^2) * (b^2 + b * c + c^2) *
    (c^2 + c * a + a^2) :=
begin
  -- The three initial steps use CauchyâSchwarz to prove
  -- `(a * b + b * c) ^ 2 â¤ (a ^ 2 + b ^ 2) * (b ^ 2 + c ^ 2)`
  -- which is required for the final call to `nlinarith`.
  let u : euclidean_space â (fin 2) := ![a, b],
  let v : euclidean_space â (fin 2) := ![b, c],
  have hâ := real_inner_mul_inner_self_le u v,
  simp [u, v, fin.sum_univ_succ, 
        âpow_two, âpow_two, le_of_lt, mul_assoc] at hâ,
  -- The model introduces another required cut (i.e. invent
  -- the term `0 â¤ (c + a) * (c + a)` and proves it).
  have hâ : 0 â¤ (c + a) * (c + a),
  { nlinarith, },
  have hâ := sq_nonneg (a * b + b * c + c * a),
  simp [sq, hâ, hâ, mul_add, add_mul] at hâ â¢,
  nlinarith [sq_nonneg (b - a),
             sq_nonneg (c - b),
             sq_nonneg (a - c)]
end

Formal mathematics involves two main challenges that make a naive application of reinforcement learning unlikely toÂ succeed.(i)Â Infinite action space: not only does formal mathematics have an extremely large search space (like Go for example), it also has an infinite action space. At each step of a proof search, the model must choose not from a well-behaved finite set of actions, but a complex and infinite set of tactics, involving exogenous mathematical terms that have to be generated (e.g., generating a mathematical statement to be used as a witness, an object used in steps such as âthere exists anÂ xÂ s.t. â¦â, or a cut, the introduction and the chaining of a lemma in the middle of aÂ proof).(ii)Â Lack of self-play: conversely to 2-player games, a prover is not playing against an opponent but against a set of statements to prove. When faced with a statement that is just too hard, there is no obvious reframing that will let the prover generate intermediary easier statements to tackle first. This asymmetry prevents naive application of the self-play algorithms that were successful with 2-playerÂ games.In our work, we address the infinite action space problem by sampling actions from a language model as we search for a proof. Language models have the capability to generate the tactic calls as well as the original mathematical terms often required as arguments. Our basis for addressing the lack of self-play is the observation that the key role of self-play in 2-player games is to provide an unsupervised curriculum. Our methodology proposes to replace this unsupervised curriculum with an auxiliary set of problem statements (without requiring proofs) of varying difficulty. We empirically show that, when the difficulty of these auxiliary problems is varied enough, our training procedure is able to solve a curriculum of increasingly difficult problems, eventually generalizing to the set of problems we careÂ about.While these results are extremely exciting, as they demonstrate that deep learning models are capable of non-trivial mathematical reasoning when interacting with a formal system, we are still very far from best-student performance on these competitions, only occasionally, rather than consistently, closing challenging olympiad problems. We hope nonetheless that our work will motivate research in this domain, in particular towards theÂ IMO Grand ChallengeÂ and that theÂ statement curriculum learningÂ methodology we propose will help accelerate progress in automated reasoning inÂ general.AuthorsStanislas PoluJesse Michael HanIlya SutskeverAcknowledgmentsThanks to our paper co-authors: Igor Babuschkin, Kunhao Zheng and Mantas Baksys.Thanks to the students of the Xena Project Discord who helped us formalize proofs and statements (in particular: Antoine Labelle, Hanting Zhang, Shing Tak Lam, Paul Lezeau, Sara Diaz, Nikita Golikov, Yael Dillies, Artem Vasilyev, Ollie Perree, and Yourong Zang).Thanks in particular to Kevin Buzzard and Daniel Selsam for their support and thoughtful feedback since the very beginning of this project.ResearchOverviewIndexProductOverviewCustomer storiesSafety standardsPricingSafetyOverviewCompanyAboutCareersBlogCharterOpenAI Â© 2015âââ2023Terms & policiesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
