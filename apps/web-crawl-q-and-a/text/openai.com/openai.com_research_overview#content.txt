


Research












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit Pioneering research on the path to AGIWe believe our research will eventually lead to artificial general intelligence, a system that can solve human-level problems. Building safe and beneficial AGI is our mission.Quick linksView research indexLearn about safetyFocus areasWe build our generative models using a technology called deep learning, which leverages large amounts of data to train an AI system to perform a task.TextOur text models are advanced language processing tools that can generate, classify, and summarize text with high levels of coherence and accuracy.Aligning language models to follow instructionsWeâve trained language models that are much better at following user intentions than GPT-3.Summarizing books with human feedbackWe've trained a model to summarize entire books with human feedback.Language models are few-shot learnersWe trained GPT-3, an autoregressive language model with 175 billion parameters.ImageOur research on generative modeling for images has led to representation models like CLIP, which makes a map between text and images that an AI can read, and DALL-E, a tool for creating vivid images from text descriptions.Hierarchical text-conditional image generation with CLIP latentsWe show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity.DALLÂ·E: Creating images from textWeâve trained a neural network called DALLÂ·E that creates images from text captions for a wide range of concepts expressible in natural language.CLIP: Connecting text and imagesWeâre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision.AudioOur research on applying AI to audio processing and audio generation has led to developments in automatic speech recognition and original musical compositions.Introducing WhisperWeâve trained and are open-sourcing a neural net that approaches human level robustness and accuracy on English speech recognition.JukeboxWeâre introducing Jukebox, a neural net that generates music as raw audio in a variety of genres and artist styles.MuseNetWeâve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments.Past highlightsOur current AI research builds upon a wealth of previous projects and advances.View all researchImage GPTJun 17, 2020June 17, 2020Solving Rubikâs Cube with a robot handOct 15, 2019October 15, 2019Emergent tool use from multi-agent interactionSep 17, 2019September 17, 2019Featured rolesWe are constantly seeking talented individuals to join our team. Explore featured roles or view all open roles.View all careersSenior Corporate CounselSan Francisco, California, United States â LegalApply nowSolutions Architect, LondonLondon â Go To MarketApply nowAccount ExecutiveSan Francisco, California, United States â Go To MarketApply nowSoftware Engineer, Anti Fraud & AbuseSan Francisco, California, United States â Applied AI EngineeringApply nowSenior IP CounselSan Francisco, California, United States â LegalApply nowResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
