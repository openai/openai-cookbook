


Security












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit Security & privacyOpenAI is committed to building trust in our organization and platform by protecting our customer data, models, and products.Quick linksVisit our trust portalCompliance & accreditationsVisit our trust portalComplianceOpenAI complies with GDPR and CCPA. We can execute a Data Processing Agreement if your organization or use case requires it.The OpenAI API has been evaluated by a third-party security auditor and is SOC 2 Type 2 compliant.External auditingThe OpenAI API undergoes annual third-party penetration testing, which identifies security weaknesses before they can be exploited by malicious actors.Customer requirementsOpenAI has experience helping our customers meet their regulatory, industry and contractual requirements (e.g., HIPAA). Contact us to learn more.Reporting security issuesOpenAI invites security researchers, ethical hackers, and technology enthusiasts to report security issues via our Bug Bounty Program. The program offers safe harbor for good faith security testing and cash rewards for vulnerabilities based on their severity and impact.null linksParticipate in our Bug Bounty ProgramRead about the programWe are committed to protecting peopleâs privacy.Our goal is to build helpful AI modelsWe want our AI models to learn about the worldânot private individuals. We use training information to help our AI models, like ChatGPT, learn about language and how to understand and respond to it.We do not actively seek out personal information to train our models, and we do not use public information on the internet to build profiles about people, advertise to or target them, or to sell user data.Our models generate new words each time they are asked a question. They donât store information in a database for recalling later or âcopy and pasteâ training information when responding to questions.We work to:Reduce the amount personal information in our training datasetsTrain models to reject requests for personal information of private individualsMinimize the possibility that our models might generate responses that include the personal information of private individualsRead more about how our models are developedWays to manage dataOne of the most useful features of AI models is that they can improve over time. We continuously improve our models through research breakthroughs and exposure to real-world problems and data.We understand users may not want their data used to improve our models and provide ways for them to manage their data:In ChatGPT, users can turn off chat history, allowing them to choose which conversations can be used to train our modelsWe do not train on API customer data by defaultAn opt-out formMore informationFor more information on how we use and protect personal information, please read our help article on data usage and Privacy policy.Featured rolesWe are constantly seeking talented individuals to join our team. Explore featured roles or view all open roles.View all careersSoftware Engineer, PrivacySan Francisco, California, United States â SecurityApply nowResearch Engineer, PrivacySan Francisco, California, United States â SecurityApply nowResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
