{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to handle rate limits\n",
    "\n",
    "When you call the OpenAI API repeatedly, you may encounter error messages that say `429: 'Too Many Requests'` or `RateLimitError`. These error messages come from exceeding the API's rate limits.\n",
    "\n",
    "This guide shares tips for avoiding and handling rate limit errors.\n",
    "\n",
    "To see an example script for throttling parallel requests to avoid rate limit errors, see [api_request_parallel_processor.py](https://github.com/openai/openai-cookbook/blob/main/examples/api_request_parallel_processor.py).\n",
    "\n",
    "## Why rate limits exist\n",
    "\n",
    "Rate limits are a common practice for APIs, and they're put in place for a few different reasons.\n",
    "\n",
    "- First, they help protect against abuse or misuse of the API. For example, a malicious actor could flood the API with requests in an attempt to overload it or cause disruptions in service. By setting rate limits, OpenAI can prevent this kind of activity.\n",
    "- Second, rate limits help ensure that everyone has fair access to the API. If one person or organization makes an excessive number of requests, it could bog down the API for everyone else. By throttling the number of requests that a single user can make, OpenAI ensures that everyone has an opportunity to use the API without experiencing slowdowns.\n",
    "- Lastly, rate limits can help OpenAI manage the aggregate load on its infrastructure. If requests to the API increase dramatically, it could tax the servers and cause performance issues. By setting rate limits, OpenAI can help maintain a smooth and consistent experience for all users.\n",
    "\n",
    "Although hitting rate limits can be frustrating, rate limits exist to protect the reliable operation of the API for its users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default rate limits\n",
    "\n",
    "Your rate limit and spending limit (quota) are automatically adjusted based on a number of factors. As your usage of the OpenAI API goes up and you successfully pay the bill, we automatically increase your usage tier. You can find specific information regarding rate limits using the resources below.\n",
    "\n",
    "### Other rate limit resources\n",
    "\n",
    "Read more about OpenAI's rate limits in these other resources:\n",
    "\n",
    "- [Guide: Rate limits](https://platform.openai.com/docs/guides/rate-limits?context=tier-free)\n",
    "- [Help Center: Is API usage subject to any rate limits?](https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits)\n",
    "- [Help Center: How can I solve 429: 'Too Many Requests' errors?](https://help.openai.com/en/articles/5955604-how-can-i-solve-429-too-many-requests-errors)\n",
    "\n",
    "### Requesting a rate limit increase\n",
    "\n",
    "To learn more about increasing your organization's usage tier and rate limit, visit your [Limits settings page](https://platform.openai.com/account/limits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example rate limit error\n",
    "\n",
    "A rate limit error will occur when API requests are sent too quickly. If using the OpenAI Python library, they will look something like:\n",
    "\n",
    "```\n",
    "RateLimitError: Rate limit reached for default-codex in organization org-{id} on requests per min. Limit: 20.000000 / min. Current: 24.000000 / min. Contact support@openai.com if you continue to have issues or if you’d like to request an increase.\n",
    "```\n",
    "\n",
    "Below is example code for triggering a rate limit error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request a bunch of completions in a loop\n",
    "for _ in range(100):\n",
    "    client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        max_tokens=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to mitigate rate limit errors\n",
    "\n",
    "### Retrying with exponential backoff\n",
    "\n",
    "One easy way to mitigate rate limit errors is to automatically retry requests with a random exponential backoff. Retrying with exponential backoff means performing a short sleep when a rate limit error is hit, then retrying the unsuccessful request. If the request is still unsuccessful, the sleep length is increased and the process is repeated. This continues until the request is successful or until a maximum number of retries is reached.\n",
    "\n",
    "This approach has many benefits:\n",
    "\n",
    "- Automatic retries means you can recover from rate limit errors without crashes or missing data\n",
    "- Exponential backoff means that your first retries can be tried quickly, while still benefiting from longer delays if your first few retries fail\n",
    "- Adding random jitter to the delay helps retries from all hitting at the same time\n",
    "\n",
    "Note that unsuccessful requests contribute to your per-minute limit, so continuously resending a request won’t work.\n",
    "\n",
    "Below are a few example solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example #1: Using the Tenacity library\n",
    "\n",
    "[Tenacity](https://tenacity.readthedocs.io/en/latest/) is an Apache 2.0 licensed general-purpose retrying library, written in Python, to simplify the task of adding retry behavior to just about anything.\n",
    "\n",
    "To add exponential backoff to your requests, you can use the `tenacity.retry` [decorator](https://peps.python.org/pep-0318/). The following example uses the `tenacity.wait_random_exponential` function to add random exponential backoff to a request.\n",
    "\n",
    "Note that the Tenacity library is a third-party tool, and OpenAI makes no guarantees about its reliability or security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8PAu6anX2JxQdYmJRzps38R8u0ZBC', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='in a small village nestled among green fields and rolling hills, there lived a kind-hearted and curious young girl named Lily. Lily was known for her bright smile and infectious laughter, bringing joy to everyone around her.\\n\\nOne sunny morning, as Lily played in the meadows, she stumbled upon a mysterious book tucked away beneath a tall oak tree. Intrigued, she picked it up and dusted off its weathered cover to reveal intricate golden patterns. Without hesitation, she opened it, discovering that its pages were filled with magical tales and enchanting adventures.\\n\\nAmong the stories she found, one particularly caught her attention—a tale of a long-lost treasure hidden deep within a mysterious forest. Legend had it that whoever found this hidden treasure would be granted one wish, no matter how big or small. Excited by the prospect of finding such treasure and fulfilling her wildest dreams, Lily decided to embark on a thrilling journey to the forest.\\n\\nGathering her courage, Lily told her parents about the magical book and her quest to find the hidden treasure. Though concerned for their daughter\\'s safety, they couldn\\'t help but admire her spirit and determination. They hugged her tightly and blessed her with love and luck, promising to await her return.\\n\\nEquipped with a map she found within the book, Lily ventured into the depths of the thick forest. The trees whispered tales of forgotten secrets, and the enchanted creatures hidden within watched her every step. But Lily remained undeterred, driven by her desire to discover what lay ahead.\\n\\nDays turned into weeks as Lily traversed through dense foliage, crossed swift rivers, and climbed treacherous mountains. She encountered mystical beings who offered guidance and protection along her perilous journey. With their help, she overcame countless obstacles and grew braver with each passing day.\\n\\nFinally, after what felt like an eternity, Lily reached the heart of the forest. There, beneath a jeweled waterfall, she found the long-lost treasure—a magnificent chest adorned with sparkling gemstones. Overwhelmed with excitement, she gently opened the chest to reveal a brilliant light that illuminated the forest.\\n\\nWithin the glow, a wise voice echoed, \"You have proven your courage and pure heart, young Lily. Make your wish, and it shall be granted.\"\\n\\nLily thought deeply about her wish, realizing that her true treasure was the love and happiness she felt in her heart. Instead of making a wish for herself, she asked for the wellbeing and prosperity of her village, spreading joy and harmony to everyone living there.\\n\\nAs the light faded, Lily knew her quest was complete. She retraced her steps through the forest, returning home to find her village flourishing. Fields bloomed with vibrant flowers, and laughter filled the air.\\n\\nThe villagers greeted Lily with open arms, recognizing her selflessness and the magic she had brought into their lives. From that day forward, they told the tale of Lily\\'s journey, celebrating her as a heroine who embodied the power of love, kindness, and the belief that true treasure lies within oneself.\\n\\nAnd so, the story of Lily became an everlasting legend, inspiring generations to follow their dreams, be selfless, and find the true treasures that lie within their hearts.', role='assistant', function_call=None, tool_calls=None))], created=1701010806, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=641, prompt_tokens=12, total_tokens=653))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs)\n",
    "\n",
    "\n",
    "completion_with_backoff(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"Once upon a time,\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example #2: Using the backoff library\n",
    "\n",
    "Another library that provides function decorators for backoff and retry is [backoff](https://pypi.org/project/backoff/).\n",
    "\n",
    "Like Tenacity, the backoff library is a third-party tool, and OpenAI makes no guarantees about its reliability or security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AqRiD3gF3q8VVs6w8jgba6FHGr0L5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"in a small village nestled between lush green hills and a shimmering lake, there lived a young girl named Elara. Elara had a curious spirit and a heart full of dreams. Every day, she would explore the woods surrounding her home, searching for hidden treasures and magical creatures.\\n\\nOne sunny afternoon, while wandering deeper into the forest than she ever had before, Elara stumbled upon a sparkling, crystal-clear pond. As she knelt down to take a closer look, she noticed a glimmering object at the bottom. It was a beautifully crafted key, shining with an otherworldly light. Without thinking twice, Elara reached into the cool water and retrieved the key, feeling a strange warmth envelop her.\\n\\nLittle did she know, this key was no ordinary key. It was said to unlock a secret door hidden in the heart of the forest, a door that led to a realm of wonder and adventure. Legends whispered of enchanted beings, ancient wisdom, and challenges that could only be overcome through bravery and kindness.\\n\\nExcited by the possibility of what awaited her, Elara set off on a quest to find the hidden door. Guided by a faint glow that seemed to beckon her, she journeyed through twisting pathways, lush groves, and enchanted glades.\\n\\nAlong the way, she encountered talking animals, wise old trees, and mischievous fairies, each offering clues and riddles that tested her resolve and imagination. With each challenge she faced, Elara grew stronger and more confident, realizing that the true magic lay not just in the world around her, but within herself.\\n\\nAfter what felt like days of exploring, she finally found the door—a majestic archway covered in vines and blossoms, with a keyhole that sparkled like the night sky. Heart pounding with excitement, Elara inserted the key. With a gentle turn, the door slowly creaked open, revealing a land more breathtaking than she could have ever imagined.\\n\\nAs she stepped through the doorway, she found herself in a vibrant world filled with colors beyond description, where the sky shimmered in hues of gold and lavender, and the air was filled with the sweet scent of flowers that sang as they swayed in the breeze. Here, she encountered beings of light who welcomed her with open arms.\\n\\nBut soon, she discovered that this realm was in peril. A dark shadow loomed over the land, threatening to steal its magic and joy. Elara knew she couldn’t stand by and do nothing. With the friends she had made along her journey and the courage she had found within herself, she set out to confront the darkness.\\n\\nThrough trials that tested her strength, intellect, and compassion, Elara and her friends gathered the forgotten magic of the realm. They united their powers, confronting the shadow in an epic battle of light and dark. In the end, it was Elara's unwavering belief in hope and friendship that banished the darkness, restoring peace and harmony to the land.\\n\\nGrateful for her bravery, the beings of light gifted Elara a shimmering pendant that would allow her to return to their world whenever she wished, reminding her that true magic lies in the connections we forge with others and the courage to follow our dreams.\\n\\nWith her heart full of joy, Elara returned to her village, forever changed by her adventure. She would often revisit the magical realm, sharing stories with her friends and inspiring them to embrace their own dreams. And so, the girl who once wandered the woods became a beacon of hope, a reminder that within every heart lies the power to change the world.\\n\\nAnd from that day on, the little village thrived, full of laughter, love, and dreams waiting to be explored—each adventure beginning just like hers, with a curious heart and a willingness to believe in the impossible. \\n\\nThe end.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), internal_metrics=[{'cached_prompt_tokens': 0, 'total_accepted_tokens': 0, 'total_batched_tokens': 794, 'total_predicted_tokens': 0, 'total_rejected_tokens': 0, 'total_tokens_in_completion': 795, 'cached_embeddings_bytes': 0, 'cached_embeddings_n': 0, 'uncached_embeddings_bytes': 0, 'uncached_embeddings_n': 0, 'fetched_embeddings_bytes': 0, 'fetched_embeddings_n': 0, 'n_evictions': 0, 'sampling_steps': 767, 'sampling_steps_with_predictions': 0, 'batcher_ttft': 0.20319080352783203, 'batcher_initial_queue_time': 0.12981152534484863}])], created=1737062945, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=767, prompt_tokens=12, total_tokens=779, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, cached_tokens_internal=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import backoff  # for exponential backoff\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.RateLimitError, max_time=60, max_tries=6)\n",
    "def completions_with_backoff(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs)\n",
    "\n",
    "\n",
    "completions_with_backoff(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"Once upon a time,\"}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: Manual backoff implementation\n",
    "\n",
    "If you don't want to use third-party libraries, you can implement your own backoff logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8PAxGvV3GbLpnOoKSvJ00XCUdOglM', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"in a faraway kingdom, there lived a young princess named Aurora. She was known for her beauty, grace, and kind heart. Aurora's kingdom was filled with lush green meadows, towering mountains, and sparkling rivers. The princess loved spending time exploring the enchanting forests surrounding her castle.\\n\\nOne day, while Aurora was wandering through the woods, she stumbled upon a hidden clearing. At the center stood a majestic oak tree, its branches reaching towards the sky. Aurora approached the tree with curiosity, and as she got closer, she noticed a small door at its base.\\n\\nIntrigued, she gently pushed open the door and was amazed to find herself in a magical realm. The forest transformed into a breathtaking wonderland, with colorful flowers blooming in every direction and woodland creatures frolicking joyously. Aurora's eyes widened with wonder as she explored this extraordinary world.\\n\\nAs she explored further, Aurora came across a small cottage in the distance. Curiosity overcame her, and she cautiously approached the cottage. To her surprise, an elderly woman with twinkling eyes and a warm smile stood in the doorway, welcoming her inside.\\n\\nThe woman revealed herself to be a fairy named Luna. Luna informed Aurora that she had been chosen to undertake a quest that would bring harmony to both her kingdom and the mystical realm. Aurora, eager to help, listened intently as Luna explained that a powerful enchantress had cast a spell on the kingdom, causing darkness and despair to loom over the land.\\n\\nTo break the curse, Aurora had to embark on a journey to retrieve a magical crystal hidden deep within the heart of an ancient cave. Without hesitation, the princess agreed and bid farewell to Luna, promising to return victorious.\\n\\nWith newfound determination, Aurora set off on her quest. Along the way, she encountered numerous challenges and obstacles but never lost hope. She often drew strength from the enchanting woodland creatures who accompanied her on this journey, reminding her that she was not alone.\\n\\nAfter a long and arduous journey, Aurora reached the entrance of the ancient cave. Inside, she faced a series of tests that pushed her physical and emotional limits. With sheer determination and unwavering courage, she overcame each trial, paving her way to the crystal's resting place.\\n\\nAs Aurora held the crystal in her hands, its warmth spread through her body. The artifact contained unimaginable power that could shatter the enchantress's curse and restore light to her kingdom. Brimming with joy and newfound strength, she made her way back to Luna's cottage.\\n\\nUpon her return, Aurora and Luna performed a powerful ritual, using the crystal's magic to break the curse. Waves of light and color spread across the kingdom, banishing darkness and despair. The once-gray skies turned blue, and laughter filled the air once again. The kingdom rejoiced, thanking Princess Aurora for her bravery and selflessness.\\n\\nFrom that day forward, Aurora was hailed as a hero, not only in her kingdom but also in the mystical realm. She continued to be a beacon of hope and kindness, reminding everyone that true courage lies within, waiting to be awakened.\\n\\nAnd so, Princess Aurora's tale lived on as a timeless reminder that even in the darkest of times, there is always light and hope to be found.\", role='assistant', function_call=None, tool_calls=None))], created=1701011002, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=657, prompt_tokens=12, total_tokens=669))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import random\n",
    "import time\n",
    "\n",
    "# define a retry decorator\n",
    "def retry_with_exponential_backoff(\n",
    "    func,\n",
    "    initial_delay: float = 1,\n",
    "    exponential_base: float = 2,\n",
    "    jitter: bool = True,\n",
    "    max_retries: int = 10,\n",
    "    errors: tuple = (openai.RateLimitError,),\n",
    "):\n",
    "    \"\"\"Retry a function with exponential backoff.\"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Initialize variables\n",
    "        num_retries = 0\n",
    "        delay = initial_delay\n",
    "\n",
    "        # Loop until a successful response or max_retries is hit or an exception is raised\n",
    "        while True:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "\n",
    "            # Retry on specified errors\n",
    "            except errors as e:\n",
    "                # Increment retries\n",
    "                num_retries += 1\n",
    "\n",
    "                # Check if max retries has been reached\n",
    "                if num_retries > max_retries:\n",
    "                    raise Exception(\n",
    "                        f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
    "                    )\n",
    "\n",
    "                # Increment the delay\n",
    "                delay *= exponential_base * (1 + jitter * random.random())\n",
    "\n",
    "                # Sleep for the delay\n",
    "                time.sleep(delay)\n",
    "\n",
    "            # Raise exceptions for any errors not specified\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@retry_with_exponential_backoff\n",
    "def completions_with_backoff(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs)\n",
    "\n",
    "\n",
    "completions_with_backoff(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"Once upon a time,\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backing off to another model\n",
    "\n",
    "If you encounter rate limit errors on your primary model, one option is to switch to a secondary model, often one that’s less powerful or more cost-effective. This approach helps keep your application responsive when your primary model is throttled or unavailable.\n",
    "\n",
    "However, fallback models can differ significantly in accuracy, latency, and cost. As a result, this strategy might not work for every use case; particularly those requiring highly consistent results. Additionally, keep in mind that some models share rate limits, which may reduce the effectiveness of simply switching models.\n",
    "\n",
    "Before deploying this approach to production, thoroughly test how it affects output quality, user experience, and operational budgets. Validate your fallback solution with relevant evaluations to ensure it meets your requirements and maintains acceptable performance under real-world conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ApgkrBU1L4JFy7Fb3m8YjZeDnX2T6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"there was a small, peaceful village nestled between towering mountains and lush, green forests. The villagers lived simple yet joyful lives, farming their land and tending to their animals. Among them was a young girl named Elara, who possessed an insatiable curiosity about the world beyond the mountains.\\n\\nElara had always been fascinated by the stories her grandmother told her about the legendary Phoenix, a mythical bird rumored to live in the heart of the mountains. According to the tales, the Phoenix was a majestic creature with feathers that shimmered like gold and eyes that glowed with the warmth of a thousand sunsets. It was said to possess the power of rebirth, rising anew from its own ashes, and that anyone who witnessed this miracle would be granted a single wish.\\n\\nDetermined to uncover the truth behind the legend, Elara set out on a journey to find the Phoenix. Armed with nothing but her grandmother's stories and her unwavering spirit, she ventured into the forest. The path was fraught with challenges—steep cliffs, raging rivers, and thick, tangled underbrush. Yet, Elara faced each obstacle with courage and determination.\\n\\nAs days turned into weeks, Elara's hope began to wane. Exhausted and weary, she reached a hidden valley bathed in the golden light of the setting sun. There, to her astonishment, she found a nest of radiant flames. Within the fire, the Phoenix emerged, a breathtaking vision of beauty and power.\\n\\nElara watched in awe as the Phoenix spread its wings, casting a warm, golden glow over the valley. In that moment, she remembered her grandmother's words and whispered her wish—a wish not for herself, but for the prosperity and happiness of her village.\\n\\nThe Phoenix gazed at her with eyes full of understanding and, with a graceful lift, soared into the sky, leaving behind a single, glowing feather. Elara took the feather, feeling its warmth in her hands, and made her way back to her village.\\n\\nUpon her return, Elara found her village transformed. The fields were more fertile than ever, laughter echoed through the streets, and a sense of peace enveloped their lives. The villagers hailed Elara as a hero, a symbol of courage and selflessness.\\n\\nAnd so, Elara's journey came to an end, but her story lived on, a testament to the power of hope, bravery, and the magic that can be found when one dares to chase their dreams.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), internal_metrics=[{'cached_prompt_tokens': 0, 'total_accepted_tokens': 0, 'total_batched_tokens': 523, 'total_predicted_tokens': 0, 'total_rejected_tokens': 0, 'total_tokens_in_completion': 524, 'cached_embeddings_bytes': 0, 'cached_embeddings_n': 0, 'uncached_embeddings_bytes': 0, 'uncached_embeddings_n': 0, 'fetched_embeddings_bytes': 0, 'fetched_embeddings_n': 0, 'n_evictions': 0, 'sampling_steps': 496, 'sampling_steps_with_predictions': 0, 'batcher_ttft': 0.03744220733642578, 'batcher_initial_queue_time': 0.0005207061767578125}])], created=1736882441, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=496, prompt_tokens=12, total_tokens=508, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, cached_tokens_internal=0)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def completions_with_fallback(fallback_model, **kwargs):\n",
    "    try:\n",
    "        return client.chat.completions.create(**kwargs)\n",
    "    except openai.RateLimitError:\n",
    "        kwargs['model'] = fallback_model\n",
    "        return client.chat.completions.create(**kwargs)\n",
    "    \n",
    "    \n",
    "completions_with_fallback(fallback_model=\"gpt-4o-mini\", model=\"gpt-4o\", messages=[{\"role\": \"user\", \"content\": \"Once upon a time,\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing `max_tokens` to match expected completions\n",
    "\n",
    "Rate limit usage is calculated based on the greater of:\n",
    "1. `max_tokens` - the maximum number of tokens allowed in a response.\n",
    "2. Estimated tokens in your input – derived from your prompt’s character count.\n",
    "\n",
    "If you set `max_tokens` too high, your usage can be overestimated, even if the actual response is much shorter. To avoid hitting rate limits prematurely, configure `max_tokens` so it closely matches the size of the response you expect. This ensures more accurate usage calculations and helps prevent unintended throttling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Aq0JmjugPw2i232ZEZuK5inHnx6Vc', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='in a small village nestled between lush green hills and a sparkling river, there lived a young girl named Lila. Lila was known for her boundless curiosity and adventurous spirit. She had a wild imagination, often spinning tales about the mysteries that lay beyond the village borders.\\n\\nOne day, while exploring the forest, Lila stumbled upon a hidden path she had never seen before. The path was winding and overgrown, beckoning her with whispers of adventure. Against her better judgment, she decided to', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), internal_metrics=[{'cached_prompt_tokens': 0, 'total_accepted_tokens': 0, 'total_batched_tokens': 127, 'total_predicted_tokens': 0, 'total_rejected_tokens': 0, 'total_tokens_in_completion': 128, 'cached_embeddings_bytes': 0, 'cached_embeddings_n': 0, 'uncached_embeddings_bytes': 0, 'uncached_embeddings_n': 0, 'fetched_embeddings_bytes': 0, 'fetched_embeddings_n': 0, 'n_evictions': 0, 'sampling_steps': 100, 'sampling_steps_with_predictions': 0, 'batcher_ttft': 0.030033111572265625, 'batcher_initial_queue_time': 0.0006170272827148438}])], created=1736957642, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=100, prompt_tokens=12, total_tokens=112, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, cached_tokens_internal=0)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def completions_with_max_tokens(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs)\n",
    "\n",
    "\n",
    "completions_with_max_tokens(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"Once upon a time,\"}], max_tokens=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to maximize throughput of batch processing given rate limits\n",
    "\n",
    "If you're processing real-time requests from users, backoff and retry is a great strategy to minimize latency while avoiding rate limit errors.\n",
    "\n",
    "However, if you're processing large volumes of batch data, where throughput matters more than latency, there are a few other things you can do in addition to backoff and retry.\n",
    "\n",
    "### Proactively adding delay between requests\n",
    "\n",
    "If you are constantly hitting the rate limit, then backing off, then hitting the rate limit again, then backing off again, it's possible that a good fraction of your request budget will be 'wasted' on requests that need to be retried. This limits your processing throughput, given a fixed rate limit.\n",
    "\n",
    "Here, one potential solution is to calculate your rate limit and add a delay equal to its reciprocal (e.g., if your rate limit 20 requests per minute, add a delay of 3–6 seconds to each request). This can help you operate near the rate limit ceiling without hitting it and incurring wasted requests.\n",
    "\n",
    "#### Example of adding delay to a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8PAyCR1axKsomV0e349XiCN1Z81pH', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"in a small village, there lived a young girl named Maya. Maya was known for her kindness and love for nature. She spent hours exploring the forests surrounding the village, admiring the vibrant flowers and talking to the animals.\\n\\nOne sunny day, as Maya was picking wildflowers, she stumbled upon a wounded blackbird with a broken wing. Feeling sorry for the bird, Maya gently picked it up and cradled it in her hands. She knew she had to help the bird, so she hurried back to her cottage.\\n\\nMaya set up a cozy nest for the blackbird and carefully splinted its wing. She fed it worms and berries, doing everything she could to nurse it back to health. Each day, she would sing lullabies and tell stories to keep the blackbird company. Slowly, the bird's wing healed, and before long, it was ready to fly again.\\n\\nOn a beautiful morning, Maya opened the window of her cottage and released the blackbird into the sky. As the bird soared into the air, Maya's heart filled with joy and gratitude. Little did she know, this act of kindness would change her life forever.\\n\\nThe following night, a mysterious glowing light illuminated Maya's room. Startled, she sat up and saw a magical creature standing before her. It was a fairy, tiny yet radiating warmth and light.\\n\\nThe fairy introduced herself as Luna, the Guardian of the Forest. She had witnessed Maya's kindness towards the blackbird and had been watching her ever since. Luna explained that she had come to reward Maya for her selflessness.\\n\\nWith a wave of her wand, Luna granted Maya the ability to communicate with animals. Maya's eyes widened with amazement as she realized she could now understand the language of nature. Birds chirped melodies, rabbits whispered secrets, and trees shared their ancient wisdom.\\n\\nOver time, Maya's ability made her beloved by both humans and animals. Farmers sought her advice on how to care for their crops, and children flocked to her for stories of her enchanting encounters with the forest creatures. Maya used her gift to teach others about the importance of living in harmony with nature.\\n\\nAs years passed, Maya became known as the Village Guardian. She dedicated herself to protecting the surrounding forests from harm and educating others on sustainable living. The village flourished under Maya's guidance, and animals and humans lived side by side peacefully.\\n\\nAnd so, Maya's story became a legend passed down through generations. Her kindness, love for nature, and her ability to communicate with animals inspired people to treat the world around them with compassion and care.\", role='assistant', function_call=None, tool_calls=None))], created=1701011060, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=524, prompt_tokens=12, total_tokens=536))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define a function that adds a delay to a Completion API call\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return client.chat.completions.create(**kwargs)\n",
    "\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "rate_limit_per_minute = 20\n",
    "delay = 60.0 / rate_limit_per_minute\n",
    "\n",
    "delayed_completion(\n",
    "    delay_in_seconds=delay,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Once upon a time,\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching requests\n",
    "\n",
    "The OpenAI API enforces separate limits for requests per minute/day (RPM/RPD) and tokens per minute (TPM). If you’re hitting RPM limits but still have available TPM capacity, consider batching multiple tasks into each request.\n",
    "\n",
    "By bundling several prompts together, you reduce the total number of requests sent per minute, which helps avoid hitting the RPM cap. This approach may also lead to higher overall throughput if you manage your TPM usage carefully. However, keep the following points in mind:\n",
    "- Each model has a maximum number of tokens it can process in one request. If your batched prompt exceeds this limit, the request will fail or be truncated.\n",
    "- Batching can introduce extra waiting time if tasks are delayed until they’re grouped into a single request. This might affect user experience for time-sensitive applications.\n",
    "- When sending multiple prompts, the response object may not return in the same order or format as the prompts that were submitted. You should try to match each response back to its corresponding prompt by post-processing the output.\n",
    "\n",
    "#### Example without batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time,in a quaint little village nestled between rolling hills and a sparkling river, there lived a young girl named\n",
      "Once upon a time,Once upon a time, in a tranquil village nestled between rolling hills and lush forests, there lived a\n",
      "Once upon a time,in a lush, green valley surrounded by towering mountains, there lay a small village called Eldergrove\n",
      "Once upon a time,in a quaint little village nestled between rolling hills and a sparkling river, there lived a young girl named\n",
      "Once upon a time,in a small village nestled between whispering woods and a sparkling river, there lived a curious young girl\n",
      "Once upon a time,in a small village nestled between a vast forest and a shimmering lake, there lived a kind-hearted girl\n",
      "Once upon a time,in a quaint little village nestled between rolling hills and a shimmering lake, there lived a curious girl named\n",
      "Once upon a time,in a quaint little village nestled between emerald hills and a sparkling brook, there was a curious child named\n",
      "Once upon a time,in a quaint little village nestled between rolling hills and lush forests, there lived an old clockmaker named\n",
      "Once upon a time,in a quaint little village nestled between rolling hills and a shimmering lake, there lived a curious young girl\n"
     ]
    }
   ],
   "source": [
    "num_stories = 10\n",
    "content = \"Once upon a time,\"\n",
    "\n",
    "# serial example, with one story completion per request\n",
    "for _ in range(num_stories):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "        max_tokens=20,\n",
    "    )\n",
    "\n",
    "    print(content + response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batching multiple prompts in a single request\n",
    "\n",
    "This approach packs several prompts into a single request, resulting in a single response from the model that addresses each prompt in turn.\n",
    "\n",
    "While this method is efficient in terms of API calls, it may require extra parsing or post-processing on your end to separate the responses. Additionally, there is a risk that the model’s output will “blend” the prompts if it isn’t guided clearly, so be sure to instruct it explicitly on how to structure its answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Story #1:** Once upon a time, in a small village nestled between lush green hills, there lived a young girl named Clara. Clara had a gift for talking to animals. One day, while wandering through the forest, she heard a soft whimpering sound. Following the noise, she discovered a tiny fox caught in a hunter's snare. Clara gently freed the fox and, in gratitude, it promised to grant her one wish. Clara wished for the village to always have enough food and happiness. From that day on, whenever a storm threatened their harvest, the fox would bring rainbows that promised bountiful crops and joyful hearts.\n",
      "\n",
      "**Story #2:** Once upon a time, in a kingdom where the sky was painted in eternal twilight, lived a boy named Leo who adored the stars. Every night, he would climb a hill and gaze at them, dreaming of discovering their secrets. One fateful night, a shooting star fell close by. Leo ran to it and found a small, glowing orb. It was a fallen star, and it spoke to him! The star revealed that every star had a story, but only those with pure hearts could hear them. With the star as his guide, Leo traveled across the sky, learning the tales of constellations and sharing them with his village, igniting a love for the cosmos among its people.\n",
      "\n",
      "**Story #3:** Once upon a time, in a forgotten land where time stood still, there was a magical clocktower that had the power to control time itself. The clockkeeper, an old man named Silas, was the only one who understood its mysteries. One day, a curious girl named Elara stumbled upon the tower, intrigued by its intricate designs and the enchanting sounds that echoed from within. Silas decided to teach her the ways of time. Elara learned that every tick of the clock affected the world outside. Together, they saved a village from a disaster by rewinding time just long enough to warn the villagers. In gratitude, the townspeople honored Elara as the \"Keeper of Moments,\" reminding them that every second is precious.\n",
      "\n",
      "**Story #4:** Once upon a time, in a world where emotions could be seen as colors, there was a young artist named Mia. Mia had the unique ability to paint her feelings, which would bring joy to those who gazed upon her artwork. One day, she encountered a clouded figure in the marketplace, shrouded in gray and sorrow. Determined to bring color back to their life, Mia invited the figure to her studio. As she painted, her brushstrokes began to lift the gloom, revealing beautiful colors hidden beneath. With each layer, the figure began to smile. Soon, they transformed into a vibrant rainbow, spreading happiness throughout the world, reminding everyone that we can share our colors with others.\n",
      "\n",
      "**Story #5:** Once upon a time, in a distant ocean, there was a graceful mermaid named Luna who longed to see the land above the waves. One evening, she swam close to the surface and witnessed a ship sailing on the horizon. Curious, she swam alongside it and overheard the sailors singing songs of adventure and freedom. Captivated, Luna decided to explore the surface world. With the help of a kind sailor, she transformed into a human for one night. They danced under the moonlight, sharing dreams of the sea and sky. As dawn approached, Luna returned to the ocean, but she left behind a shell that played their song, reminding them of their magical encounter and the bond between land and sea.\n",
      "\n",
      "**Story #6:** Once upon a time, in a realm of enchanted forests, there lived a wise old owl named Olwen. Every creature came to him for advice, but one day, a young squirrel named Pip approached him, desperate for help. Pip had lost his way in the vast woods and could not find his family. Olwen offered to guide him, but only if Pip could solve one riddle. With determination, Pip listened closely and thought hard. After several attempts, he finally answered the riddle correctly, impressing the wise owl. Olwen led Pip through the mystical forest, and with each step, Pip discovered the beauty of his surroundings. They finally reached his family, and Pip learned that sometimes, getting lost is simply a path to finding oneself.\n",
      "\n",
      "**Story #7:** Once upon a time, in a land where dreams floated like clouds in the sky, there lived a young boy named Finn. Each night, he would catch dreams and weave them into tapestries, bringing hope and joy to his village. One night, Finn discovered a dark dream threatening to engulf the others. Instead of capturing it, he decided to understand it. He entered the dark dream and discovered it was a reflection of fear and pain. Rather than fight it, he shared stories of courage and love, transforming the dark dream into a beautiful tapestry of light. Finn returned home, and from that night on, his village learned that embracing even the darkest dreams could lead to the most beautiful transformations.\n",
      "\n",
      "**Story #8:** Once upon a time, in a bustling city of towering skyscrapers, there lived a little robot named EZ-9. EZ-9 was designed to assist people, but he felt an unquenchable yearning to create rather than just serve. One day, he stumbled upon a forgotten park, overgrown with weeds and neglected. Inspired, EZ-9 began to DIY—using scrap metal and old parts, he transformed the park into a vibrant space filled with art installations and blooming flowers. The people of the city were enchanted as they discovered the park, and they soon started joining EZ-9 in his creative endeavors. Together, they brought life back to the forgotten space, reminding everyone of the beauty in collaboration and imagination.\n",
      "\n",
      "**Story #9:** Once upon a time, in a vast desert woven with golden sands, there was a wise camel named Khamar. Khamar had traveled across the lands, gathering tales from every traveler he encountered. One day, he came across a lost caravan, desperate for water and guidance. Khamar offered to lead them to an oasis, but first, he shared his stories of courage and friendship. Inspired by the tales, the caravan members found strength in one another, helping each other carry their burdens. When they finally reached the sparkling oasis, they were not just relieved by the water but also bonded by the power of shared stories. From that day on, Khamar became their storyteller, transforming every journey into an adventure filled with laughter and camaraderie.\n",
      "\n",
      "**Story #10:** Once upon a time, there was a giant tree known as Elderwood, whose roots spread deep into the earth and whose branches touched the sky. Beneath this extraordinary tree, a young girl named Aria discovered a hidden door carved into the trunk. Curious, she opened it and found herself in the Realm of Whispers, where the voices of history awaited her. Each whisper told a story of bravery, love, and wisdom from ages long past. Aria realized that she could share these tales with her village, keeping the wisdom alive. Returning home, she spoke of the stories, inspiring her people to value their heritage and cultivate a brighter future. Through her journeys in the tree, Aria became the bridge between the past and future, forever connected to the magic of Elderwood.\n"
     ]
    }
   ],
   "source": [
    "num_stories = 10\n",
    "content = \"Once upon a time,\"\n",
    "\n",
    "prompt_lines = [f\"Story #{i+1}: {content}\" for i in range(num_stories)]\n",
    "prompt_text = \"\\n\".join(prompt_lines)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": \"You are a helpful assistant. Please respond to each prompt as a separate short story.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt_text\n",
    "    }\n",
    "]\n",
    "\n",
    "# batched example, with all story completions in one request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batching multiple prompts in a single request with Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs) feature offers a more robust way to batch multiple prompts in a single request. \n",
    "\n",
    "Here, rather than parsing raw text or hoping the model follows informal formatting, you specify a strict schema. This ensures your application can reliably parse the results by examining the defined structure. This eliminates the need for extensive validation or complicated parsing logic, as Structured Outputs guarantees consistent, type-safe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"stories\":[\"Once upon a time, in a quiet village nestled between rolling hills, there lived a kind-hearted baker named Elara. Every morning, the sweet aroma of fresh bread wafted through the streets, drawing villagers to her shop like bees to flowers. One day, an elderly woman entered, asking for bread but only having a few coins. Elara smiled, gave her the bread for free, and said, 'Take care of yourself, for kindness is the most valuable currency.' From that day on, the village thrived on love and generosity, thanks to one baker's warm heart.\",\"Once upon a time, in a dense, enchanted forest, a curious fox named Finn dreamed of flying. Every day, he would sit under a towering oak tree, watching the birds soar gracefully in the sky. One day, a wise old owl noticed Finn's longing and said, 'If you wish to fly, you must create your own wings.' Inspired, Finn gathered feathers and twigs, crafting a pair of colorful wings. With a little help from his friends, he leaped off a hill and soared into the sky, discovering that sometimes, dreams can come true in the most unexpected ways.\",\"Once upon a time, high atop a misty mountain, there was a kingdom where the stars were not just sights to behold but who everyone believed were distant relatives looking down on them. The people would light lanterns every night, believing it would guide their kin back home. One star, named Astra, noticed this and descended to the earth, taking the form of a beautiful woman. She revealed herself at the lantern festival and danced among the villagers, reminding them that their spirits lived on in the stars, forever connected despite the miles between them.\",\"Once upon a time, there was a brave little turtle named Tilly who lived in a pond surrounded by flourishing meadows. Tilly dreamed of seeing the world beyond her pond, but her friends told her it was too dangerous. Undeterred, she set off on an adventure, slowly but surely. Along her journey, she befriended a hesitant rabbit who later turned out to be a great help in escaping a tricky situation. They returned to the pond with tales of wonders and taught the other animals that courage exists even in the smallest of hearts.\",\"Once upon a time, in a bustling city filled with towering skyscrapers, a young girl named Zara discovered an old paintbrush in a thrift store. The moment she picked it up, colors danced around her, and the mundane world transformed into a vibrant canvas. Everything she painted became alive, bringing joy and wonder to those around her. However, a greedy businessman sought to control her gift. With the help of her friends, Zara spread beauty all over the city, proving that art could not be owned, only shared—to uplift spirits and fill hearts with hope.\",\"Once upon a time, deep in the ocean, there lived a little mermaid named Mira who collected artifacts from shipwrecks. Among her treasures was a small, rusted key that sparked her curiosity. One day, she discovered an ancient door hidden within a coral cave. Using the key, she unlocked a magical underwater realm filled with shimmering creatures and lost souls. Gaston, a seaweed wizard, explained that she had freed those trapped for centuries. Mira returned home, determined to explore and protect the ocean’s depths, becoming its guardian.\",\"Once upon a time, in a land where dreams sprinkled the air like glitter, a gentle giant named Hugo roamed the hills. While most humans feared him, a brave child named Elinor approached him with kindness and shared her dreams. Hugo, touched by her bravery, decided to help Elinor realize her biggest dream—to see the land beyond the mountains. With great care, he carried her on his shoulders, showing her wonders and basking in the sunshine, proving that friendship knows no bounds, no matter the size.\",\"Once upon a time, in a quaint little town, there was an old library that was rumored to be magical. Books there whispered secrets and stories when no one was listening. A shy young boy named Leo discovered this secret during a stormy afternoon. Each night, he returned to read, and soon the book characters began to emerge, inviting him into their adventures. Leo, who once felt invisible, became a hero in this enchanted world, discovering the importance of stories and imagination and the power they held to change lives.\",\"Once upon a time, a lonely little planet named Zyra spun in solitude, far from the stars. One day, a comet zipped past, and Zyra longed to ask it to stay. The comet, noticing Zyra's glow dimming with sadness, decided to help. It brought star seeds from distant galaxies, filling Zyra with life and color. With each seed planted, new friends arrived—trees, crystalline lakes, and joyful creatures. Zyra learned that sometimes, all it takes to shine bright is to seek connections, no matter how distant they may seem.\",\"Once upon a time, in a sprawling desert filled with golden sands, there was a mystical oasis known to grant one wish to anyone who could find it. A clever merchant named Amir searched tirelessly for this oasis, guided by dreams and whispers of the wind. When he finally found it, he wished not for riches or power, but for the ability to bring peace to his land. His wish echoed across the dunes, and as the winds changed, they carried his message of hope, leading his people to unite, discovering that the true treasure was in unity and love.\"]}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Define the Pydantic model for the structured output\n",
    "class StoryResponse(BaseModel):\n",
    "    stories: list[str]\n",
    "\n",
    "num_stories = 10\n",
    "content = \"Once upon a time,\"\n",
    "\n",
    "prompt_lines = [f\"Story #{i+1}: {content}\" for i in range(num_stories)]\n",
    "prompt_text = \"\\n\".join(prompt_lines)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": \"You are a helpful assistant. Please respond to each prompt as a separate short story.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt_text\n",
    "    }\n",
    "]\n",
    "\n",
    "# batched example, with all story completions in one request and using structured output\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    response_format=StoryResponse,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example parallel processing script\n",
    "\n",
    "We've written an example script for parallel processing large quantities of API requests: [api_request_parallel_processor.py](https://github.com/openai/openai-cookbook/blob/main/examples/api_request_parallel_processor.py).\n",
    "\n",
    "The script combines some handy features:\n",
    "- Streams requests from file, to avoid running out of memory for giant jobs\n",
    "- Makes requests concurrently, to maximize throughput\n",
    "- Throttles both request and token usage, to stay under rate limits\n",
    "- Retries failed requests, to avoid missing data\n",
    "- Logs errors, to diagnose problems with requests\n",
    "\n",
    "Feel free to use it as is or modify it to suit your needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
