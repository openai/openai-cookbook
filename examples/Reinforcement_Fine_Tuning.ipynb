{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring Model Graders for Reinforcement Fine-Tuning**\n",
    "\n",
    "*This guide is for developers and ML practitioners who already know their way around OpenAIʼs APIs, have a basic understanding of reinforcement fine-tuning (RFT), and wish to use their fine-tuned models for research or other appropriate uses. OpenAI’s services are not intended for the personalized treatment or diagnosis of any medical condition and are subject to our [applicable terms](https://openai.com/policies/).*\n",
    "\n",
    "[Reinforcement fine-tuning (RFT)](https://platform.openai.com/docs/guides/reinforcement-fine-tuning) of reasoning models consists in running reinforcement learning on of top the models to improve their reasoning performance by exploring the solution space and reinforcing strategies that result in a higher reward. RFT helps the model make sharper decisions and interpret context more effectively. \n",
    "\n",
    "\n",
    "In this guide, weʼll walk through how to apply RFT to the OpenAI `o4-mini` reasoning model, using a task from the life sciences research domain: predicting outcomes from doctor-patient transcripts and descriptions, which is a necessary assessment in many health research studies. We'll use a subset of the medical-o1-verifiable-problem [dataset](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-verifiable-problem/viewer/default/train?row=0). You will learn key steps to take in order to succesfully run RFT jobs for your use-cases.\n",
    "\n",
    "Here’s what we’ll cover:\n",
    "\n",
    "- **[1. Setup](#1-setup)**\n",
    "- **[2. Gathering the dataset](#2-gathering-the-dataset)**\n",
    "- **[3. Benchmarking the base model](#3-benchmarking-the-base-model)**\n",
    "- **[4. Defining your grader](#4-defining-your-grader)**\n",
    "- **[5. Training](#5-training)**\n",
    "- **[6. Using your fine-tuned model](#6-using-your-fine-tuned-model)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1. Setup**\n",
    "\n",
    "Even strong reasoning models can miss the mark when it comes to expert-level behavior-especially in domains like medicine, where nuance and exactness matter. Imagine a model trying to extract [ICD-10](https://www.cms.gov/medicare/coding-billing/icd-10-codes) codes from a transcript: even if it understands the gist, it may not use the precise terminology expected by medical professionals. \n",
    "\n",
    "Other great candidates for RFT include topics like ledger normalization or tiering fraud risk- settings in which you want precise, reliable, and repeatable reasoning. Checkout our [RFT use-cases guide](https://platform.openai.com/docs/guides/rft-use-cases) for great examples. \n",
    "\n",
    "In our case, weʼll focus on teaching `o4-mini` to become better at predicting the outcomes of clinical conversations and descriptions. Specifically, we want to see if RFT can boost the accuracy of the prediction. \n",
    "\n",
    "Along the way, weʼll talk about how to write effective graders, how they guide the modelʼs learning, and how to watch out for classic reward-hacking pitfalls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **2. Gathering the Dataset**\n",
    "\n",
    "Letʼs start off by loading the dataset from Hugging Face. Weʼre interested in samples framed as a description of a patient case with an associated question, followed by the correct answer. These represent real world transcripts where a physician is summarizing a case and assigning an outcome. For any use-case, verifying the accuracy of the gold level answers is critical and requires careful consideration. Here, we will trust the dataset quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theophile/Documents/repos/jupyter-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered samples: 9169\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"FreedomIntelligence/medical-o1-verifiable-problem\")\n",
    "\n",
    "def is_age_question(sample):\n",
    "    question = sample.get('Open-ended Verifiable Question', '')\n",
    "    # Match \"A 88-year-old\", \"An 8-year-old\", \"A 23-year-old\", etc. at the start\n",
    "    return re.match(r\"^(A|An) \\d{1,2}-year-old\", question) is not None\n",
    "\n",
    "filtered_samples = [s for s in ds[\"train\"] if is_age_question(s)]\n",
    "print(f\"Filtered samples: {len(filtered_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of RFT is that it doesnʼt need thousands of samples to start making a difference. Thanks to trajectory sampling and the feedback loop during training, the model learns not just correct behaviors, but also patterns to avoid. This means we can see solid gains even with small datasets.\n",
    "\n",
    "For this run, weʼll randomly sample 100 training and 100 test examples and slightly normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 100\n",
      "Number of test samples: 100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Randomly select 100 training samples from filtered_samples\n",
    "train_samples = random.sample(filtered_samples, min(100, len(filtered_samples)))\n",
    "\n",
    "# Remove training samples from filtered_samples to avoid overlap\n",
    "remaining_samples = [s for s in filtered_samples if s not in train_samples]\n",
    "\n",
    "# Randomly select 100 test samples from the remaining samples (no overlap)\n",
    "test_samples = random.sample(remaining_samples, min(100, len(remaining_samples)))\n",
    "\n",
    "print(f\"Number of training samples: {len(train_samples)}\")\n",
    "print(f\"Number of test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the 'Ground-True Answer' fields to all lowercase in train and test samples\n",
    "for sample in train_samples:\n",
    "    if 'Ground-True Answer' in sample and isinstance(sample['Ground-True Answer'], str):\n",
    "        sample['Ground-True Answer'] = sample['Ground-True Answer'].lower()\n",
    "\n",
    "for sample in test_samples:\n",
    "    if 'Ground-True Answer' in sample and isinstance(sample['Ground-True Answer'], str):\n",
    "        sample['Ground-True Answer'] = sample['Ground-True Answer'].lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert these samples to `jsonl` format, as expected by the [reinforcement finetuning API](https://platform.openai.com/docs/api-reference/fine-tuning/reinforcement-input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_to_jsonl_format(samples, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for sample in samples:\n",
    "            user_content = sample.get(\"Open-ended Verifiable Question\", \"\")\n",
    "            reference_answer = sample.get(\"Ground-True Answer\", \"\")\n",
    "            json_obj = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": user_content}\n",
    "                ],\n",
    "                \"reference_answer\": reference_answer\n",
    "            }\n",
    "            f.write(json.dumps(json_obj) + \"\\n\")\n",
    "\n",
    "def load_jsonl(filename):\n",
    "    samples = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            samples.append(json.loads(line))\n",
    "    return samples\n",
    "\n",
    "# Save the datasets to jsonl files\n",
    "convert_to_jsonl_format(train_samples, \"data/medical_01_verifiable_problem_train.jsonl\")\n",
    "convert_to_jsonl_format(test_samples, \"data/medical_01_verifiable_problem_val.jsonl\")\n",
    "\n",
    "# Load the datasets back from jsonl files\n",
    "train_samples_loaded = load_jsonl(\"data/medical_01_verifiable_problem_train.jsonl\")\n",
    "test_samples_loaded = load_jsonl(\"data/medical_01_verifiable_problem_val.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next up: we’ll see how the base model performs out of the box-and where there’s room to grow.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **3. Benchmarking the Base Model**\n",
    "\n",
    "Before we fine-tune anything, we need to know where we’re starting from. Benchmarking gives us a clear picture of the model’s initial strengths and weaknesses-so we can later measure how far it’s come.\n",
    "\n",
    "We’ll first lean on two simple yet powerful evaluators:\n",
    "\n",
    "1. `clinical_phrase_binary_grader` - an exact-match checker.\n",
    "2. `clinical_phrase_grader` - a softer, token-based similarity grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, utils\n",
    "\n",
    "def clinical_phrase_grader(sample: dict, item: dict) -> float:\n",
    "    from rapidfuzz import fuzz, utils\n",
    "    score = fuzz.token_set_ratio(sample[\"output_text\"], item[\"reference_answer\"], processor=utils.default_process)\n",
    "    return score / 100.0\n",
    "\n",
    "def clinical_phrase_binary_grader(sample: dict, item: dict) -> float:\n",
    "    return 1.0 if sample[\"output_text\"] == item[\"reference_answer\"] else 0.0\n",
    "\n",
    "def combined_grader(sample: dict, item: dict, weights: list[float] = [0.85, 0.15]) -> float:\n",
    "    clinical_phrase_score = clinical_phrase_grader(sample, item)\n",
    "    binary_score = clinical_phrase_binary_grader(sample, item)\n",
    "    return weights[0] * clinical_phrase_score + weights[1] * binary_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This combination lets us track both strict correctness and partial lexical overlap. The binary grader gives a crisp 0 or 1: did the model produce an exact match? The softer one gives more nuance-how close did the output come to the gold answer? We use both because outcomes are often phrased in multiple valid ways. For instance, a model might respond with “gouty arthritis” instead of “gout.” While a human evaluator could consider this partially acceptable, a strict string match would not. Combining exact and fuzzy scoring ensures a more accurate and fair assessment of model outputs. \n",
    "\n",
    "We build a helper function to preprend the examples with a system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_system_prompt_to_first_user_message(samples, system_prompt, path=None):\n",
    "    new_samples = []\n",
    "    for sample in samples:\n",
    "        # Deep copy to avoid mutating the original\n",
    "        sample_copy = json.loads(json.dumps(sample))\n",
    "        messages = sample_copy.get(\"messages\", [])\n",
    "        if messages and messages[0].get(\"role\") == \"user\" and isinstance(messages[0].get(\"content\"), str):\n",
    "            if not messages[0][\"content\"].startswith(system_prompt):\n",
    "                messages[0][\"content\"] = f\"{system_prompt}\\n\\n{messages[0]['content']}\"\n",
    "        new_samples.append(sample_copy)\n",
    "    if path is not None:\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in new_samples:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt = \"\"\"You are an expert clinician. For each clinical vignette, respond with exactly one phrase: the single most likely outcome or phenomenon, all in lowercase. \n",
    "- Do not add punctuation, articles, explanations, or commentary - output only the term itself.\n",
    "- Sometimes, the expected answer can be a synonym of what you think.\n",
    "- Use the standard clinical name (e.g. “thought withdrawal”, “Toxoplasma encephalitis”).\"\"\"\n",
    "train_samples_loaded_simple_sys_prompt = prepend_system_prompt_to_first_user_message(\n",
    "    train_samples_loaded, simple_prompt, path=\"data/medical_01_verifiable_problem_train_simple_prompt.jsonl\"\n",
    ")\n",
    "test_samples_loaded_simple_sys_prompt = prepend_system_prompt_to_first_user_message(\n",
    "    test_samples_loaded, simple_prompt, path=\"data/medical_01_verifiable_problem_val_simple_prompt.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then build a helper function to generate and store the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_model_predictions(\n",
    "    subset,\n",
    "    prompt_type,\n",
    "    model_name=\"o4-mini-2025-04-16\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    n_runs=1,\n",
    "    verbose=False,\n",
    "):\n",
    "    if isinstance(subset, str):\n",
    "        samples_path = f\"data/medical_01_verifiable_problem_{subset}_{prompt_type}_prompt.jsonl\"\n",
    "        with open(samples_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            test_samples = [json.loads(line) for line in f if line.strip()]\n",
    "    else:\n",
    "        test_samples = [subset]\n",
    "\n",
    "    def run_inference(item):\n",
    "        resp = client.responses.create(\n",
    "            model=model_name,\n",
    "            input=item[\"messages\"],\n",
    "            reasoning={\"effort\": reasoning_effort, \"summary\": \"detailed\"},\n",
    "        )\n",
    "        model_prediction = {'output_text': resp.output_text}\n",
    "        reasoning_tokens_used = resp.usage.output_tokens_details.reasoning_tokens\n",
    "        summaries = [seg.text for item in resp.output if item.type == \"reasoning\" for seg in item.summary]\n",
    "        summaries_string = \"\\n\".join(summaries)\n",
    "        if verbose:\n",
    "            print(\"Prompt: {}\".format(item[\"messages\"][0][\"content\"]))\n",
    "            print(f\"Model Sample: {model_prediction}\\nSolution: {item['reference_answer']}\\n\")\n",
    "        return {\n",
    "            \"model_prediction\": model_prediction[\"output_text\"],\n",
    "            \"input\": item,\n",
    "            \"reasoning_tokens_used\": reasoning_tokens_used,\n",
    "            \"reference_answer\": item[\"reference_answer\"],\n",
    "            \"summaries\": summaries_string\n",
    "        }\n",
    "\n",
    "    # Ensure the predictions directory exists before any file operations\n",
    "    predictions_dir = os.path.join(\"data\", \"rft\", \"predictions\")\n",
    "    os.makedirs(predictions_dir, exist_ok=True)\n",
    "\n",
    "    # Check if results already exist for all runs\n",
    "    results_per_run = []\n",
    "    for run_idx in range(n_runs):\n",
    "        run_save_path = os.path.join(\n",
    "            predictions_dir,\n",
    "            f\"{subset}_{prompt_type}_{model_name}_{reasoning_effort}_predictions_run{run_idx+1}.json\"\n",
    "        )\n",
    "        if os.path.exists(run_save_path):\n",
    "            print(f\"Results for run {run_idx+1} already exist at {run_save_path}. Loading results.\")\n",
    "            with open(run_save_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                run_results = json.load(f)\n",
    "            results_per_run.append(run_results)\n",
    "        else:\n",
    "            if len(test_samples) == 1:\n",
    "                run_results = [run_inference(test_samples[0])]\n",
    "            else:\n",
    "                run_results = []\n",
    "                with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                    futures = [executor.submit(run_inference, item) for item in test_samples]\n",
    "                    for future in tqdm(futures, total=len(futures), desc=f\"Generating predictions (run {run_idx+1})\"):\n",
    "                        result = future.result()\n",
    "                        run_results.append(result)\n",
    "                with open(run_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(run_results, f, ensure_ascii=False, indent=2)\n",
    "            results_per_run.append(run_results)\n",
    "\n",
    "    # Return a flat list for backward compatibility\n",
    "    if n_runs == 1:\n",
    "        return results_per_run[0]\n",
    "    else:\n",
    "        return results_per_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the predictions, first make sure your API key is set:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI o4-mini model\n",
    "results_simple_o4mini = generate_model_predictions(\n",
    "    subset=\"train\",\n",
    "    prompt_type=\"simple\",\n",
    "    model_name=\"o4-mini\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    n_runs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI o3 model\n",
    "results_simple_o3 = generate_model_predictions(\n",
    "    subset=\"train\",\n",
    "    prompt_type=\"simple\",\n",
    "    model_name=\"o3\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    n_runs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have predictions that are ready to be evaluated.<br>\n",
    "We'll build a helper function that allows us to easily swap in different scoring methods,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def evaluate_predictions_with_grader(\n",
    "    predictions,\n",
    "    grader_func=combined_grader,\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    if isinstance(predictions, dict):\n",
    "        predictions = [predictions]\n",
    "\n",
    "    def run_grading(pred):\n",
    "        model_prediction = {\"output_text\": pred[\"model_prediction\"]}\n",
    "        item = pred[\"input\"]\n",
    "        score = grader_func(model_prediction, item)\n",
    "        result = pred.copy()\n",
    "        result[\"score\"] = score\n",
    "        return result\n",
    "\n",
    "    if len(predictions) == 1:\n",
    "        result = run_grading(predictions[0])\n",
    "        results.append(result)\n",
    "    else:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(run_grading, pred) for pred in predictions]\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Grading predictions\"):\n",
    "                results.append(future.result())\n",
    "\n",
    "    total = len(results)\n",
    "    correct = sum(r[\"score\"] for r in results)\n",
    "    accuracy = correct / total if total else 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"total_samples\": total,\n",
    "        \"accuracy\": accuracy,\n",
    "    }\n",
    "    print(metrics)\n",
    "    return metrics, results\n",
    "\n",
    "def run_prediction_evaluation(\n",
    "    model_name=\"o4-mini\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    prompt_type=\"simple\",\n",
    "    subset=\"train\",\n",
    "    grader_func=combined_grader,\n",
    "    num_runs=3,\n",
    "):\n",
    "    if isinstance(grader_func, functools.partial):\n",
    "        name = grader_func.func.__name__\n",
    "        mg = grader_func.keywords[\"model_grader\"]\n",
    "        mg_name = mg[\"name\"]\n",
    "        name = f\"{name}_{mg_name}\"\n",
    "    else:\n",
    "        name = getattr(grader_func, \"__name__\", getattr(grader_func, \"__class__\", type(grader_func)).__name__)\n",
    "    grader_func_name = name.replace(\" \", \"_\").replace(\":\", \"_\").replace(\"/\", \"_\").replace(\",\", \"_\")\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        preds_path = f\"data/rft/predictions/{subset}_{prompt_type}_{model_name}_{reasoning_effort}_predictions_run{i+1}.json\"\n",
    "        with open(preds_path, \"r\") as f:\n",
    "            preds = json.load(f)\n",
    "        metrics, results_with_scores = evaluate_predictions_with_grader(preds, grader_func=grader_func)\n",
    "        # Save the scored results\n",
    "        with open(f\"data/rft/predictions/{subset}_{prompt_type}_{model_name}_{reasoning_effort}_{grader_func_name}_predictions_run_{i+1}_scored.json\", \"w\") as f:\n",
    "            json.dump(results_with_scores, f, indent=2)\n",
    "        # Save the metrics\n",
    "        with open(f\"data/rft/predictions/{subset}_{prompt_type}_{model_name}_{reasoning_effort}_{grader_func_name}_predictions_run_{i+1}_metrics.json\", \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        # Save the scores (if present in results_with_scores)\n",
    "        scores = [item.get(\"score\") for item in results_with_scores if \"score\" in item]\n",
    "        with open(f\"data/rft/predictions/{subset}_{prompt_type}_{model_name}_{reasoning_effort}_{grader_func_name}_predictions_run_{i+1}_scores.json\", \"w\") as f:\n",
    "            json.dump(scores, f, indent=2)\n",
    "\n",
    "def load_predictions(\n",
    "    model_name=\"o4-mini\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    prompt_type=\"simple\",\n",
    "    subset=\"train\",\n",
    "    grader_func_name=\"clinical_phrase_grader\",\n",
    "    num_runs=3\n",
    "):\n",
    "    all_predictions = []\n",
    "    all_metrics = []\n",
    "    for run in range(1, num_runs + 1):\n",
    "        pred_path = f\"data/rft/predictions/{subset}_{prompt_type}_{model_name}_{reasoning_effort}_{grader_func_name}_predictions_run_{run}_scored.json\"\n",
    "        metrics_path = f\"data/rft/predictions/{subset}_{prompt_type}_{model_name}_{reasoning_effort}_{grader_func_name}_predictions_run_{run}_metrics.json\"\n",
    "        try:\n",
    "            with open(pred_path, \"r\") as f:\n",
    "                predictions = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            predictions = None\n",
    "        try:\n",
    "            with open(metrics_path, \"r\") as f:\n",
    "                metrics = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            metrics = None\n",
    "        all_predictions.append(predictions)\n",
    "        all_metrics.append(metrics)\n",
    "    return all_predictions, all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then run the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:00<00:00, 610524.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.590985993228499}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:00<00:00, 311612.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.5750433490539723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:00<00:00, 769597.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.5943742483874717}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"o4-mini\"\n",
    "reasoning_effort = \"medium\"\n",
    "prompt_type = \"simple\"\n",
    "subset = \"train\"\n",
    "grader_func = combined_grader\n",
    "grader_func_name = \"combined_grader\"\n",
    "num_runs = 3\n",
    "run_prediction_evaluation(\n",
    "    model_name=model_name, \n",
    "    reasoning_effort=reasoning_effort, \n",
    "    prompt_type=prompt_type, \n",
    "    subset=subset, \n",
    "    grader_func=grader_func, \n",
    "    num_runs=num_runs\n",
    ")\n",
    "predictions_o4mini_medium_simple_prompt, metrics_o4mini_medium_simple_prompt = load_predictions(model_name=model_name, reasoning_effort=reasoning_effort, prompt_type=prompt_type, subset=subset, grader_func_name=grader_func_name, num_runs=num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the results allows us to spot trends and failure modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total mistakes: 86\n",
      "\n",
      "[Sample 18]\n",
      "  Model prediction: acute anterior uveitis\n",
      "  Reference answer: recurring eye redness and pain\n",
      "  Score: 0.3596153846153846\n",
      "\n",
      "[Sample 19]\n",
      "  Model prediction: 390 meq\n",
      "  Reference answer: 150 meq\n",
      "  Score: 0.6071428571428571\n",
      "\n",
      "[Sample 20]\n",
      "  Model prediction: adamts13 deficiency\n",
      "  Reference answer: decreased adamts13 activity in serum\n",
      "  Score: 0.5037037037037037\n",
      "\n",
      "[Sample 22]\n",
      "  Model prediction: todd paralysis\n",
      "  Reference answer: seizure\n",
      "  Score: 0.16190476190476194\n",
      "\n",
      "[Sample 23]\n",
      "  Model prediction: hypokalemia\n",
      "  Reference answer: hypomagnesemia\n",
      "  Score: 0.612\n"
     ]
    }
   ],
   "source": [
    "# Print mistakes where the model did not get the correct answer (score < 1.0)\n",
    "mistakes = [\n",
    "    {\"index\": i, **res}\n",
    "    for i, res in enumerate(predictions_o4mini_medium_simple_prompt[0])\n",
    "    if res[\"score\"] < 1.0\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal mistakes: {len(mistakes)}\")\n",
    "for m in mistakes[15:20]:\n",
    "    print(f\"\\n[Sample {m['index']}]\")\n",
    "    print(f\"  Model prediction: {m['model_prediction']}\")\n",
    "    print(f\"  Reference answer: {m['reference_answer']}\")\n",
    "    print(f\"  Score: {m['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, typical failure modes fall into three categories:\n",
    "1. Small differences and formatting issues, score >=0.8.\n",
    "2. Partial lexical match, 0.3 < score < 0.8.\n",
    "3. Lexically off-base, score < 0.3.\n",
    "\n",
    "We can visualize the full score distribution on the training set.\n",
    "\n",
    "> Note: In practice, analyzing model errors at scale often involves a mix of manual review and automated methods-like tagging failure types or clustering predictions by score and content. That workflow is beyond the scope of this guide, but it's a valuable next step once you've identified broad patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x125f6b7a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "scores_distribution = [m['score'] for m in predictions_o4mini_medium_simple_prompt[0]]\n",
    "plt.hist(scores_distribution, alpha=0.6, label='o4-mini medium simple prompt')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with other models and prompts, and visualize scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:00<00:00, 820803.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.6186850707880021}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:00<00:00, 523633.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.6149897683385446}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:00<00:00, 515270.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.6254662232084496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# OpenAI o3 model\n",
    "model_name = \"o3\"\n",
    "reasoning_effort = \"medium\"\n",
    "prompt_type = \"simple\"\n",
    "subset = \"train\"\n",
    "grader_func = combined_grader\n",
    "grader_func_name = \"combined_grader\"\n",
    "num_runs = 3\n",
    "run_prediction_evaluation(model_name=model_name, reasoning_effort=reasoning_effort, prompt_type=prompt_type, subset=subset, grader_func=grader_func, num_runs=num_runs)\n",
    "predictions_o3_medium_simple_prompt, metrics_o3_medium_simple_prompt = load_predictions(model_name=model_name, reasoning_effort=reasoning_effort, prompt_type=prompt_type, subset=subset, grader_func_name=grader_func_name, num_runs=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def average_and_std_metrics(metrics_list):\n",
    "    \"\"\"Returns dicts of mean and std for a list of metrics dicts.\"\"\"\n",
    "    if not metrics_list: return {}, {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    arr = {k: np.array([m[k] for m in metrics_list]) for k in keys}\n",
    "    mean = {k: float(np.mean(arr[k])) for k in keys}\n",
    "    std = {k: float(np.std(arr[k])) for k in keys}\n",
    "    return mean, std\n",
    "\n",
    "def plot_model_accuracies(model_metrics_avg, model_metrics_std, grader_title=\"Combined Grader Accuracy\", sharey: bool = True) -> None:\n",
    "    \"\"\"Plots model accuracies with standard deviation error bars.\"\"\"\n",
    "    # Convert the nested dicts into tidy DataFrames\n",
    "    df_avg = pd.DataFrame(model_metrics_avg).T.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "    df_std = pd.DataFrame(model_metrics_std).T.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "\n",
    "    # Long-form for Seaborn\n",
    "    long_df_avg = df_avg.melt(id_vars=\"Model\", value_vars=[\"accuracy\"], var_name=\"Metric\", value_name=\"Accuracy\")\n",
    "    long_df_std = df_std.melt(id_vars=\"Model\", value_vars=[\"accuracy\"], var_name=\"Metric\", value_name=\"Std\")\n",
    "\n",
    "    # Merge avg and std for error bars\n",
    "    long_df = pd.merge(long_df_avg, long_df_std, on=[\"Model\", \"Metric\"])\n",
    "\n",
    "    pretty_names = {\"accuracy\": grader_title}\n",
    "\n",
    "    # Create a separate figure for each metric\n",
    "    for metric_key in [\"accuracy\"]:\n",
    "        metric_df = long_df[long_df[\"Metric\"] == metric_key].copy()\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        # Plot bars with error bars\n",
    "        ax = sns.barplot(data=metric_df, x=\"Model\", y=\"Accuracy\", hue=\"Model\", palette=\"tab10\", legend=False, errorbar=None)\n",
    "        bars = ax.patches\n",
    "        # Add error bars manually\n",
    "        for i, row in enumerate(metric_df.itertuples()):\n",
    "            bar = bars[i]\n",
    "            x = bar.get_x() + bar.get_width() / 2\n",
    "            y = row.Accuracy\n",
    "            yerr = row.Std\n",
    "            ax.errorbar(x=x, y=y, yerr=yerr, fmt='none', ecolor='black', capsize=5, elinewidth=2, capthick=2, zorder=10)\n",
    "        plt.title(pretty_names[metric_key])\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"\")\n",
    "        if sharey: plt.ylim(0, 1)\n",
    "        # Annotate bars with exact values\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f\"{height:.2f}\", xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 6), textcoords=\"offset points\", ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        plt.xticks(rotation=15, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_metrics_o4mini_medium_simple_prompt, std_metrics_o4mini_medium_simple_prompt = average_and_std_metrics(metrics_o4mini_medium_simple_prompt)\n",
    "avg_metrics_o3_medium_simple_prompt, std_metrics_o3_medium_simple_prompt = average_and_std_metrics(metrics_o3_medium_simple_prompt)\n",
    "model_metrics_avg = {\n",
    "    \"o4-mini-medium-simple-prompt\": avg_metrics_o4mini_medium_simple_prompt,\n",
    "    \"o3-medium-simple-prompt\": avg_metrics_o3_medium_simple_prompt,\n",
    "}\n",
    "model_metrics_std = {\n",
    "    \"o4-mini-medium-simple-prompt\": std_metrics_o4mini_medium_simple_prompt,\n",
    "    \"o3-medium-simple-prompt\": std_metrics_o3_medium_simple_prompt,\n",
    "}\n",
    "plot_model_accuracies(model_metrics_avg, model_metrics_std, grader_title=\"Combined Grader Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the modelʼs performance has clear limits. In practice, iterating on the prompt often helps boost baseline results and get more out of the base model. However, in this case, our prompt engineering didnʼt lead to meaningful improvements-so we excluded those runs from the analysis.\n",
    "\n",
    "\n",
    "A key requirement for RFT to work is that the base model demonstrates it can successfully complete the task for at least some examples right out of the gate. The initial accuracy of ~0.6 is a strong signal that RFT can boost performance. If the model never succeeds on your tasks, there is no training signal to hill climb on.\n",
    "\n",
    "\n",
    "This evaluation process prepares us for the next step: guiding the model with structured, high-quality feedback from a grader.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **4. Defining Your Grader**\n",
    "\n",
    "The grader defines the reward function that shapes model behavior during RFT. It provides examples of desired outputs-and penalizes undesirable ones. Designing an effective grader requires both principled structure and thoughtful domain insight, and is perhaps the most important task for successful RFT. \n",
    "\n",
    "In this section, we will present 3 graders, show how they should be set up to fit the API, and discuss the results they yielded. We will then show how to actually launch an RFT task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String based grader\n",
    "We began with a dual grader using our earlier evaluation functions since it provides a distribution of scores that will be aligned with the lexical proximity of the prediction to the reference answer. It provided a starting point, but the signal wasnʼt rich enough for `o4-mini` to truly learn and improve, and a first experiment showed stagnant reward during the RFT run. For the API calls, you should build the python grading function as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# --- Utility functions ---\n",
    "def build_python_grader_payload(grader_fn) :\n",
    "    \"\"\"Build a payload for a python grader.\"\"\"\n",
    "    grader_source = inspect.getsource(grader_fn)\n",
    "    # Enforce function name to be `grade`\n",
    "    grader_source = grader_source.replace(grader_fn.__name__, \"grade\", 1)\n",
    "    return {\n",
    "        \"type\": \"python\",\n",
    "        \"source\": grader_source,\n",
    "    }\n",
    "\n",
    "multi_python_grader_tool_call = {\n",
    "    \"type\": \"multi\",\n",
    "    \"graders\": {\n",
    "        \"clinical_phrase\": {\n",
    "            \"name\": \"clinical_phrase_grader\",\n",
    "            \"image_tag\": \"2025-05-08\",\n",
    "            **build_python_grader_payload(clinical_phrase_grader),\n",
    "        },\n",
    "        \"clinical_phrase_binary\": {\n",
    "            \"name\": \"clinical_phrase_binary_grader\",\n",
    "            \"image_tag\": \"2025-05-08\",\n",
    "            **build_python_grader_payload(clinical_phrase_binary_grader),\n",
    "        },\n",
    "    },\n",
    "    \"calculate_output\": \"0.85 * clinical_phrase + 0.15 * clinical_phrase_binary\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a snapshot of its training curves, where the green curve is the traning set reward and the blue curve is the test set reward:\n",
    "\n",
    "![RFT String Grader](../images/rft_string_grader.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Grader 1\n",
    "To address this limitation, we introduced a more advanced approach: the **model grader**. A model-based grader lets us embed semantic understanding and nuance into the feedback. Thatʼs especially powerful when domain-specific synonyms or fuzzy reasoning are in play. \n",
    "\n",
    "We used gpt-4.1 as our grader model, guided by a rubric that emphasized semantic fidelity: clinical synonymy, correct disease categorization, and conceptual alignment. Rather than focusing on superficial phrasing-e.g., \"Is this the same string?\"-the grader aimed to answer, \"Does this reflect the correct outcome or phenomenon?\" \n",
    "\n",
    "To ensure the grader aligned with expert expectations, we evaluated it on a subset of base model predictions. For any production use-case, domain expert reviewers should verify that model assigned scores reflect preferred answer orderings and align with domain judgment. This typically involves confirming that the model grader correctly ranks predictions according to their validity. In the scope of this cookbook, we approximated this evaluation by using OpenAI `o3` to check whether higher-quality predictions were consistently rewarded relative to their alternatives.\n",
    "\n",
    "From these discussions of `o3` , we iteratively update the model grader until the results are aligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_PROMPT_1 = \"\"\"\n",
    "System:\n",
    "  You are an expert medical grader. Compare the **Reference Answer** to the **Model's Answer** and produce **only** a JSON object with:\n",
    "    • **result**: a float between 0.0 and 1.0  \n",
    "    • **steps**: a list of reasoning steps (each with a `\"description\"` and a `\"conclusion\"`)\n",
    "\n",
    "  Scoring rubric (start at 0.0, then add or subtract):\n",
    "    1. Exact lexical match: **+0.15**  \n",
    "    2. Clinical synonym (e.g. “withdrawal of thought” ↔ “thought withdrawal”): **+0.35**  \n",
    "    3. Same disease family (e.g. two viral encephalitides): **+0.35**  \n",
    "    4. Partial term overlap (e.g. “ulcer” in both phrases): **+0.15**  \n",
    "    5. Completely unrelated: **-0.10**\n",
    "\n",
    "  • If multiple criteria apply, sum their weights (max 1.0).  \n",
    "  • Cap the final score to the [0.0, 1.0] range.  \n",
    "  • In your **steps**, show which rule you applied and the running subtotal.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be submitted through the API, this is how the dictionary is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grader_1 = {\n",
    "   \"type\": \"score_model\",\n",
    "   \"name\": \"gpt41_score_model_1\",\n",
    "   \"input\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": GRADER_PROMPT_1\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Reference Answer: {{item.reference_answer}}. Model's Answer: {{sample.output_text}}\"\n",
    "        }\n",
    "   ],\n",
    "   \"pass_threshold\": 0.75,\n",
    "   \"model\": \"gpt-4.1-2025-04-14\",\n",
    "   \"range\": [0, 1],\n",
    "   \"sampling_params\": {\n",
    "       \"seed\": 42,\n",
    "       \"temperature\": 0,\n",
    "   },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, we set up the model grader locally to check the results of the models we will fine-tune next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_format = {\n",
    "  \"name\": \"float_score_classification\",\n",
    "  \"strict\": True,\n",
    "  \"schema\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"steps\": {\n",
    "        \"type\": \"array\",\n",
    "        \"description\": \"A sequence of steps outlining the reasoning process.\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"description\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"Detailed description of the reasoning in this step.\"\n",
    "            },\n",
    "            \"conclusion\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The conclusion of the reasoning in this step.\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"description\", \"conclusion\"],\n",
    "          \"additionalProperties\": False\n",
    "        }\n",
    "      },\n",
    "      \"result\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"The float score assigned to the response. This should be in inclusive range RANGE_MIN to RANGE_MAX.\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"steps\", \"result\"],\n",
    "    \"additionalProperties\": False\n",
    "  }\n",
    "}\n",
    "\n",
    "# for completions\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": response_format\n",
    "}\n",
    "\n",
    "# Adapted python_model_grader to match the other graders' interface\n",
    "def python_model_grader(sample, item, model_grader=model_grader_1):\n",
    "    \"\"\"\n",
    "    Calls an OpenAI model to grade the model output against the reference answer.\n",
    "    Expects sample to have \"output_text\", item to have \"reference_answer\".\n",
    "    Returns a float score (parsed from the model's JSON response).\n",
    "    \"\"\"\n",
    "    # Prepare the prompt as the grader expects\n",
    "    system_prompt = model_grader[\"input\"][0][\"content\"]\n",
    "    user_prompt = model_grader[\"input\"][1][\"content\"]\n",
    "    user_prompt_filled = user_prompt.replace(\"{{item.reference_answer}}\", item[\"reference_answer\"]).replace(\"{{sample.output_text}}\", sample[\"output_text\"])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_filled}\n",
    "    ]\n",
    "    # Call the OpenAI API with the grader's model\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_grader[\"model\"],\n",
    "        messages=messages,\n",
    "        seed=model_grader.get(\"sampling_params\", {}).get(\"seed\", None),\n",
    "        temperature=model_grader.get(\"sampling_params\", {}).get(\"temperature\", 0),\n",
    "        response_format=response_format,\n",
    "    )\n",
    "    # Parse the float score from the model's JSON response\n",
    "    parsed = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    return float(parsed[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the rubric initially delivered sensible feedback, the model soon uncovered a loophole and began **reward-hacking**. Scores shot up-sometimes by 20-30 percentage points-not because clinical accuracy improved but because the model padded its “one phrase” answers with synonyms, doses, and full management plans. You might see `begin warfarin therapy **and** continue unfractionated heparin for ≥5 days, overlapping until the INR is in the therapeutic range (2–3)` or `chewable aspirin 325 mg stat plus nitroglycerin…` instead of the required `continue unfractionated heparin` or `aspirin` respectively. Although the system prompt is explicit-*“respond with exactly one phrase: the single most likely outcome or phenomenon”*-these verbose outputs inflate *lexical_similarity* scores without precisely adding prediction value. This experience highlights the need to continuously inspect model outputs and remain vigilant for reward-hacking behaviours that can quietly distort evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a snapshot of its training curves (green is training reward, blue is test reward):\n",
    "\n",
    "![RFT Model Hacking](../images/rft_hacking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Grader 2\n",
    "To mitigate this reward-hack, we refined the grader prompt by clarifying expectations, enforcing stricter output constraints, and supplying contrastive examples of correct versus incorrect behavior. Once again, we've iterated with `o3`, leveraging predictions from the base `o4-mini` and the previous fine-tuned model hacking examples, to design and validate our grader. Another important point of this updated grader is the reduction of the weight of the *lexical_similarity*, to ensure that *clinical_similarity* prevails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_PROMPT_2 = \"\"\"You are an expert medical grader.\n",
    "\n",
    "Compare the reference_answer (gold standard) with the model_prediction\n",
    "and return **exactly** this JSON object:\n",
    "\n",
    "{\n",
    "  \"steps\": [            // each: {\"description\": \"...\", \"conclusion\": \"...\"}\n",
    "    …\n",
    "  ],\n",
    "  \"result\": <float 0-1 rounded to 3 decimals>\n",
    "}\n",
    "\n",
    "──────────────── Input placeholders ───────────────\n",
    "reference_answer:\n",
    "model_prediction:\n",
    "\n",
    "──────────── Normalisation steps ────────────\n",
    "• lowercase, strip punctuation / excess whitespace  \n",
    "• expand common abbreviations (e.g. cll → chronic lymphocytic leukemia)  \n",
    "• map both strings to ICD-10 / SNOMED concepts when possible\n",
    "\n",
    "──────────── Clinical layer rubric ───────────\n",
    "L1  exact concept or universally accepted synonym  \n",
    "L2  same concept but benign modifier differs (e.g. “acute”, “left”)  \n",
    "L3  same disease / drug family but wrong subtype or variant  \n",
    "L4  same organ system but entirely different disease / intervention  \n",
    "L5  only partial mechanistic overlap (e.g. both vasodilators)  \n",
    "L6  unrelated or nonsensical\n",
    "\n",
    "──────────── Scoring parameters ─────────────\n",
    "clinical_weight  = 0.90\n",
    "lexical_weight   = 0.10\n",
    "clinical_similarity = {1:1.00, 2:0.85, 3:0.45, 4:0.30, 5:0.10, 6:0.00}\n",
    "\n",
    "lexical_similarity = normalized_levenshtein(reference_answer,\n",
    "                                            model_prediction)\n",
    "\n",
    "# Optional penalty if a clinically critical adjective is missing\n",
    "critical_modifiers = [\n",
    "  \"wide\", \"narrow\", \"acute\", \"chronic\", \"posteromedial\",\n",
    "  \"oxidized\", \"oxidised\", \"left\", \"right\"\n",
    "]\n",
    "modifier_pen = -0.05 if any(\n",
    "    w in reference_answer and w not in model_prediction\n",
    "    for w in critical_modifiers\n",
    ") else 0.0\n",
    "\n",
    "# Determine layer L (1-6) per rubric above using ontology + judgment.\n",
    "if L == 6:\n",
    "    score = 0.0\n",
    "else:\n",
    "    score = (clinical_weight * clinical_similarity[L] +\n",
    "             lexical_weight  * lexical_similarity) + modifier_pen\n",
    "\n",
    "Clamp to [0,1] and round to 3 decimals.  \n",
    "Output **only** the JSON.\n",
    "\n",
    "──────────────── Worked examples ─────────────\n",
    "reference_answer: beta-thalassemia major  \n",
    "model_prediction: beta-thalassemia minor  \n",
    "reasoning: Both involve β-globin chain synthesis, but “major” causes\n",
    "          transfusion-dependent anemia while “minor” is largely benign;\n",
    "          same family, wrong subtype → **L3**. Lexical ≈ 0.83.  \n",
    "score = 0.90·0.45 + 0.10·0.83 = 0.488 → **0.488**\n",
    "\n",
    "reference_answer: ACE inhibitor  \n",
    "model_prediction: angiotensin-receptor blocker  \n",
    "reasoning: Both act on the renin–angiotensin axis yet on different\n",
    "          targets; only partial mechanistic overlap → **L5**.\n",
    "          Lexical ≈ 0.31.  \n",
    "score = 0.90·0.10 + 0.10·0.31 = 0.121 → **0.121**\n",
    "\n",
    "reference_answer: acute pancreatitis  \n",
    "model_prediction: pancreatitis  \n",
    "reasoning: Same disorder but missing timing adjective “acute”;\n",
    "          benign modifier difference → **L2**. Lexical ≈ 0.78.  \n",
    "score = 0.90·0.85 + 0.10·0.78 = 0.843 → **0.843**\n",
    "\n",
    "reference_answer: valproate  \n",
    "model_prediction: valproic acid  \n",
    "reasoning: Valproic acid is the active moiety of valproate; mechanisms\n",
    "          and indications are identical → **L1**. Lexical ≈ 0.82.  \n",
    "score = 0.90·1.00 + 0.10·0.82 = 0.982 → **0.982**\n",
    "\n",
    "reference_answer: riboflavin  \n",
    "model_prediction: riboflavin deficiency  \n",
    "reasoning: Adds “deficiency” but refers to the same vitamin (B₂);\n",
    "          benign modifier difference → **L2**. Lexical ≈ 0.60.  \n",
    "score = 0.90·0.85 + 0.10·0.60 = 0.825 → **0.825**\n",
    "\n",
    "reference_answer: splenectomy  \n",
    "model_prediction: acetaminophen overdose  \n",
    "reasoning: Surgical removal of the spleen has no mechanistic or anatomic\n",
    "          relationship to toxic drug ingestion → **L6**.  \n",
    "score = **0.000**\n",
    "\n",
    "reference_answer: ulcerative colitis  \n",
    "model_prediction: Crohn disease  \n",
    "reasoning: Both are inflammatory-bowel diseases but differ in location,\n",
    "          histology and management; same organ system, different disease\n",
    "          → **L4**. Lexical ≈ 0.38.  \n",
    "score = 0.90·0.30 + 0.10·0.38 = 0.308 → **0.308**\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grader_2 = {\n",
    "   \"type\": \"score_model\",\n",
    "   \"name\": \"gpt41_score_model_2\",\n",
    "   \"input\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": GRADER_PROMPT_2\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Reference Answer: {{item.reference_answer}}. Model's Answer: {{sample.output_text}}\"\n",
    "        }\n",
    "   ],\n",
    "   \"pass_threshold\": 0.75,\n",
    "   \"model\": \"gpt-4.1-2025-04-14\",\n",
    "   \"range\": [0, 1],\n",
    "   \"sampling_params\": {\n",
    "       \"seed\": 42,\n",
    "       \"temperature\": 0,\n",
    "   },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The final result was a high-signal, domain-sensitive grader that guided the model toward more appropriate and concise predictions.\n",
    "\n",
    "**Note on cost:** LLM graders incur token usage charges in addition to training compute. To manage costs effectively, we recommend:\n",
    "1. Testing your grader locally on base model completions (and optionally synthetic ones) to ensure it aligns with your rubric or human preferences. When available, use [flex processing](https://platform.openai.com/docs/guides/flex-processing) for more efficient evaluation.\n",
    "2. Starting with a small-scale RFT run to validate grader alignment and detect potential reward-hacking before scaling up.\n",
    "\n",
    "Let's look at how to launch the training in the next step!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **5. Training**\n",
    "\n",
    "Once your prompt and grader are finalized, you can proceed to training. This section shows how to launch RFT using your final grader-but naturally, you would have already run similar commands when experimenting with earlier grader versions to evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure the grader passed API test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grader validated\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "# Validate a grader configuration for fine-tuning\n",
    "payload = {\"grader\": model_grader_2}\n",
    "try:\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/fine_tuning/alpha/graders/validate\",\n",
    "        json=payload,\n",
    "        headers=HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Grader validated\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error validating grader: {e}\")\n",
    "    if 'response' in locals():\n",
    "        print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and upload the training and test sets to the OpenAI file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file detected: data/medical_01_verifiable_problem_train_simple_prompt.jsonl\n",
      "Uploading file: data/medical_01_verifiable_problem_train_simple_prompt.jsonl\n",
      "File uploaded successfully. File ID: file-19L9jKsJXNJ17DtjvPwN3M\n",
      "test file detected: data/medical_01_verifiable_problem_val_simple_prompt.jsonl\n",
      "Uploading file: data/medical_01_verifiable_problem_val_simple_prompt.jsonl\n",
      "File uploaded successfully. File ID: file-78q2N1QAMKhLiRK3zVB6MC\n"
     ]
    }
   ],
   "source": [
    "# Set your training and test file paths\n",
    "train_file = \"data/medical_01_verifiable_problem_train_simple_prompt.jsonl\"\n",
    "test_file = \"data/medical_01_verifiable_problem_val_simple_prompt.jsonl\"\n",
    "\n",
    "def upload_file(file_path: str) -> str:\n",
    "    \"\"\"Upload a file to the OpenAI platform for fine-tuning.\"\"\"\n",
    "    print(f\"Uploading file: {file_path}\")\n",
    "    with open(file_path, 'rb') as f:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/files\",\n",
    "            headers=HEADERS,\n",
    "            files={\"file\": f},\n",
    "            data={\"purpose\": \"fine-tune\"}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        file_id = response.json()[\"id\"]\n",
    "        print(f\"File uploaded successfully. File ID: {file_id}\")\n",
    "        return file_id\n",
    "\n",
    "train_file_id = train_file\n",
    "if train_file.endswith(\"jsonl\"):\n",
    "    print(f\"Training file detected: {train_file}\")\n",
    "    train_file_id = upload_file(train_file)\n",
    "test_file_id = test_file\n",
    "if test_file and test_file.endswith(\"jsonl\"):\n",
    "    print(f\"test file detected: {test_file}\")\n",
    "    test_file_id = upload_file(test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the hyper-parameters for our run. We will be fine-tuning `o4-mini`, with the `medium` reasoning effort. This parameter will impact the duration by limiting the number of tokens the model uses to reason. We tune with a moderate compute multiplier and reasonable number of epochs, prioritizing efficiency and fast iteration. Additionally, we set the `eval_samples` parameter to 3 to make the validation curves more robust given the stochasticity of `o4-mini`’s outputs. Averaging across multiple samples reduces noise and helps reveal consistent patterns of learning.\n",
    "\n",
    "You’ll want to tailor these depending on your budget, desired generalization, and dataset difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model and other parameters\n",
    "model = \"o4-mini-2025-04-16\"\n",
    "suffix = \"medical_01_verifiable_problem_gpt41_grader\"\n",
    "reasoning_effort = \"medium\"\n",
    "n_epochs = 5\n",
    "seed = 42\n",
    "grader = model_grader_2\n",
    "response_format_predictions = None\n",
    "compute_multiplier = 1.0\n",
    "eval_samples = 3\n",
    "eval_interval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to launch the run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job created with ID: ftjob-tt3B7l45hLUoaXGJRfoL1lLT\n",
      "View the job details at: https://platform.openai.com/finetune/ftjob-tt3B7l45hLUoaXGJRfoL1lLT\n"
     ]
    }
   ],
   "source": [
    "# Launch the RFT job\n",
    "payload = dict(\n",
    "    training_file=train_file_id,\n",
    "    validation_file=test_file_id,\n",
    "    model=model,\n",
    "    suffix=suffix,\n",
    "    method=dict(\n",
    "        type=\"reinforcement\",\n",
    "        reinforcement=dict(\n",
    "            grader=grader,\n",
    "            response_format=response_format_predictions,\n",
    "            hyperparameters=dict(\n",
    "                compute_multiplier=compute_multiplier,\n",
    "                eval_samples=eval_samples,\n",
    "                eval_interval=eval_interval,\n",
    "                n_epochs=n_epochs,\n",
    "                reasoning_effort=reasoning_effort,\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/fine_tuning/jobs\",\n",
    "        json=payload,\n",
    "        headers=HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    job_id = response.json().get(\"id\")\n",
    "    if job_id:\n",
    "        print(\"Training job created with ID:\", job_id)\n",
    "        print(\n",
    "            f\"View the job details at: https://platform.openai.com/finetune/{job_id}\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve job ID from response.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred while creating the training job: {e}\")\n",
    "    if 'response' in locals():\n",
    "        print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the [dashboard](https://platform.openai.com/finetune/) you can observe the reward plots - they let you watch overall performance improve across steps, while the per-grader charts break down specific components in the case of a *multi_grader*. Reasoning token usage trends (often decreasing as the model gets more confident) and step duration metrics give insight into efficiency. Grader latency and error count plots help ensure your grader stays performant and bug-free during the run.\n",
    "\n",
    "Here is a snapshot of our training curves, where the green and orange curves are for the training set, while tbe blue and red curves are for the test subset:\n",
    "\n",
    "![RFT Dashboard Example](../images/rft_dashboard_modelgrader2.png)\n",
    "\n",
    "During training, evaluation runs on the test set are logged directly to the [Evaluation API](https://platform.openai.com/evaluations?tab=runs). You can head there to track how your samples perform and get a sense of how predictions evolve over time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **6. Using Your Fine-Tuned Model**\n",
    "\n",
    "When training completes, you can call your new model by its `model_id` and benchmark its improvements. Expect sharper predictions! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve information about a fine-tuning job (including the fine-tuned model id), use the job_id:\n",
    "response = requests.get(\n",
    "    f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}\",\n",
    "    headers=HEADERS,\n",
    ")\n",
    "if response.ok:\n",
    "    data = response.json()\n",
    "    if data.get(\"status\") == \"succeeded\":\n",
    "        fine_tuned_model_id = data.get(\"fine_tuned_model\")\n",
    "    else:\n",
    "        fine_tuned_model_id = None\n",
    "else:\n",
    "    raise Exception(f\"Request failed: {response.status_code} - {response.text}\")\n",
    "print(\"Fine-tuned model id:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's prediction scores\n",
    "\n",
    "Let's compute the scores of our base and fine-tuned models for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions (run 1): 100%|██████████| 100/100 [01:16<00:00,  1.30it/s]\n",
      "Generating predictions (run 2): 100%|██████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "Generating predictions (run 3): 100%|██████████| 100/100 [01:07<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:22<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.7730899999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.7697499999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:19<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.78996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "model_name = fine_tuned_model_id\n",
    "reasoning_effort = \"medium\"\n",
    "prompt_type = \"simple\"\n",
    "subset = \"val\"\n",
    "grader_func = partial(python_model_grader, model_grader=model_grader_2)\n",
    "grader_func_name = \"python_model_grader_gpt41_score_model_2\"\n",
    "num_runs = 3\n",
    "\n",
    "results_ft_model_grader_2 = generate_model_predictions(\n",
    "    subset=subset,\n",
    "    prompt_type=prompt_type,\n",
    "    model_name=model_name,\n",
    "    reasoning_effort=reasoning_effort,\n",
    "    n_runs=num_runs\n",
    ")\n",
    "\n",
    "run_prediction_evaluation(\n",
    "    model_name=model_name, \n",
    "    reasoning_effort=reasoning_effort, \n",
    "    prompt_type=prompt_type, \n",
    "    subset=subset,\n",
    "    grader_func=grader_func, \n",
    "    num_runs=num_runs\n",
    ")\n",
    "predictions_ftmodel_medium_simple_prompt_model_grader_2, metrics_ftmodel_medium_simple_prompt_model_grader_2 = load_predictions(\n",
    "    model_name=model_name,\n",
    "    reasoning_effort=reasoning_effort,\n",
    "    prompt_type=prompt_type,\n",
    "    subset=subset,\n",
    "    grader_func_name=grader_func_name,\n",
    "    num_runs=num_runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions (run 1):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions (run 1): 100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n",
      "Generating predictions (run 2): 100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "Generating predictions (run 3): 100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n",
      "Grading predictions: 100%|██████████| 100/100 [00:19<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.72282}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:19<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.72807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:17<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.74812}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"o4-mini\"\n",
    "reasoning_effort = \"medium\"\n",
    "prompt_type = \"simple\"\n",
    "subset = \"val\"\n",
    "grader_func = partial(python_model_grader, model_grader=model_grader_2)\n",
    "grader_func_name = \"python_model_grader_gpt41_score_model_2\"\n",
    "num_runs = 3\n",
    "\n",
    "results_o4mini_model_grader_2 = generate_model_predictions(\n",
    "    subset=subset,\n",
    "    prompt_type=prompt_type,\n",
    "    model_name=model_name,\n",
    "    reasoning_effort=reasoning_effort,\n",
    "    n_runs=num_runs\n",
    ")\n",
    "run_prediction_evaluation(\n",
    "    model_name=model_name, \n",
    "    reasoning_effort=reasoning_effort, \n",
    "    prompt_type=prompt_type, \n",
    "    subset=subset,\n",
    "    grader_func=grader_func, \n",
    "    num_runs=num_runs\n",
    ")\n",
    "predictions_o4mini_medium_simple_prompt_model_grader_2, metrics_o4mini_medium_simple_prompt_model_grader_2 = load_predictions(\n",
    "    model_name=model_name,\n",
    "    reasoning_effort=reasoning_effort,\n",
    "    prompt_type=prompt_type,\n",
    "    subset=subset,\n",
    "    grader_func_name=grader_func_name,\n",
    "    num_runs=num_runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions (run 1):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions (run 1): 100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n",
      "Generating predictions (run 2): 100%|██████████| 100/100 [00:52<00:00,  1.90it/s]\n",
      "Generating predictions (run 3): 100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n",
      "Grading predictions: 100%|██████████| 100/100 [00:21<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.74015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:16<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.7515900000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading predictions: 100%|██████████| 100/100 [00:16<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_samples': 100, 'accuracy': 0.74235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"o3\"\n",
    "reasoning_effort = \"medium\"\n",
    "prompt_type = \"simple\"\n",
    "subset = \"val\"\n",
    "grader_func = partial(python_model_grader, model_grader=model_grader_2)\n",
    "grader_func_name = \"python_model_grader_gpt41_score_model_2\"\n",
    "num_runs = 3\n",
    "\n",
    "results_o3_model_grader_2 = generate_model_predictions(\n",
    "    subset=subset,\n",
    "    prompt_type=prompt_type,\n",
    "    model_name=model_name,\n",
    "    reasoning_effort=reasoning_effort,\n",
    "    n_runs=num_runs\n",
    ")\n",
    "run_prediction_evaluation(\n",
    "    model_name=model_name, \n",
    "    reasoning_effort=reasoning_effort, \n",
    "    prompt_type=prompt_type, \n",
    "    subset=subset,\n",
    "    grader_func=grader_func, \n",
    "    num_runs=num_runs\n",
    ")\n",
    "predictions_o3_medium_simple_prompt_model_grader_2, metrics_o3_medium_simple_prompt_model_grader_2 = load_predictions(\n",
    "    model_name=model_name,\n",
    "    reasoning_effort=reasoning_effort,\n",
    "    prompt_type=prompt_type,\n",
    "    subset=subset,\n",
    "    grader_func_name=grader_func_name,\n",
    "    num_runs=num_runs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_metrics_o4mini_medium_simple_prompt_model_grader_2, std_metrics_o4mini_medium_simple_prompt_model_grader_2 = average_and_std_metrics(metrics_o4mini_medium_simple_prompt_model_grader_2)\n",
    "avg_metrics_o3_medium_simple_prompt_model_grader_2, std_metrics_o3_medium_simple_prompt_model_grader_2 = average_and_std_metrics(metrics_o3_medium_simple_prompt_model_grader_2)\n",
    "avg_metrics_ftmodel_medium_simple_prompt_model_grader_2, std_metrics_ftmodel_medium_simple_prompt_model_grader_2 = average_and_std_metrics(metrics_ftmodel_medium_simple_prompt_model_grader_2)\n",
    "model_metrics_avg = {\n",
    "    \"o4-mini-medium-simple-prompt\": avg_metrics_o4mini_medium_simple_prompt_model_grader_2,\n",
    "    \"o3-medium-simple-prompt\": avg_metrics_o3_medium_simple_prompt_model_grader_2,\n",
    "    \"ftmodel-medium-simple-prompt\": avg_metrics_ftmodel_medium_simple_prompt_model_grader_2\n",
    "}\n",
    "model_metrics_std = {\n",
    "    \"o4-mini-medium-simple-prompt\": std_metrics_o4mini_medium_simple_prompt_model_grader_2,\n",
    "    \"o3-medium-simple-prompt\": std_metrics_o3_medium_simple_prompt_model_grader_2,\n",
    "    \"ftmodel-medium-simple-prompt\": std_metrics_ftmodel_medium_simple_prompt_model_grader_2\n",
    "}\n",
    "plot_model_accuracies(model_metrics_avg, model_metrics_std, grader_title=\"Model Grader 2 Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total mistakes: 84\n",
      "\n",
      "[Sample 9]\n",
      "  Model prediction: ventilation-perfusion scan\n",
      "  Reference answer: lung ventilation-perfusion scan\n",
      "  Score: 0.989\n",
      "\n",
      "[Sample 11]\n",
      "  Model prediction: autoimmune destruction of melanocytes (vitiligo)\n",
      "  Reference answer: autoimmune melanocyte destruction\n",
      "  Score: 0.991\n",
      "\n",
      "[Sample 12]\n",
      "  Model prediction: contrast enhanced computed tomography of the abdomen\n",
      "  Reference answer: ct abdomen\n",
      "  Score: 0.812\n",
      "\n",
      "[Sample 13]\n",
      "  Model prediction: unfractionated heparin\n",
      "  Reference answer: enoxaparin\n",
      "  Score: 0.428\n",
      "\n",
      "[Sample 15]\n",
      "  Model prediction: t cell–mediated delayed (type iv) hypersensitivity\n",
      "  Reference answer: th1-mediated cytotoxicity\n",
      "  Score: 0.932\n"
     ]
    }
   ],
   "source": [
    "# Print mistakes where the model did not get the correct answer (score < 1.0)\n",
    "mistakes = [\n",
    "    {\"index\": i, **res}\n",
    "    for i, res in enumerate(predictions_ftmodel_medium_simple_prompt_model_grader_2[0])\n",
    "    if res[\"score\"] < 1.0\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal mistakes: {len(mistakes)}\")\n",
    "for m in mistakes[5:10]:\n",
    "    print(f\"\\n[Sample {m['index']}]\")\n",
    "    print(f\"  Model prediction: {m['model_prediction']}\")\n",
    "    print(f\"  Reference answer: {m['reference_answer']}\")\n",
    "    print(f\"  Score: {m['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see about a 5-point boost in accuracy after fine-tuning. Looking at the first few errors, the model tends to harshly penalize answers that are close but not clinically identical-like *unfractionated heparin* vs. *enoxaparin*. It also dings longer answers, even when they’re correct, like *contrast enhanced computed tomography of the abdomen*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o4-mini-medium-simple-prompt bin counts: [ 2. 20. 13.  5. 60.]\n",
      "ftmodel-medium-simple-prompt bin counts: [ 3. 12.  9.  6. 70.]\n",
      "Max bin count (y-axis): 70.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_o4 = [p['score'] for p in predictions_o4mini_medium_simple_prompt_model_grader_2[0]]\n",
    "scores_ft = [p['score'] for p in predictions_ftmodel_medium_simple_prompt_model_grader_2[0]]\n",
    "\n",
    "# Determine common bins for both histograms\n",
    "all_scores = scores_o4 + scores_ft\n",
    "bins = plt.hist(all_scores, bins=5, alpha=0)[1]\n",
    "\n",
    "# Plot histograms and capture the counts\n",
    "counts_o4, _, _ = plt.hist(\n",
    "    scores_o4,\n",
    "    bins=bins,\n",
    "    alpha=0.6,\n",
    "    label='o4-mini-medium-simple-prompt'\n",
    ")\n",
    "counts_ft, _, _ = plt.hist(\n",
    "    scores_ft,\n",
    "    bins=bins,\n",
    "    alpha=0.6,\n",
    "    label='ftmodel-medium-simple-prompt'\n",
    ")\n",
    "\n",
    "plt.title(\"Model Grader 2 Score Distribution by Model\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.ylim(top=75)\n",
    "plt.legend()\n",
    "\n",
    "# Print the bin counts\n",
    "print(\"o4-mini-medium-simple-prompt bin counts:\", counts_o4)\n",
    "print(\"ftmodel-medium-simple-prompt bin counts:\", counts_ft)\n",
    "print(\"Max bin count (y-axis):\", max(max(counts_o4), max(counts_ft)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distruibution of scores, we observe that RFT helped shift the model’s predictions out of the mid-to-low score zone (0.2-0.6) and into the high range (0.8-1.0). Since the grader emphasizes clinical similarity over lexical match, this shift reflects stronger medical reasoning-not just better phrasing-according to our *expert* grader. As seen in the (0.0-0.1) range, a handful of already weak predictions fell even further, hinting at a residual knowledge gap.\n",
    "\n",
    "Note that, because the earlier `combined_grader` was designed to reward lexical correctness, its accuracy didnʼt improve much-which is expected. That gap reinforces why validating your model grader is critical, and why you should monitor for reward-hacking. In our case, we used `o3` to spot-check grading behavior, but domain expert review is essential. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's reasoning\n",
    "\n",
    "Another important point in the analysis of the fine-tuned model are the reasoning summaries. The model may provide key information throughout these summaries, and exploring them to understand where the model fails can drive updates in the model's and the grader's system prompts. Below, we show examples of such chain of thought summaries that the model produced to show its way of answering the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reasoning_tokens_used o4-mini: 404\n",
      "Mean reasoning_tokens_used o3: 384\n",
      "Mean reasoning_tokens_used ftmodel: 925\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of lists into a single list of dicts\n",
    "predictions = {\n",
    "    \"o4-mini\": predictions_o4mini_medium_simple_prompt_model_grader_2,\n",
    "    \"o3\": predictions_o3_medium_simple_prompt_model_grader_2,\n",
    "    \"ftmodel\": predictions_ftmodel_medium_simple_prompt_model_grader_2,\n",
    "}\n",
    "\n",
    "for model_name, predictions in predictions.items():\n",
    "    all_preds = [item for sublist in predictions for item in sublist]\n",
    "    reasoning_tokens = [p['reasoning_tokens_used'] for p in all_preds if 'reasoning_tokens_used' in p]\n",
    "    mean_reasoning_tokens = np.mean(reasoning_tokens)\n",
    "    print(f\"Mean reasoning_tokens_used {model_name}: {mean_reasoning_tokens:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuned model spends more reasoning tokens to think through the question. Let's visualize an example thanks to the reasoning summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Choosing imaging study**\n",
      "\n",
      "The user is looking for a single phrase regarding the imaging study for a 49-year-old male with chronic alcohol consumption and related symptoms. I'm considering whether to suggest a CT scan or MRI; however, a CT scan is often the initial choice for chronic pancreatitis. I’ll go with \"abdominal ct scan\" since it's standardized. I need to ensure I format it in lowercase without punctuation, following the user’s request. So the output is \"abdominal ct scan.\"\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "markdown_text = results_o4mini_model_grader_2[0][30][\"summaries\"]\n",
    "display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Considering imaging options**\n",
      "\n",
      "I'm analyzing the user's question about a 49-year-old male with symptoms suggesting steatorrhea, possibly indicating exocrine pancreatic insufficiency from chronic alcohol use. It raises concerns about chronic pancreatitis or pancreatic cancer. I think the best imaging choice is a contrast-enhanced CT scan of the abdomen because it effectively examines structural abnormalities. Alternatively, an endoscopic ultrasound could be more sensitive, but CT is generally preferred. So, my recommendation is to start with a contrast-enhanced CT scan.\n",
      "**Determining the appropriate imaging study**\n",
      "\n",
      "I'm analyzing the question about the most suitable imaging study for a patient with symptoms suggesting chronic pancreatitis. The standard approach for suspected chronic pancreatitis is a contrast-enhanced CT scan of the abdomen, as it effectively identifies pancreatic calcifications and structural changes. While MRCP and endoscopic ultrasound provide additional details, CT is often preferred as the initial test. Therefore, my answer should focus on recommending a \"contrast-enhanced abdominal CT\" as the next step in evaluation.\n"
     ]
    }
   ],
   "source": [
    "markdown_text = results_ft_model_grader_2[0][30][\"summaries\"]\n",
    "display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base `o4‑mini`’s reasoning zooms straight to “abdominal CT scan,” mostly worrying about lowercase formatting and giving only a cursory “often the initial choice” justification. The `finetuned model`, meanwhile, first links the patient’s steatorrhea and alcohol history to chronic pancreatitis or cancer, weighs CT against MRCP and EUS, and explains why a contrast‑enhanced abdominal CT best reveals calcifications and structural change. The latter seems more careful, and seems to have learnt to break down the case description even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To push the scores further\n",
    "Both the baseline `o3` and our fine-tuned `o4-mini` sometimes scored zero on the same samples-a red flag that the reference labels may be wrong. Before adding more compute, invest in data quality: have a domain expert relabel the noisy slice, analyze the model's reasoning, then tighten the grader prompt. Clean, trusted data and methodical updates almost always buys more accuracy than extra epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Conclusion**\n",
    "\n",
    "Weʼve looked at how to design graders that give `o4-mini` the kind of detailed feedback it needs during RFT. That signal is what helps the model actually learn and improve beyond the baseline. Model graders can be incredibly powerful for this-but only if theyʼre designed carefully. A sloppy grader or sloppy data can send the wrong signals and steer the model in the wrong direction. \n",
    "\n",
    "You're now ready to apply reinforcement fine-tuning on your own models using the OpenAI API. Weʼre excited to see how you push the boundaries of reasoning and tool use with custom graders and smarter model behavior!\n",
    "\n",
    "For troubleshooting or next steps, refer to the [OpenAI fine-tuning documentation](https://platform.openai.com/docs/guides/fine-tuning)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
