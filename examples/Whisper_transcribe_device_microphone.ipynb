{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Whisper API to Transcribe Text from Your Device Microphone\n",
        "\n",
        "The [Audio Whisper API](https://platform.openai.com/docs/guides/speech-to-text) is capable of translating and transcribing speech into written form. It is powered by OpenAI's [`large-v2 Whisper model`](https://github.com/openai/whisper).\n",
        "\n",
        "In this guide, we will record audio from your device's microphone and use the Audio Whisper API to transcribe it. This functionality is similar to clicking the microphone 🎙️ icon in ChatGPT (note that speech-to-text is not supported in [ChatGPT for Web](http://chatgpt.com)).\n",
        "\n",
        "![whisper_onChatGPTApp_cvk](../images/whisper_onChatGPTApp_cvk.gif)\n",
        "\n",
        "We'll be working with WAV files. Although larger than MP3, WAV files store audio in an uncompressed format, preserving audio quality, which can significantly improve the accuracy of transcription and translation.\n",
        "\n",
        "We will go through the following steps:\n",
        "\n",
        "1. **Recording:** Capture audio from your device microphone and store it in a temporary file.\n",
        "2. **Transcribing or Translating:** Use OpenAI's Whisper API to convert the audio to text (either transcribing English or translating other languages to English).\n",
        "3. **Copying:** Copy the transcribed/translated text to your clipboard.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Microphone Permissions](#microphone-permissions)\n",
        "2. [Setup](#setup)\n",
        "3. [Recording Audio](#recording-audio)\n",
        "4. [Transcribing and Translating Audio](#transcribing-and-translating-audio)\n",
        "5. [Copying to Clipboard](#copying-to-clipboard)\n",
        "6. [Main Function and Demos](#main-function-and-demos)\n",
        "7. [Troubleshooting](#troubleshooting)\n",
        "8. [FAQ](#faq)\n",
        "9. [Conclusion](#conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Microphone Permissions\n",
        "\n",
        "Before we start, ensure the necessary permissions to access the microphone.\n",
        "\n",
        "### For Windows\n",
        "\n",
        "1. Open **Settings**.\n",
        "2. Go to **Privacy > Microphone**.\n",
        "3. Ensure that \"Microphone access for this device\" is turned on.\n",
        "4. Ensure that your Python IDE is allowed to access the microphone.\n",
        "\n",
        "### For MacOS\n",
        "\n",
        "1. Open **System Preferences**.\n",
        "2. Go to **Security & Privacy > Privacy**.\n",
        "3. Select **Microphone** from the left-hand menu.\n",
        "4. Ensure that your Python IDE is checked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "We need several libraries to record and process audio:\n",
        "\n",
        "-   **pyaudio:** To capture audio from the microphone.\n",
        "-   **wave:** To handle .wav files.\n",
        "-   **tempfile:** To create temporary files for storing recordings.\n",
        "-   **simpleaudio:** To play back audio (for debugging).\n",
        "-   **openai:** To access the Whisper API.\n",
        "-   **pyperclip:** To copy text to the clipboard.\n",
        "-   **python-dotenv:** To load environment variables (for API keys)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install prerequisites (you may need to adjust these based on your OS):\n",
        "\n",
        "!brew install ffmpeg -q       # For audio processing\n",
        "!brew install portaudio -q    # For PyAudio support\n",
        "\n",
        "# Install Python packages:\n",
        "%pip install -q simpleaudio pyaudio wave pyperclip openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API Key Setup\n",
        "\n",
        "1. **Obtain an API key:** Get your API key from the [OpenAI website](https://platform.openai.com/account/api-keys).\n",
        "2. **Create a .env file:** In your project directory, create a file named `.env`.\n",
        "3. **Store your API key:** Add the following line to your `.env` file, replacing `your_actual_api_key_here` with your key:\n",
        "\n",
        "    ```\n",
        "    OPENAI_API_KEY=your_actual_api_key_here\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load the API key from the .env file\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recording Audio\n",
        "\n",
        "We'll create a `record_audio` function that handles audio recording. It will support both **timed recording** (for a specified duration) and **manual recording** (stopping when the user presses Enter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's break down the steps involved in the `record_audio` function:\n",
        "\n",
        "1. **Set Up Temporary File:**\n",
        "\n",
        "    *   A temporary file is created to store the recorded audio.\n",
        "    *   This file will be automatically deleted after it's no longer needed.\n",
        "\n",
        "    ```python\n",
        "    temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "    temp_file_name = temp_file.name\n",
        "    ```\n",
        "\n",
        "2. **Callback Function:**\n",
        "\n",
        "    *   The `callback` function is responsible for writing chunks of audio data to the temporary file as they are received from the microphone.\n",
        "\n",
        "    ```python\n",
        "    def callback(data_input, frame_count, time_info, status):\n",
        "        wav_file.writeframes(data_input)\n",
        "        return None, pyaudio.paContinue\n",
        "    ```\n",
        "\n",
        "3. **Record Audio:**\n",
        "\n",
        "    *   **Open a `.wav` file:** A new WAV file is opened in write-binary (\"wb\") mode to store the audio data.\n",
        "    *   **Set Audio Format:** The audio format is configured as follows:\n",
        "        *   **1 channel (mono):** Using a single channel (mono) is sufficient for speech recognition and reduces processing overhead.\n",
        "        *   **16-bit samples:** 16-bit samples offer a good balance between audio quality and file size.\n",
        "        *   **16000 Hz sample rate:** A 16kHz sample rate is commonly used in speech recognition because it captures the relevant frequency range of human speech while keeping file sizes manageable.\n",
        "    *   **Initialize PyAudio:** A PyAudio object is created to interface with the microphone.\n",
        "    *   **Start Recording:** The `audio.open()` function starts an audio stream, which continuously receives audio data from the microphone and passes it to the `callback` function for writing to the temporary file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "\n",
        "def record_audio(timed_recording=False, record_seconds=5):\n",
        "    \"\"\"Records audio from the microphone.\n",
        "\n",
        "    Args:\n",
        "        timed_recording (bool): If True, record for a fixed duration.\n",
        "        record_seconds (int): Duration of recording in seconds (if timed_recording is True).\n",
        "\n",
        "    Returns:\n",
        "        str: The path to the temporary audio file.\n",
        "    \"\"\"\n",
        "    temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "    temp_file_name = temp_file.name\n",
        "\n",
        "    def callback(data_input, frame_count, time_info, status):\n",
        "        \"\"\"Writes audio data to the temporary file.\"\"\"\n",
        "        wav_file.writeframes(data_input)\n",
        "        return (None, pyaudio.paContinue)\n",
        "\n",
        "    with wave.open(temp_file_name, \"wb\") as wav_file:\n",
        "        wav_file.setnchannels(1)  # Mono channel\n",
        "        wav_file.setsampwidth(2)  # 16-bit samples\n",
        "        wav_file.setframerate(16000)  # 16kHz sample rate\n",
        "\n",
        "        audio = pyaudio.PyAudio()\n",
        "        stream = audio.open(\n",
        "            format=pyaudio.paInt16,\n",
        "            channels=1,\n",
        "            rate=16000,\n",
        "            input=True,\n",
        "            frames_per_buffer=1024,\n",
        "            stream_callback=callback,\n",
        "        )\n",
        "\n",
        "        if timed_recording:\n",
        "            print(f\"Recording for {record_seconds} seconds...\")\n",
        "            time.sleep(record_seconds)\n",
        "        else:\n",
        "            input(\"Press Enter to stop recording...\")\n",
        "\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        audio.terminate()\n",
        "\n",
        "    return temp_file_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transcribing and Translating Audio\n",
        "\n",
        "Instead of combining both functionalities, we'll use separate functions for transcribing and translating to improve code clarity. We will also adjust the usage of the `prompt` parameter to make it more aligned with the API design - to be an example rather than an instruction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_audio_file(file_name, prompt=\"\"):\n",
        "    \"\"\"Transcribes an audio file using the Whisper API.\n",
        "\n",
        "    Args:\n",
        "        file_name (str): The path to the audio file.\n",
        "        prompt (str): An optional prompt to guide the transcription.\n",
        "\n",
        "    Returns:\n",
        "        str: The transcribed text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"rb\") as audio_file:\n",
        "            response = client.audio.transcriptions.create(\n",
        "                model=\"whisper-1\", file=audio_file, prompt=prompt\n",
        "            )\n",
        "            return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def translate_audio_file(file_name, prompt=\"\"):\n",
        "    \"\"\"Translates an audio file to English using the Whisper API.\n",
        "\n",
        "    Args:\n",
        "        file_name (str): The path to the audio file.\n",
        "        prompt (str): An optional prompt to guide the translation.\n",
        "\n",
        "    Returns:\n",
        "        str: The translated text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"rb\") as audio_file:\n",
        "            response = client.audio.translations.create(\n",
        "                model=\"whisper-1\", file=audio_file, prompt=prompt\n",
        "            )\n",
        "            return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during translation: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** You can use the `prompt` parameter to *guide* the transcription or translation. This is useful for various reasons, such as:\n",
        "\n",
        "*   **Spelling correction:** Providing correctly spelled words or names.\n",
        "*   **Language specification:** Indicating the language of the audio.\n",
        "*   **Acronym recognition:** Helping the model recognize specific acronyms.\n",
        "*   **Filler word control:** Influencing whether filler words are included or excluded.\n",
        "*   **Punctuation:** Guiding the model to use appropriate punctuation.\n",
        "\n",
        "For more information, refer to the [Audio Whisper API's reference on prompting](https://platform.openai.com/docs/guides/speech-to-text/prompting) or [prestontuggle's AI Cookbook Recipe](https://cookbook.openai.com/examples/whisper_prompting_guide)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Copying to Clipboard\n",
        "\n",
        "We'll use the `pyperclip` library to copy the transcribed or translated text to the clipboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyperclip\n",
        "\n",
        "\n",
        "def copy_to_clipboard(text):\n",
        "    \"\"\"Copies text to the clipboard.\"\"\"\n",
        "    if text:\n",
        "        pyperclip.copy(text)\n",
        "        print(\"Result copied to clipboard!\")\n",
        "    else:\n",
        "        print(\"Nothing to copy. Transcription/translation may have failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Function and Demos\n",
        "\n",
        "Here's the main `transcribe_audio` function that combines all the steps:\n",
        "\n",
        "1. Recording audio\n",
        "2. Transcribing or translating\n",
        "3. Copying the result to the clipboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import simpleaudio as sa\n",
        "import os\n",
        "\n",
        "\n",
        "def transcribe_audio(\n",
        "    debug: bool = False,\n",
        "    prompt: str = \"\",\n",
        "    timed_recording: bool = False,\n",
        "    record_seconds: int = 5,\n",
        "    is_english: bool = True,\n",
        ") -> str:\n",
        "    \"\"\"Records, transcribes/translates, and copies audio to clipboard.\n",
        "\n",
        "    Args:\n",
        "        debug (bool): If True, plays back the recorded audio.\n",
        "        prompt (str): A prompt to guide the transcription/translation.\n",
        "        timed_recording (bool): If True, record for a fixed duration.\n",
        "        record_seconds (int): Duration of recording in seconds.\n",
        "        is_english (bool): If True, transcribes; otherwise, translates to English.\n",
        "\n",
        "    Returns:\n",
        "        str: The transcribed or translated text.\n",
        "    \"\"\"\n",
        "    temp_file_name = record_audio(timed_recording, record_seconds)\n",
        "\n",
        "    if debug:\n",
        "        print(\"Playing back recorded audio...\")\n",
        "        playback = sa.WaveObject.from_wave_file(temp_file_name)\n",
        "        play_obj = playback.play()\n",
        "        play_obj.wait_done()\n",
        "\n",
        "    if is_english:\n",
        "        result = transcribe_audio_file(temp_file_name, prompt)\n",
        "    else:\n",
        "        result = translate_audio_file(temp_file_name, prompt)\n",
        "\n",
        "    os.remove(temp_file_name)\n",
        "    copy_to_clipboard(result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo 1: Transcribe English Speech\n",
        "\n",
        "This demo records 5 seconds of spoken English and transcribes it. The prompt provides an example of the desired output format. We will also adjust the prompt in the English transcription demo to reflect this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Demo: Transcribe 5 seconds of spoken English\n",
            "Recording for 5 seconds...\n",
            "Playing back recorded audio...\n",
            "Result copied to clipboard!\n",
            "\n",
            "Transcription: Supercalifragilisticexpialidocious, I assume Whisper cannot transcribe this, but let's see how it performs.\n"
          ]
        }
      ],
      "source": [
        "print(\"Demo: Transcribe 5 seconds of spoken English\")\n",
        "result = transcribe_audio(\n",
        "    debug=True,\n",
        "    prompt=\"This is a sample transcription of speech in English. The speaker is discussing technology and AI. Ensure the output uses proper grammar, punctuation, and complete sentences, similar to this example.\",\n",
        "    timed_recording=True,\n",
        "    record_seconds=5,\n",
        "    is_english=True,\n",
        ")\n",
        "print(\"\\nTranscription:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo 2: Translate Spanish Speech to English\n",
        "\n",
        "This demo records 5 seconds of spoken Spanish and translates it into English. The prompt guides the translation, and unlike before, sets a 5-second limit to the recording time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Demo: Transcribe 5 seconds of spoken Spanish and translate into English\n",
            "Recording for 5 seconds...\n",
            "Result copied to clipboard!\n",
            "\n",
            "Translation: Hello, my name is Carl, written with a C. I don't speak Spanish, but it's a pleasure to meet you.\n"
          ]
        }
      ],
      "source": [
        "print(\"Demo: Transcribe 5 seconds of spoken Spanish and translate into English\")\n",
        "result = transcribe_audio(\n",
        "    debug=False,\n",
        "    prompt=\"This is a translation of Spanish speech into English. The speaker is having a casual conversation. A sample translation would be: 'Hello, how are you doing today? I hope everything is going well.' Ensure the output uses proper grammar and punctuation.\",\n",
        "    timed_recording=True,\n",
        "    record_seconds=5,\n",
        "    is_english=False,\n",
        ")\n",
        "print(\"\\nTranslation:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "-   **Microphone not working:**\n",
        "    -   Check microphone connections and volume.\n",
        "    -   Ensure your application has microphone access permissions.\n",
        "-   **Audio quality issues:**\n",
        "    -   Record in a quiet environment.\n",
        "-   **Transcription/translation errors:**\n",
        "    -   Ensure the audio is clear.\n",
        "    -   Re-record if necessary.\n",
        "    -   Set `is_english` correctly.\n",
        "-   **API key issues:**\n",
        "    -   Verify your `.env` file is in the correct location and has the correct API key.\n",
        "\n",
        "### Advanced Troubleshooting\n",
        "\n",
        "-   **Debugging audio playback:**\n",
        "    -   Enable the `debug` parameter to listen to the recorded audio.\n",
        "-   **Handling large audio files:**\n",
        "    -   Consider splitting long recordings into smaller chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FAQ\n",
        "\n",
        "See Whisper Audio API's official FAQs [here](https://help.openai.com/en/articles/7031512-whisper-audio-api-faq).\n",
        "\n",
        "**Q: How can I improve the transcription accuracy?**\n",
        "\n",
        "-   Ensure the recording environment is quiet.\n",
        "-   Speak clearly and at a moderate pace.\n",
        "-   Use a high-quality microphone if possible.\n",
        "-   For English transcription, use the `prompt` parameter to provide context.\n",
        "\n",
        "**Q: Can I use this method to transcribe audio in other languages?**\n",
        "\n",
        "-   Yes, the Whisper model supports [multiple languages](https://platform.openai.com/docs/guides/speech-to-text/supported-languages). Set `is_english=False` to use the translation feature, which will translate non-English audio to English text.\n",
        "\n",
        "**Q: How do I choose between manual and timed recording?**\n",
        "\n",
        "-   Use `timed_recording=False` if you want to control the recording duration manually (press Enter to stop).\n",
        "-   Use `timed_recording=True` and set `record_seconds` to automatically stop recording after a specific duration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You have now learned how to create an audio transcription and translation tool using OpenAI's Whisper API. You can record audio from your device's microphone, transcribe English speech, translate other languages to English, and copy the results to your clipboard. Feel free to experiment further with the [API reference](https://platform.openai.com/docs/api-reference/audio) and modify the code to suit your needs!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
