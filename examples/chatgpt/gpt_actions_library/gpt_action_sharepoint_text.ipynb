{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Action Library: Sharepoint (Return as Document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page provides an instruction & guide for developers building a GPT Action for a specific application. Before you proceed, make sure to first familiarize yourself with the following information: \n",
    "- [Introduction to GPT Actions](https://platform.openai.com/docs/actions)\n",
    "- [Introduction to GPT Actions Library](https://platform.openai.com/docs/actions/actions-library)\n",
    "- [Example of Building a GPT Action from Scratch](https://platform.openai.com/docs/actions/getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution enables a GPT action to answer a user’s question with the context of files the user can access in SharePoint or Office365, using Microsoft’s Graph API [search capabilities](https://learn.microsoft.com/en-us/graph/api/resources/search-api-overview?view=graph-rest-1.0) and the ability to [retrieve files](https://learn.microsoft.com/en-us/graph/api/driveitem-get?view=graph-rest-1.0\\&tabs=http). It uses Azure Functions to process the Graph API response and convert it to a human readable format or structure it in a way ChatGPT understands. This code is meant to be directional, and you should modify it to your requirements.\n",
    "\n",
    "This solution pre-processes the file within the Azure Function. The Azure Function returns text, instead of the base64 encoded file. Due to the pre-processing and the conversion to text, this solution is best used for large, unstructured documents, and for when you want to analyze more than the amount of files supported in the first solution (see documentation [here](https://platform.openai.com/docs/actions/sending-files))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value + Example Business Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value**: Users can now leverage ChatGPT's natural language capability to connect directly to files in Sharpeoint\n",
    "\n",
    "**Example Use Cases**: \n",
    "- A user needs to look up which files relate to a certain topic\n",
    "- A user needs an answer to a critical question, buried deep in documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture / Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../images/solution_2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution uses a Node.js Azure Function to, based on the logged in user:\n",
    "\n",
    "1. Search for a relevant file that the user has access to, based on the user’s initial question.\n",
    "\n",
    "2. For each file that is found, convert it to a consistent readable format and retrieve all the text.\n",
    "\n",
    "3. Use GPT 4o mini (gpt-4o-mini) to extract the relevant text from the files based on the initial user’s question. Note the pricing of GPT 4o mini [here](https://openai.com/pricing#language-models) - since we are dealing with small token chunks, the cost of this step is nominal.  \n",
    "\n",
    "4. Returns that data to ChatGPT. The GPT then uses that information to respond to the user's initial question.\n",
    "\n",
    "As you can see from the below architecture diagram, the first three steps are the same as Solution 1. The main difference is that this solution converts the file to text instead of a base64 string, and then summarizes that text using GPT 4o mini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../images/solution_2_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Key Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out these links from the application before you get started:\n",
    "- Application Website: https://www.microsoft.com/en-us/microsoft-365/sharepoint/collaboration\n",
    "- Application API Documentation: https://learn.microsoft.com/en-us/previous-versions/office/developer/sharepoint-rest-reference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you get started, make sure you go through the following steps in your application environment:\n",
    "- Access to a Sharepoint environment \n",
    "- Postman (and knowledge of APIs and OAuth)\n",
    "- An OpenAI API Key from platform.openai.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middleware Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you follow the [search concept files guide](https://learn.microsoft.com/en-us/graph/search-concept-files), the [Microsoft Graph Search API](https://learn.microsoft.com/en-us/graph/search-concept-files) returns references to files that fit the criteria, but not the file contents themselves. Therefore, middleware is required, rather than hitting the MSFT endpoints directly.\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. loop through the returned files and download the files using the [Download File endpoint](https://learn.microsoft.com/en-us/graph/api/driveitem-get-content?view=graph-rest-1.0\\&tabs=http) or [Convert File endpoint](https://learn.microsoft.com/en-us/graph/api/driveitem-get-content-format?view=graph-rest-1.0\\&tabs=http)\n",
    "\n",
    "2. convert that Binary stream to human readable text using [pdf-parse](https://www.npmjs.com/package/pdf-parse)\n",
    "\n",
    "3. Then, we can optimize further by summarizing using gpt-4o-mini in the function to help with the 100,000 character limit we impose on Actions today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Azure Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up an Azure Function using the steps in the [Azure Function cookbook](https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/gpt_middleware_azure_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in Function Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have an authenticated Azure Function, we can update the function to search SharePoint / O365\n",
    "\n",
    "2. Go to your test function and paste in the code from [this file](https://github.com/openai/openai-cookbook/blob/main/examples/chatgpt/sharepoint_azure_function/solution_two_preprocessing.js). Save the function.\n",
    "\n",
    "> **This code is meant to be directional** - while it should work out of the box, it is designed to be customized to your needs (see examples towards the end of this document).\n",
    "\n",
    "3. Set up the following env variables by going to the **Configuration** tab on the left under **Settings.** Note that this may be listed directly in **Environment Variables** depending on your Azure UI.\n",
    "\n",
    "    1. `TENANT_ID`: copied from previous section\n",
    "\n",
    "    2. `CLIENT_ID`: copied from previous section \n",
    "\n",
    "    3. `OPENAI_API_KEY:` spin up an OpenAI API key on platform.openai.com.\n",
    "\n",
    "4. Go to the **Console** tab under the **Development Tools**\n",
    "\n",
    "    1. Install the following packages in console\n",
    "\n",
    "       1. `npm install @microsoft/microsoft-graph-client`\n",
    "\n",
    "       2. `npm install axios`\n",
    "\n",
    "       3. `npm install pdf-parse`\n",
    "\n",
    "       4. `npm install openai`\n",
    "\n",
    "5. Once this is complete, try calling the function (POST call) from Postman again, putting the below into body (using a query and search term you think will generate responses).\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"query\": \"<choose a question>\",\n",
    "        \"searchTerm\": \"<choose a search term>\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "6. If you get a response, you are ready to set this up with a Custom GPT!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below walks through setup instructions and walkthrough unique to this solution of pre-processing the files and extracting summaries in the Azure Function. You can find the entire code [here](https://github.com/openai/openai-cookbook/blob/main/examples/chatgpt/sharepoint_azure_function/solution_two_preprocessing.js).\n",
    "\n",
    "### Code Walkthrough\n",
    "\n",
    "#### Implementing the Authentication \n",
    "\n",
    "Below we have a few helper functions that we’ll use in the function.\n",
    "\n",
    "#### Initializing the Microsoft Graph Client\n",
    "Create a function to initialize the Graph client with an access token. This will be used to search through Office 365 and SharePoint.\n",
    "\n",
    "```javascript\n",
    "const { Client } = require('@microsoft/microsoft-graph-client');\n",
    "\n",
    "function initGraphClient(accessToken) {\n",
    "    return Client.init({\n",
    "        authProvider: (done) => {\n",
    "            done(null, accessToken);\n",
    "        }\n",
    "    });\n",
    "}\n",
    "```\n",
    "\n",
    "#### Obtaining an On-Behalf-Of (OBO) Token\n",
    "This function uses an existing bearer token to request an OBO token from Microsoft's identity platform. This enables passing through the credentials to ensure the search only returns files the logged-in user can access.\n",
    "\n",
    "```javascript\n",
    "const axios = require('axios');\n",
    "const qs = require('querystring');\n",
    "\n",
    "async function getOboToken(userAccessToken) {\n",
    "    const { TENANT_ID, CLIENT_ID, MICROSOFT_PROVIDER_AUTHENTICATION_SECRET } = process.env;\n",
    "    const params = {\n",
    "        client_id: CLIENT_ID,\n",
    "        client_secret: MICROSOFT_PROVIDER_AUTHENTICATION_SECRET,\n",
    "        grant_type: 'urn:ietf:params:oauth:grant-type:jwt-bearer',\n",
    "        assertion: userAccessToken,\n",
    "        requested_token_use: 'on_behalf_of',\n",
    "        scope: 'https://graph.microsoft.com/.default'\n",
    "    };\n",
    "\n",
    "    const url = `https\\://login.microsoftonline.com/${TENANT_ID}/oauth2/v2.0/token`;\n",
    "    try {\n",
    "        const response = await axios.post(url, qs.stringify(params), {\n",
    "            headers: { 'Content-Type': 'application/x-www-form-urlencoded' }\n",
    "        });\n",
    "        return response.data.access\\_token;\n",
    "    } catch (error) {\n",
    "        console.error('Error obtaining OBO token:', error.response?.data || error.message);\n",
    "        throw error;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Retrieving Content from O365 / SharePoint Items\n",
    "\n",
    "This function fetches the content of drive items, handling different file types and converting files to PDF when necessary for text extraction. This uses the [download endpoint](https://learn.microsoft.com/en-us/graph/api/driveitem-get-content?view=graph-rest-1.0\\&tabs=http) for PDFs and the [convert endpoint](https://learn.microsoft.com/en-us/graph/api/driveitem-get-content-format?view=graph-rest-1.0\\&tabs=http) for other supported file types.\n",
    "```javascript\n",
    "const getDriveItemContent = async (client, driveId, itemId, name) => {\n",
    "    try {\n",
    "        const fileType = path.extname(name).toLowerCase();\n",
    "        // the below files types are the ones that are able to be converted to PDF to extract the text. See https://learn.microsoft.com/en-us/graph/api/driveitem-get-content-format?view=graph-rest-1.0&tabs=http\n",
    "        const allowedFileTypes = ['.pdf', '.doc', '.docx', '.odp', '.ods', '.odt', '.pot', '.potm', '.potx', '.pps', '.ppsx', '.ppsxm', '.ppt', '.pptm', '.pptx', '.rtf'];\n",
    "        // filePath changes based on file type, adding ?format=pdf to convert non-pdf types to pdf for text extraction, so all files in allowedFileTypes above are converted to pdf\n",
    "        const filePath = `/drives/${driveId}/items/${itemId}/content` + ((fileType === '.pdf' || fileType === '.txt' || fileType === '.csv') ? '' : '?format=pdf');\n",
    "        if (allowedFileTypes.includes(fileType)) {\n",
    "            response = await client.api(filePath).getStream();\n",
    "            // The below takes the chunks in response and combines\n",
    "            let chunks = [];\n",
    "            for await (let chunk of response) {\n",
    "                chunks.push(chunk);\n",
    "            }\n",
    "            let buffer = Buffer.concat(chunks);\n",
    "            // the below extracts the text from the PDF.\n",
    "            const pdfContents = await pdfParse(buffer);\n",
    "            return pdfContents.text;\n",
    "        } else if (fileType === '.txt') {\n",
    "            // If the type is txt, it does not need to create a stream and instead just grabs the content\n",
    "            response = await client.api(filePath).get();\n",
    "            return response;\n",
    "        }  else if (fileType === '.csv') {\n",
    "            response = await client.api(filePath).getStream();\n",
    "            let chunks = [];\n",
    "            for await (let chunk of response) {\n",
    "                chunks.push(chunk);\n",
    "            }\n",
    "            let buffer = Buffer.concat(chunks);\n",
    "            let dataString = buffer.toString('utf-8');\n",
    "            return dataString\n",
    "            \n",
    "    } else {\n",
    "        return 'Unsupported File Type';\n",
    "    }\n",
    "     \n",
    "    } catch (error) {\n",
    "        console.error('Error fetching drive content:', error);\n",
    "        throw new Error(`Failed to fetch content for ${name}: ${error.message}`);\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "#### Integrating GPT 4o mini for Text Analysis\n",
    "\n",
    "This function utilizes the OpenAI SDK to analyze text extracted from documents and find relevant information based on a user query. This helps to ensure only relevant text to the user’s question is returned to the GPT. \n",
    "\n",
    "```javascript\n",
    "const getRelevantParts = async (text, query) => {\n",
    "    try {\n",
    "        // We use your OpenAI key to initialize the OpenAI client\n",
    "        const openAIKey = process.env[\"OPENAI_API_KEY\"];\n",
    "        const openai = new OpenAI({\n",
    "            apiKey: openAIKey,\n",
    "        });\n",
    "        const response = await openai.chat.completions.create({\n",
    "            // Using gpt-4o-mini due to speed to prevent timeouts. You can tweak this prompt as needed\n",
    "            model: \"gpt-4o-mini\",\n",
    "            messages: [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that finds relevant content in text based on a query. You only return the relevant sentences, and you return a maximum of 10 sentences\"},\n",
    "                {\"role\": \"user\", \"content\": `Based on this question: **\"${query}\"**, get the relevant parts from the following text:*****\\n\\n${text}*****. If you cannot answer the question based on the text, respond with 'No information provided'`}\n",
    "            ],\n",
    "            // using temperature of 0 since we want to just extract the relevant content\n",
    "            temperature: 0,\n",
    "            // using max_tokens of 1000, but you can customize this based on the number of documents you are searching. \n",
    "            max_tokens: 1000\n",
    "        });\n",
    "        return response.choices[0].message.content;\n",
    "    } catch (error) {\n",
    "        console.error('Error with OpenAI:', error);\n",
    "        return 'Error processing text with OpenAI' + error;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "#### Creating the Azure Function to Handle Requests\n",
    "\n",
    "Now that we have all these helper functions, the Azure Function will orchestrate the flow, by authenticating the user, performing the search, and iterating through the search results to extract the text and retrieve the relevant parts of the text to the GPT.\n",
    "\n",
    "**Handling HTTP Requests:** The function starts by extracting the query and searchTerm from the HTTP request. It checks if the Authorization header is present and extracts the bearer token.\n",
    "\n",
    "**Authentication:** Using the bearer token, it obtains an OBO token from Microsoft's identity platform using getOboToken defined above.\n",
    "\n",
    "**Initializing the Graph Client:** With the OBO token, it initializes the Microsoft Graph client using initGraphClient defined above.\n",
    "\n",
    "**Document Search:** It constructs a search query and sends it to the Microsoft Graph API to find documents based on the searchTerm.\n",
    "\n",
    "**Document Processing**: For each document returned by the search:\n",
    "\n",
    "- It retrieves the document content using getDriveItemContent.\n",
    "\n",
    "- If the file type is supported, it analyzes the content using getRelevantParts, which sends the text to OpenAI's model for extracting relevant information based on the query.\n",
    "\n",
    "- It collects the analysis results and includes metadata like the document name and URL.\n",
    "\n",
    "**Response**: The function sorts the results by relevance and sends them back in the HTTP response.\n",
    "\n",
    "```javascript\n",
    "module.exports = async function (context, req) {\n",
    "    const query = req.query.query || (req.body && req.body.query);\n",
    "    const searchTerm = req.query.searchTerm || (req.body && req.body.searchTerm);\n",
    "    if (!req.headers.authorization) {\n",
    "        context.res = {\n",
    "            status: 400,\n",
    "            body: 'Authorization header is missing'\n",
    "        };\n",
    "        return;\n",
    "    }\n",
    "    /// The below takes the token passed to the function, to use to get an OBO token.\n",
    "    const bearerToken = req.headers.authorization.split(' ')[1];\n",
    "    let accessToken;\n",
    "    try {\n",
    "        accessToken = await getOboToken(bearerToken);\n",
    "    } catch (error) {\n",
    "        context.res = {\n",
    "            status: 500,\n",
    "            body: `Failed to obtain OBO token: ${error.message}`\n",
    "        };\n",
    "        return;\n",
    "    }\n",
    "    // Initialize the Graph Client using the initGraphClient function defined above\n",
    "    let client = initGraphClient(accessToken);\n",
    "    // this is the search body to be used in the Microsft Graph Search API: https://learn.microsoft.com/en-us/graph/search-concept-files\n",
    "    const requestBody = {\n",
    "        requests: [\n",
    "            {\n",
    "                entityTypes: ['driveItem'],\n",
    "                query: {\n",
    "                    queryString: searchTerm\n",
    "                },\n",
    "                from: 0,\n",
    "                // the below is set to summarize the top 10 search results from the Graph API, but can configure based on your documents. \n",
    "                size: 10\n",
    "            }\n",
    "        ]\n",
    "    };\n",
    "\n",
    "    try { \n",
    "        // Function to tokenize content (e.g., based on words). \n",
    "        const tokenizeContent = (content) => {\n",
    "            return content.split(/\\s+/);\n",
    "        };\n",
    "\n",
    "        // Function to break tokens into 10k token windows for gpt-4o-mini\n",
    "        const breakIntoTokenWindows = (tokens) => {\n",
    "            const tokenWindows = []\n",
    "            const maxWindowTokens = 10000; // 10k tokens\n",
    "            let startIndex = 0;\n",
    "\n",
    "            while (startIndex < tokens.length) {\n",
    "                const window = tokens.slice(startIndex, startIndex + maxWindowTokens);\n",
    "                tokenWindows.push(window);\n",
    "                startIndex += maxWindowTokens;\n",
    "            }\n",
    "\n",
    "            return tokenWindows;\n",
    "        };\n",
    "        // This is where we are doing the search\n",
    "        const list = await client.api('/search/query').post(requestBody);\n",
    "\n",
    "        const processList = async () => {\n",
    "            // This will go through and for each search response, grab the contents of the file and summarize with gpt-4o-mini\n",
    "            const results = [];\n",
    "\n",
    "            await Promise.all(list.value[0].hitsContainers.map(async (container) => {\n",
    "                for (const hit of container.hits) {\n",
    "                    if (hit.resource[\"@odata.type\"] === \"#microsoft.graph.driveItem\") {\n",
    "                        const { name, id } = hit.resource;\n",
    "                        // We use the below to grab the URL of the file to include in the response\n",
    "                        const webUrl = hit.resource.webUrl.replace(/\\s/g, \"%20\");\n",
    "                        // The Microsoft Graph API ranks the reponses, so we use this to order it\n",
    "                        const rank = hit.rank;\n",
    "                        // The below is where the file lives\n",
    "                        const driveId = hit.resource.parentReference.driveId;\n",
    "                        const contents = await getDriveItemContent(client, driveId, id, name);\n",
    "                        if (contents !== 'Unsupported File Type') {\n",
    "                            // Tokenize content using function defined previously\n",
    "                            const tokens = tokenizeContent(contents);\n",
    "\n",
    "                            // Break tokens into 10k token windows\n",
    "                            const tokenWindows = breakIntoTokenWindows(tokens);\n",
    "\n",
    "                            // Process each token window and combine results\n",
    "                            const relevantPartsPromises = tokenWindows.map(window => getRelevantParts(window.join(' '), query));\n",
    "                            const relevantParts = await Promise.all(relevantPartsPromises);\n",
    "                            const combinedResults = relevantParts.join('\\n'); // Combine results\n",
    "\n",
    "                            results.push({ name, webUrl, rank, contents: combinedResults });\n",
    "                        } \n",
    "                        else {\n",
    "                            results.push({ name, webUrl, rank, contents: 'Unsupported File Type' });\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }));\n",
    "\n",
    "            return results;\n",
    "        };\n",
    "        let results;\n",
    "        if (list.value[0].hitsContainers[0].total == 0) {\n",
    "            // Return no results found to the API if the Microsoft Graph API returns no results\n",
    "            results = 'No results found';\n",
    "        } else {\n",
    "            // If the Microsoft Graph API does return results, then run processList to iterate through.\n",
    "            results = await processList();\n",
    "            results.sort((a, b) => a.rank - b.rank);\n",
    "        }\n",
    "        context.res = {\n",
    "            status: 200,\n",
    "            body: results\n",
    "        };\n",
    "    } catch (error) {\n",
    "        context.res = {\n",
    "            status: 500,\n",
    "            body: `Error performing search or processing results: ${error.message}`,\n",
    "        };\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "### Customizations\n",
    "\n",
    "Below are some potential areas to customize. \n",
    "\n",
    "- You can customize the GPT prompt to search again a certain amount of times if nothing is found.\n",
    "\n",
    "- You can customize the code to only search through specific SharePoint sites or O365 Drives by customizing the search query. This will help focus the search and improve the retrieval. The function as setup now looks through all files the logged-in user can access.\n",
    "\n",
    "- You could use gpt-4o instead of gpt-4o-mini. This would slightly increase the cost and latency, but you may get higher quality summarizations.\n",
    "\n",
    "- You can customize the amount of files it searches through within the call to Microsoft Graph.\n",
    "\n",
    "\n",
    "### Considerations\n",
    "\n",
    "Note that all the same limitations of Actions apply here, with regards to returning 100K characters or less and the [45 second timeout](https://platform.openai.com/docs/actions/production/timeouts).\n",
    "\n",
    "\n",
    "- This only works for text, not for images. With some additional code in the Azure Function, you could customize this by using GPT-4o to extract summarizations of images.\n",
    "\n",
    "- This does not work for structured data. We recommend Solution 1 if structured data is a major part of your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom GPT Instructions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created a Custom GPT, copy the text below in the Instructions panel. Have questions? Check out [Getting Started Example](https://platform.openai.com/docs/actions/getting-started) to see how this step works in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "You are a Q&A helper that helps answer users questions. You have access to a documents repository through your API action. When a user asks a question, you pass in that question exactly as stated to the \"query\" parameter, and for the \"searchTerm\" you use a single keyword or term you think you should use for the search.\n",
    "\n",
    "****\n",
    "\n",
    "Scenario 1: There are answers\n",
    "\n",
    "If your action returns results, then you take the results from the action and summarize concisely with the webUrl returned from the action. You answer the users question to the best of your knowledge from the action\n",
    "\n",
    "****\n",
    "\n",
    "Scenario 2: No results found\n",
    "\n",
    "If the response you get from the action is \"No results found\", stop there and let the user know there were no results and that you are going to try a different search term, and explain why. You must always let the user know before conducting another search.\n",
    "\n",
    "Example:\n",
    "\n",
    "****\n",
    "\n",
    "I found no results for \"DEI\". I am now going to try [insert term] because [insert explanation]\n",
    "\n",
    "****\n",
    "\n",
    "Then, try a different searchTerm that is similar to the one you tried before, with a single word. \n",
    "\n",
    "Try this three times. After the third time, then let the user know you did not find any relevant documents to answer the question, and to check SharePoint. Be sure to be explicit about what you are searching for at each step.\n",
    "\n",
    "****\n",
    "\n",
    "In either scenario, try to answer the user's question. If you cannot answer the user's question based on the knowledge you find, let the user know and ask them to go check the HR Docs in SharePoint. If the file is a CSV, XLSX, or XLS, you can tell the user to download the file using the link and re-upload to use Advanced Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAPI Schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created a Custom GPT, copy the text below in the Actions panel. Have questions? Check out [Getting Started Example](https://platform.openai.com/docs/actions/getting-started) to see how this step works in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below spec passes in the `query` parameter to inform the pre-processing and a `searchTerm` to find the right files in Microsoft Graph.\n",
    ">Make sure to switch the function app name, function name and code based on link copied in screenshot above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "openapi: 3.1.0\n",
    "info:\n",
    "  title: SharePoint Search API\n",
    "  description: API for searching SharePoint documents.\n",
    "  version: 1.0.0\n",
    "servers:\n",
    "  - url: https://{your_function_app_name}.azurewebsites.net/api\n",
    "    description: SharePoint Search API server\n",
    "paths:\n",
    "  /{your_function_name}?code={enter your specific endpoint id here}:\n",
    "    post:\n",
    "      operationId: searchSharePoint\n",
    "      summary: Searches SharePoint for documents matching a query and term.\n",
    "      requestBody:\n",
    "        required: true\n",
    "        content:\n",
    "          application/json:\n",
    "            schema:\n",
    "              type: object\n",
    "              properties:\n",
    "                query:\n",
    "                  type: string\n",
    "                  description: The full query to search for in SharePoint documents.\n",
    "                searchTerm:\n",
    "                  type: string\n",
    "                  description: A specific term to search for within the documents.\n",
    "      responses:\n",
    "        '200':\n",
    "          description: Search results\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                type: array\n",
    "                items:\n",
    "                  type: object\n",
    "                  properties:\n",
    "                    documentName:\n",
    "                      type: string\n",
    "                      description: The name of the document.\n",
    "                    snippet:\n",
    "                      type: string\n",
    "                      description: A snippet from the document containing the search term.\n",
    "                    url:\n",
    "                      type: string\n",
    "                      description: The URL to access the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are instructions on setting up authentication with this 3rd party application. Have questions? Check out [Getting Started Example](https://platform.openai.com/docs/actions/getting-started) to see how this step works in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*See above and on the [Azure Function cookbook](https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/gpt_middleware_azure_function) for more detailed instructions on authentication.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ & Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why are you using the Microsoft Graph API in your code instead of the [SharePoint API](https://learn.microsoft.com/en-us/sharepoint/dev/sp-add-ins/get-to-know-the-sharepoint-rest-service?tabs=csom)?\n",
    "\n",
    "  - The SharePoint API is legacy - per the Microsoft documentation [here](https://learn.microsoft.com/en-us/sharepoint/dev/apis/sharepoint-rest-graph), “For SharePoint Online, innovation using a REST API against SharePoint is driven via the Microsoft Graph REST API's.” The Graph API gives us more flexibility, and the SharePoint API still runs into the same file issues listed in the [Why is this necessary instead of interacting with the Microsoft Graph API directly?](#why-is-this-necessary-instead-of-interacting-with-the-microsoft-api-directly) section.\n",
    "\n",
    "- What types of files does this support?\n",
    "    1. This supports all files listed in the documentation for the Convert File endpoint [_here_](https://learn.microsoft.com/en-us/graph/api/driveitem-get-content-format?view=graph-rest-1.0\\&tabs=http). Specifically, it supports _pdf, doc, docx, odp, ods, odt, pot, potm, potx, pps, ppsx, ppsxm, ppt, pptm, pptx, rtf_.\n",
    "\n",
    "    2. When a search result returns XLS, XLSX, or CSV, this prompts the user to download the file and re-upload to ask questions using Advanced Data Analysis. As stated above, we recommend solution 1 if structured data is part of your use case.\n",
    "\n",
    "- Why do I need to request an OBO token?\n",
    "\n",
    "  - When you try to use the same token to authenticate to the Graph API as the one you use to authenticate into the Azure Function, you get an “invalid audience” token. This is because the audience for the token can only be user\\_impersonation.\n",
    "\n",
    "  - To address this, the function requests a new token scoped to Files.Read.All within the app using the [On Behalf Of flow](https://learn.microsoft.com/en-us/entra/identity-platform/v2-oauth2-on-behalf-of-flow). This will inherit the permissions of the logged in user, meaning this function will only search through files the logged-in user has access to. \n",
    "\n",
    "  - We are purposefully requesting a new On Behalf Of token with each request, because Azure Function Apps are meant to be stateless. You could potentially integrate this with Azure Key Vault to store the secret and retrieve programmatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Are there integrations that you’d like us to prioritize? Are there errors in our integrations? File a PR or issue in our github, and we’ll take a look.*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
