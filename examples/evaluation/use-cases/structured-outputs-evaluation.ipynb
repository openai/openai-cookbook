{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd88e7c",
   "metadata": {},
   "source": [
    "# Evaluating Code Quality Extraction with a Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf0667",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to evaluate a model's ability to extract symbols from code using the OpenAI **Evals** framework with a custom in-memory dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacc6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"_OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b272e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(limit=None):\n",
    "    openai_sdk_file_path = os.path.dirname(openai.__file__)\n",
    "\n",
    "    file_paths = [\n",
    "        os.path.join(openai_sdk_file_path, \"resources\", \"evals\", \"evals.py\"),\n",
    "        os.path.join(openai_sdk_file_path, \"resources\", \"responses\", \"responses.py\"),\n",
    "        os.path.join(openai_sdk_file_path, \"resources\", \"images.py\"),\n",
    "        os.path.join(openai_sdk_file_path, \"resources\", \"embeddings.py\"),\n",
    "        os.path.join(openai_sdk_file_path, \"resources\", \"files.py\"),\n",
    "    ]\n",
    "\n",
    "    items = []\n",
    "    for file_path in file_paths:\n",
    "        items.append({\"input\": open(file_path, \"r\").read()})\n",
    "    if limit:\n",
    "        return items[:limit]\n",
    "    return items\n",
    "\n",
    "\n",
    "structured_output_grader = \"\"\"\n",
    "You are a helpful assistant that grades the quality of extracted information from a code file.\n",
    "You will be given a code file and a list of extracted information.\n",
    "You should grade the quality of the extracted information.\n",
    "\n",
    "You should grade the quality on a scale of 1 to 7.\n",
    "You should apply the following criteria, and calculate your score as follows:\n",
    "You should first check for completeness on a scale of 1 to 7.\n",
    "Then you should apply a quality modifier.\n",
    "\n",
    "The quality modifier is a multiplier from 0 to 1 that you multiply by the completeness score.\n",
    "If there is 100% coverage for completion and it is all high quality, then you would return 7*1.\n",
    "If there is 100% coverage for completion but it is all low quality, then you would return 7*0.5.\n",
    "etc.\n",
    "\"\"\"\n",
    "\n",
    "structured_output_grader_user_prompt = \"\"\"\n",
    "<Code File>\n",
    "{{item.input}}\n",
    "</Code File>\n",
    "\n",
    "<Extracted Information>\n",
    "{{sample.output_json.symbols}}\n",
    "</Extracted Information>\n",
    "\"\"\"\n",
    "\n",
    "logs_eval = client.evals.create(\n",
    "    name=\"Code QA Eval\",\n",
    "    data_source_config={\n",
    "        \"type\": \"custom\",\n",
    "        \"item_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"input\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"include_sample_schema\": True,\n",
    "    },\n",
    "    testing_criteria=[\n",
    "        {\n",
    "            \"type\": \"score_model\",\n",
    "            \"name\": \"General Evaluator\",\n",
    "            \"model\": \"o3\",\n",
    "            \"input\": [\n",
    "                {\"role\": \"system\", \"content\": structured_output_grader},\n",
    "                {\"role\": \"user\", \"content\": structured_output_grader_user_prompt},\n",
    "            ],\n",
    "            \"range\": [1, 7],\n",
    "            \"pass_threshold\": 5.5,\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f357e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4one_completions_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1\",\n",
    "    eval_id=logs_eval.id,\n",
    "    data_source={\n",
    "        \"type\": \"completions\",\n",
    "        \"source\": {\n",
    "            \"type\": \"file_content\",\n",
    "            \"content\": [{\"item\": item} for item in get_dataset(limit=1)],\n",
    "        },\n",
    "        \"input_messages\": {\n",
    "            \"type\": \"template\",\n",
    "            \"template\": [\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": {\"type\": \"input_text\", \"text\": \"You are a helpful assistant.\"},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"Extract the symbols from the code file {{item.input}}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"sampling_params\": {\n",
    "            \"seed\": 42,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_completions_tokens\": 10000,\n",
    "            \"top_p\": 0.9,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"python_symbols\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"symbols\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"A list of symbols extracted from Python code.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"name\": {\"type\": \"string\", \"description\": \"The name of the symbol.\"},\n",
    "                                        \"symbol_type\": {\n",
    "                                            \"type\": \"string\", \"description\": \"The type of the symbol, e.g., variable, function, class.\",\n",
    "                                        },\n",
    "                                    },\n",
    "                                    \"required\": [\"name\", \"symbol_type\"],\n",
    "                                    \"additionalProperties\": False,\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"symbols\"],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                    \"strict\": True,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "gpt_4one_responses_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1-mini\",\n",
    "    eval_id=logs_eval.id,\n",
    "    data_source={\n",
    "        \"type\": \"responses\",\n",
    "        \"source\": {\n",
    "            \"type\": \"file_content\",\n",
    "            \"content\": [{\"item\": item} for item in get_dataset(limit=1)],\n",
    "        },\n",
    "        \"input_messages\": {\n",
    "            \"type\": \"template\",\n",
    "            \"template\": [\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": {\"type\": \"input_text\", \"text\": \"You are a helpful assistant.\"},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"Extract the symbols from the code file {{item.input}}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"sampling_params\": {\n",
    "            \"seed\": 42,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_completions_tokens\": 10000,\n",
    "            \"top_p\": 0.9,\n",
    "            \"text\": {\n",
    "                \"format\": {\n",
    "                    \"type\": \"json_schema\",\n",
    "                    \"name\": \"python_symbols\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"symbols\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"A list of symbols extracted from Python code.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"name\": {\"type\": \"string\", \"description\": \"The name of the symbol.\"},\n",
    "                                        \"symbol_type\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"The type of the symbol, e.g., variable, function, class.\",\n",
    "                                        },\n",
    "                                    },\n",
    "                                    \"required\": [\"name\", \"symbol_type\"],\n",
    "                                    \"additionalProperties\": False,\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"symbols\"],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                    \"strict\": True,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_runs(eval_id, run_ids):\n",
    "    while True:\n",
    "        runs = [client.evals.runs.retrieve(rid, eval_id=eval_id) for rid in run_ids]\n",
    "        for run in runs:\n",
    "            print(run.id, run.status, run.result_counts)\n",
    "        if all(run.status in {\"completed\", \"failed\"} for run in runs):\n",
    "            # dump results to file\n",
    "            for run in runs:\n",
    "                with open(f\"{run.id}.json\", \"w\") as f:\n",
    "                    f.write(\n",
    "                        client.evals.runs.output_items.list(\n",
    "                            run_id=run.id, eval_id=eval_id\n",
    "                        ).model_dump_json(indent=4)\n",
    "                    )\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "poll_runs(logs_eval.id, [gpt_4one_completions_run.id, gpt_4one_responses_run.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c316e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_output = client.evals.runs.output_items.list(\n",
    "    run_id=gpt_4one_completions_run.id, eval_id=logs_eval.id\n",
    ")\n",
    "\n",
    "responses_output = client.evals.runs.output_items.list(\n",
    "    run_id=gpt_4one_responses_run.id, eval_id=logs_eval.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Completions Output')\n",
    "for item in completions_output:\n",
    "    print(item)\n",
    "\n",
    "print('\\n# Responses Output')\n",
    "for item in responses_output:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
