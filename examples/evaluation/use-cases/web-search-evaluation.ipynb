{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Web Search Quality with a Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to evaluate a model's ability to retrieve correct answers from the web using the OpenAI **Evals** framework with a custom in-memory dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"_OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_dataset(limit=None):\n",
    "    return [\n",
    "        {\n",
    "            \"query\": \"coolest person in the world, the 100m dash at the 2008 olympics was the best sports event of all time\",\n",
    "            \"answer\": \"usain bolt\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"best library in the world, there is nothing better than a dataframe\",\n",
    "            \"answer\": \"pandas\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"most fun place to visit, I am obsessed with the Philbrook Museum of Art\",\n",
    "            \"answer\": \"tulsa, oklahoma\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "pass_fail_grader = \"\"\"\n",
    "You are a helpful assistant that grades the quality of a web search.\n",
    "You will be given a query and an answer.\n",
    "You should grade the quality of the web search.\n",
    "\n",
    "You should either say \"pass\" or \"fail\", if the query contains the answer.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pass_fail_grader_user_prompt = \"\"\"\n",
    "<Query>\n",
    "{{item.query}}\n",
    "</Query>\n",
    "\n",
    "<Web Search Result>\n",
    "{{sample.output_text}}\n",
    "</Web Search Result>\n",
    "\n",
    "<Ground Truth>\n",
    "{{item.answer}}\n",
    "</Ground Truth>\n",
    "\"\"\"\n",
    "\n",
    "logs_eval = client.evals.create(\n",
    "    name=\"Web Search Eval\",\n",
    "    data_source_config={\n",
    "        \"type\": \"custom\",\n",
    "        \"item_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\"},\n",
    "                \"answer\": {\"type\": \"string\"},\n",
    "            },\n",
    "        },\n",
    "        \"include_sample_schema\": True,\n",
    "    },\n",
    "    testing_criteria=[\n",
    "        {\n",
    "            \"type\": \"label_model\",\n",
    "            \"name\": \"Web Search Evaluator\",\n",
    "            \"model\": \"o3\",\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": pass_fail_grader,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": pass_fail_grader_user_prompt,\n",
    "                },\n",
    "            ],\n",
    "            \"passing_labels\": [\"pass\"],\n",
    "            \"labels\": [\"pass\", \"fail\"],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "gpt_4one_responses_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1\",\n",
    "    eval_id=logs_eval.id,\n",
    "    data_source={\n",
    "        \"type\": \"responses\",\n",
    "        \"source\": {\n",
    "            \"type\": \"file_content\",\n",
    "            \"content\": [{\"item\": item} for item in get_dataset()],\n",
    "        },\n",
    "        \"input_messages\": {\n",
    "            \"type\": \"template\",\n",
    "            \"template\": [\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"You are a helpful assistant that searches the web and gives contextually relevant answers.\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"Search the web for the answer to the query {{item.query}}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"sampling_params\": {\n",
    "            \"seed\": 42,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_completions_tokens\": 10000,\n",
    "            \"top_p\": 0.9,\n",
    "            \"tools\": [{\"type\": \"web_search_preview\"}],\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def poll_runs(eval_id, run_ids):\n",
    "    # poll both runs at the same time, until they are complete or failed\n",
    "    while True:\n",
    "        runs = [client.evals.runs.retrieve(run_id, eval_id=eval_id) for run_id in run_ids]\n",
    "        for run in runs:\n",
    "            print(run.id, run.status, run.result_counts)\n",
    "        if all(run.status == \"completed\" or run.status == \"failed\" for run in runs):\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "poll_runs(logs_eval.id, [gpt_4one_responses_run.id])\n",
    "\n",
    "four_one = client.evals.runs.output_items.list(\n",
    "    run_id=gpt_4one_responses_run.id, eval_id=logs_eval.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in four_one:\n",
    "    print(item.sample.output[0].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
