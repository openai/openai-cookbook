{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3def15a",
   "metadata": {},
   "source": [
    "#  GPT-5 New Params and Tools\n",
    "\n",
    "We’re introducing new developer controls in the GPT-5 series that give you greater control over model responses—from shaping output length and style to enforcing strict formatting. Below is a quick overview of the latest features:\n",
    "\n",
    "\n",
    "| #  | Feature | Overview | Values / Usage |\n",
    "|----|---------|----------|----------------|\n",
    "| 1. | **Verbosity Parameter** | Lets you hint the model to be more or less expansive in its replies. Keep prompts stable and use the parameter instead of re-writing. | • **low** → terse UX, minimal prose.<br>• **medium** *(default)* → balanced detail.<br>• **high** → verbose, great for audits, teaching, or hand-offs. |\n",
    "| 2. | **Free-Form Function Calling** | Generate raw text payloads—anything from Python scripts to SQL queries—directly to your custom tool without JSON wrapping. Offers greater flexibility for external runtimes like:<br>• Code sandboxes (Python, C++, Java, …)<br>• SQL databases<br>• Shell environments<br>• Config generators | Use when structured JSON isn’t needed and raw text is more natural for the target tool. |\n",
    "| 3. | **Context-Free Grammar (CFG)** | A set of production rules defining valid strings in a language. Each rule rewrites a non-terminal into terminals and/or other non-terminals, independent of surrounding context. Useful for constraining output to match the syntax of programming languages or custom formats in OpenAI tools. | Use as a contract to ensure the model emits only valid strings accepted by the grammar. |\n",
    "\n",
    "**Supported Models:**  \n",
    "- gpt-5  \n",
    "- gpt-5-mini  \n",
    "- gpt-5-nano  \n",
    "\n",
    "**Supported API Endpoints** \n",
    "- Responses API \n",
    "- Chat Completions API \n",
    "\n",
    "Note: We recommend to use Responses API with GPT-5 series of model to get the most performance out of the models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb1c44",
   "metadata": {},
   "source": [
    "## Pre-requisites \n",
    "\n",
    "Let's begin with updating your OpenAI SDK that supports the new params and tools for GPT-5. Make sure you've set OPENAI_API_KEY as an environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9850c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai 1.99.1\n",
      "pandas 2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade openai pandas && \\\n",
    "echo -n \"openai \" && pip show openai | grep '^Version:' | cut -d' ' -f2 && \\\n",
    "echo -n \"pandas \" && pip show pandas | grep '^Version:' | cut -d' ' -f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6bc80",
   "metadata": {},
   "source": [
    "## 1. Verbosity Parameter \n",
    "\n",
    "### 1.1 Overview \n",
    "The verbosity parameter lets you hint the model to be more or less expansive in its replies.   \n",
    "\n",
    "**Values:** \"low\", \"medium\", \"high\"\n",
    "\n",
    "- low → terse UX, minimal prose.\n",
    "- medium (default) → balanced detail.\n",
    "- high → verbose, great for audits, teaching, or hand-offs.\n",
    "\n",
    "Keep prompts stable and use the param rather than re-writing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5260af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cbf48 th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_cbf48 td {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cbf48\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cbf48_level0_col0\" class=\"col_heading level0 col0\" >Verbosity</th>\n",
       "      <th id=\"T_cbf48_level0_col1\" class=\"col_heading level0 col1\" >Sample Output</th>\n",
       "      <th id=\"T_cbf48_level0_col2\" class=\"col_heading level0 col2\" >Output Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbf48_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cbf48_row0_col0\" class=\"data row0 col0\" >low</td>\n",
       "      <td id=\"T_cbf48_row0_col1\" class=\"data row0 col1\" >He found him behind the old shed, a damp ball of surprise,\n",
       "eyes like two small moons against the dusk.\n",
       "His palms trembled when they touched the ribs, a first brave promise —\n",
       "the word that made them both grin: \"home.\"\n",
       "\n",
       "They learned the map of each other's days:\n",
       "mud on the porch, the shorthand of paws on tile,\n",
       "lessons in patience—sit, wait, the clumsy language of fetch—\n",
       "evenings stitched together by a tail that kept time.\n",
       "\n",
       "The dog taught him how to be gentle with broken things:\n",
       "scarred knees, lost kites, the ache of a scraped promise.\n",
       "When the boy fell, the dog was there to push him up with a wet nose,\n",
       "when the world tightened, the dog leaned in like a small sun.\n",
       "\n",
       "Years threaded silver into ears and softened the sprint,\n",
       "the boy grew taller, pockets fuller of other lives.\n",
       "On the last slow walk he carried the dog across the field they had worn bare,\n",
       "and learned what it meant to hold and let go at once.\n",
       "\n",
       "Sometimes, in a house that now holds different voices,\n",
       "he still calls the name and feels a short, bright tug at the hem of memory.</td>\n",
       "      <td id=\"T_cbf48_row0_col2\" class=\"data row0 col2\" >754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbf48_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cbf48_row1_col0\" class=\"data row1 col0\" >medium</td>\n",
       "      <td id=\"T_cbf48_row1_col1\" class=\"data row1 col1\" >He was small enough to be held in two palms,\n",
       "hands surprised by the light, warm weight of a breathing animal.\n",
       "The dog came with a cardboard box of toys,\n",
       "a collar that jingled like a laugh,\n",
       "and eyes the color of late autumn pools.\n",
       "\n",
       "They learned each other by touch:\n",
       "how a thumb smoothed a lump of fur,\n",
       "how a paw fit between fingers like a promise.\n",
       "Afternoons became slow, luminous things —\n",
       "fetch across the yard, the dog tumbling through dandelions,\n",
       "the boy counting sticks as if they were crowns.\n",
       "\n",
       "At night the dog curled against a ribcage\n",
       "and taught the boy how to sleep with one ear listening.\n",
       "They shared secrets whispered into warm fur,\n",
       "bandaged scraped knees with careful nuzzles,\n",
       "and sat together on porches while light leaned away.\n",
       "\n",
       "The world outside was larger, sharper,\n",
       "but he had a companion who never measured fear,\n",
       "only presence — a warm, steady map back home.\n",
       "Lessons came not in words but in ritual:\n",
       "the bowl filled, the leash clicked, the hush before storms.\n",
       "Responsibility fit him like a second skin.\n",
       "\n",
       "Years threaded through collars and collars loosened,\n",
       "legs that once ran like wind now slowed to wiser steps.\n",
       "The boy learned how to be brave in other ways:\n",
       "walking into rooms without the certainty of pawprints,\n",
       "carrying a small quiet grief folded into his chest.\n",
       "\n",
       "Even when the dog went where yards are always green,\n",
       "he left prints on the boy’s life that never washed away —\n",
       "a tucked-in photograph, a faded ball, the smell of wet fur in summer rain.\n",
       "Sometimes, when the house is very still, the boy — now taller,\n",
       "still hears the jingle of a collar and smiles,\n",
       "for he knows how to be loved, and how to love back.</td>\n",
       "      <td id=\"T_cbf48_row1_col2\" class=\"data row1 col2\" >939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbf48_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cbf48_row2_col0\" class=\"data row2 col0\" >high</td>\n",
       "      <td id=\"T_cbf48_row2_col1\" class=\"data row2 col1\" >The dog arrived like a small sun, all fur and surprise,\n",
       "an apology for shoes chewed at the doorstep.\n",
       "He fit into the boy’s lap as if he had been made there:\n",
       "a warm, wiggling answer to the question the boy never knew he’d asked.\n",
       "\n",
       "They learned one another by touch — the boy’s clumsy fingers\n",
       "finding the soft map of ears, the steady paddling heart.\n",
       "The dog learned the geometry of a bedroom, a couch, a favorite chair;\n",
       "the boy learned the weight of responsibility when the bowl was empty.\n",
       "\n",
       "They practiced words like spellcraft: sit, stay, no — then laugh\n",
       "when the commands rearranged themselves into games.\n",
       "Mud sketched secret rivers on their trousers;\n",
       "the neighborhood became a kingdom to patrol on two legs and four.\n",
       "\n",
       "At night the dog lay like a small, even moon against the boy’s ribs,\n",
       "breathing the rhythm of a shared world into his dreams.\n",
       "Storms were smaller storms then, because the dog’s body was a promise:\n",
       "that thunder could be waited out, that hands could find something warm.\n",
       "\n",
       "They buried treasures — bones, a tin soldier, a lost mitten —\n",
       "beneath the old apple tree, sworn companions to the earth.\n",
       "They chased imagined villains down fences and over hedges,\n",
       "and sometimes, at the creek, the boy learned the exact angle of courage:\n",
       "how to step in, then trust another heartbeat beside his.\n",
       "\n",
       "The dog taught him how to be brave without knowing the word,\n",
       "showed him where loyalty lived (in the bright, impatient wag of a tail).\n",
       "He taught him how to say hello, properly; how to stay when needed;\n",
       "how to forgive a day of wrongs with a single, earnest lick.\n",
       "\n",
       "Seasons folded themselves into the years;\n",
       "the boy measured time in collars replaced, in new aches in the dog’s hips.\n",
       "Snow made the yard a clean page; leaves wrote their own goodbyes.\n",
       "When the dog’s runs slowed, the boy learned a different kind of steady:\n",
       "to sit more, to listen longer, to count the small comforts.\n",
       "\n",
       "There was a last evening where the light sat low and patient,\n",
       "and the boy — now older in ways that did not fit his face — held that same warm weight.\n",
       "He remembered the first bark like a promise kept, the first wild sprint across the grass,\n",
       "and he kept, beneath his ribs, the map of a thousand small mercies.\n",
       "\n",
       "Now when he walks by an old apple tree, his hand finds empty air,\n",
       "but his steps know how to make room for another’s rhythm.\n",
       "Sometimes a stray dog will glance his way and tilt its head,\n",
       "and he smiles, answering without words what he was taught long ago:\n",
       "\n",
       "how to open a hand, how to offer a place on the floor,\n",
       "how to recognize the sun when it returns — in fur, in breath, in the simple, astonished love\n",
       "of a first pet who showed a boy what home can mean.</td>\n",
       "      <td id=\"T_cbf48_row2_col2\" class=\"data row2 col2\" >1174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10d179bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "question = \"Write a poem about a boy and his first pet dog.\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for verbosity in [\"low\", \"medium\", \"high\"]:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=question,\n",
    "        text={\"verbosity\": verbosity}\n",
    "    )\n",
    "\n",
    "    # Extract text\n",
    "    output_text = \"\"\n",
    "    for item in response.output:\n",
    "        if hasattr(item, \"content\"):\n",
    "            for content in item.content:\n",
    "                if hasattr(content, \"text\"):\n",
    "                    output_text += content.text\n",
    "\n",
    "    # Truncate for display\n",
    "    if len(output_text) > 700:\n",
    "        sample_output = (\n",
    "            output_text[:500]\n",
    "            + \" ... redacted for brevity ... \"\n",
    "            + output_text[-200:]\n",
    "        )\n",
    "    else:\n",
    "        sample_output = output_text\n",
    "\n",
    "    usage = response.usage\n",
    "    data.append({\n",
    "        \"Verbosity\": verbosity,\n",
    "        \"Sample Output\": output_text,\n",
    "        \"Output Tokens\": usage.output_tokens\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display nicely with centered headers\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "styled_df = df.style.set_table_styles(\n",
    "    [\n",
    "        {'selector': 'th', 'props': [('text-align', 'center')]},  # Center column headers\n",
    "        {'selector': 'td', 'props': [('text-align', 'left')]}     # Left-align table cells\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdb759",
   "metadata": {},
   "source": [
    "The output tokens scale roughly linearly with verbosity: low (754) → medium (939) → high (1174)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2e969",
   "metadata": {},
   "source": [
    "### 2.3 Using Verbosity for Coding Use Cases \n",
    "\n",
    "The verbosity parameter also influences the length and complexity of generated code, as well as the depth of accompanying explanations. Here's an example, wherein we use various verboisty levels for a task to generate a Python program that sorts an array of 1000000 random numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6b6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Verbosity: low\n",
      "Output:\n",
      "#!/usr/bin/env python3\n",
      "import random\n",
      "import time\n",
      "\n",
      "def main():\n",
      "    N = 1_000_000\n",
      "    # generate 1,000,000 random floats\n",
      "    arr = [random.random() for _ in range(N)]\n",
      "\n",
      "    t0 = time.perf_counter()\n",
      "    arr.sort()  # in-place Timsort\n",
      "    t1 = time.perf_counter()\n",
      "\n",
      "    print(f\"Sorted {N} numbers in {t1 - t0:.4f} seconds\")\n",
      "    # optional quick checks\n",
      "    print(\"First 5:\", arr[:5])\n",
      "    print(\"Last 5:\", arr[-5:])\n",
      "    print(\"Verified sorted:\", all(arr[i] <= arr[i+1] for i in range(len(arr)-1)))\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "Tokens => input: 21 | output: 877\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"Output a Python program that sorts an array of 1000000 random numbers\"\n",
    "\n",
    "def ask_with_verbosity(verbosity: str, question: str):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=question,\n",
    "        text={\n",
    "            \"verbosity\": verbosity\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Extract assistant's text output\n",
    "    output_text = \"\"\n",
    "    for item in response.output:\n",
    "        if hasattr(item, \"content\"):\n",
    "            for content in item.content:\n",
    "                if hasattr(content, \"text\"):\n",
    "                    output_text += content.text\n",
    "\n",
    "    # Token usage details\n",
    "    usage = response.usage\n",
    "\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"Verbosity: {verbosity}\")\n",
    "    print(\"Output:\")\n",
    "    print(output_text)\n",
    "    print(\"Tokens => input: {} | output: {}\".format(\n",
    "        usage.input_tokens, usage.output_tokens\n",
    "    ))\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ask_with_verbosity(\"low\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a741167",
   "metadata": {},
   "source": [
    "Notice that the code output is a plain script. Now, lets run with 'medium' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2efe2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Verbosity: medium\n",
      "Output:\n",
      "Here's a simple Python program that generates 1,000,000 random floats and sorts them using Python's built-in Timsort. It times generation and sorting and verifies the result.\n",
      "\n",
      "```python\n",
      "import random\n",
      "import time\n",
      "\n",
      "def main():\n",
      "    N = 1_000_000\n",
      "\n",
      "    print(f\"Generating {N} random numbers...\")\n",
      "    t0 = time.perf_counter()\n",
      "    arr = [random.random() for _ in range(N)]\n",
      "    t1 = time.perf_counter()\n",
      "    print(f\"Generated in {t1 - t0:.3f} seconds\")\n",
      "\n",
      "    print(\"Sorting...\")\n",
      "    t2 = time.perf_counter()\n",
      "    arr.sort()\n",
      "    t3 = time.perf_counter()\n",
      "    print(f\"Sorted in {t3 - t2:.3f} seconds\")\n",
      "\n",
      "    # Quick verification\n",
      "    is_sorted = all(arr[i] <= arr[i+1] for i in range(len(arr)-1))\n",
      "    print(\"Verified sorted:\", is_sorted)\n",
      "\n",
      "    print(\"First 10 elements:\", arr[:10])\n",
      "    print(\"Last 10 elements:\", arr[-10:])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "If you prefer a faster/more memory-efficient approach and have NumPy installed, you can replace the generation and sort with:\n",
      "- arr = np.random.random(N)\n",
      "- arr.sort()\n",
      "Tokens => input: 21 | output: 1178\n"
     ]
    }
   ],
   "source": [
    "ask_with_verbosity(\"medium\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48bbeb",
   "metadata": {},
   "source": [
    "Medium verboisty, generated richer code with additioanl explanations. Let's do the same with high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f92fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Verbosity: high\n",
      "Output:\n",
      "Below are two complete Python programs you can run to generate and sort 1,000,000 random numbers. One is a pure-Python implementation using the built-in list and list.sort() (Timsort). The other uses NumPy (faster and far more memory-efficient for large numeric arrays). Each script times generation and sorting and optionally verifies the result is sorted.\n",
      "\n",
      "Pure-Python version (no extra dependencies)\n",
      "- Generates 1,000,000 Python floats with random.random().\n",
      "- Uses list.sort() (Timsort), which is O(n log n) and very efficient in practice.\n",
      "- Note: Python float objects have overhead, so the list will use substantially more memory than a raw numeric array.\n",
      "\n",
      "Save as sort_random_pure.py and run: python sort_random_pure.py\n",
      "You can change the size with the --count option.\n",
      "\n",
      "```python\n",
      "#!/usr/bin/env python3\n",
      "\"\"\"\n",
      "Generate and sort N random numbers using pure Python list and list.sort().\n",
      "Default N = 1_000_000. Use --count to override.\n",
      "\"\"\"\n",
      "import argparse\n",
      "import random\n",
      "import time\n",
      "import sys\n",
      "\n",
      "def is_sorted(seq):\n",
      "    # Efficient check: compare neighbours\n",
      "    return all(x <= y for x, y in zip(seq, seq[1:]))\n",
      "\n",
      "def main():\n",
      "    parser = argparse.ArgumentParser(description=\"Generate and sort random numbers (pure Python).\")\n",
      "    parser.add_argument(\"--count\", \"-n\", type=int, default=1_000_000,\n",
      "                        help=\"Number of random numbers to generate (default: 1_000_000)\")\n",
      "    parser.add_argument(\"--seed\", type=int, default=None, help=\"Optional random seed\")\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    n = args.count\n",
      "    if args.seed is not None:\n",
      "        random.seed(args.seed)\n",
      "\n",
      "    print(f\"Generating {n:,} random floats...\")\n",
      "    t0 = time.perf_counter()\n",
      "    data = [random.random() for _ in range(n)]\n",
      "    t1 = time.perf_counter()\n",
      "    print(f\"Generation took {t1 - t0:.3f} seconds.\")\n",
      "\n",
      "    print(\"Sorting...\")\n",
      "    t2 = time.perf_counter()\n",
      "    data.sort()   # in-place Timsort\n",
      "    t3 = time.perf_counter()\n",
      "    print(f\"Sorting took {t3 - t2:.3f} seconds.\")\n",
      "\n",
      "    print(\"Verifying sorted order...\")\n",
      "    t4 = time.perf_counter()\n",
      "    ok = is_sorted(data)\n",
      "    t5 = time.perf_counter()\n",
      "    print(f\"Verification took {t5 - t4:.3f} seconds. Sorted: {ok}\")\n",
      "\n",
      "    # Example: print first/last 3 values\n",
      "    print(\"First 3:\", data[:3])\n",
      "    print(\"Last 3:\", data[-3:])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "NumPy version (recommended for performance and memory)\n",
      "- Requires NumPy installed (pip install numpy).\n",
      "- Uses np.random.rand for fast generation and np.sort or ndarray.sort for sorting.\n",
      "- Much less memory overhead: 1,000,000 float64 values use ~8 MB, whereas a Python list of float objects can use dozens of megabytes more.\n",
      "\n",
      "Save as sort_random_numpy.py and run: python sort_random_numpy.py\n",
      "\n",
      "```python\n",
      "#!/usr/bin/env python3\n",
      "\"\"\"\n",
      "Generate and sort N random numbers using NumPy.\n",
      "Default N = 1_000_000. Use --count to override.\n",
      "Requires: numpy\n",
      "\"\"\"\n",
      "import argparse\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "def main():\n",
      "    parser = argparse.ArgumentParser(description=\"Generate and sort random numbers (NumPy).\")\n",
      "    parser.add_argument(\"--count\", \"-n\", type=int, default=1_000_000,\n",
      "                        help=\"Number of random numbers to generate (default: 1_000_000)\")\n",
      "    parser.add_argument(\"--seed\", type=int, default=None, help=\"Optional random seed\")\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    n = args.count\n",
      "    if args.seed is not None:\n",
      "        np.random.seed(args.seed)\n",
      "\n",
      "    print(f\"Generating {n:,} random floats with NumPy...\")\n",
      "    t0 = time.perf_counter()\n",
      "    data = np.random.rand(n)   # float64 by default\n",
      "    t1 = time.perf_counter()\n",
      "    print(f\"Generation took {t1 - t0:.3f} seconds.\")\n",
      "\n",
      "    print(\"Sorting (in-place) with ndarray.sort()...\")\n",
      "    t2 = time.perf_counter()\n",
      "    data.sort()  # in-place sort\n",
      "    t3 = time.perf_counter()\n",
      "    print(f\"Sorting took {t3 - t2:.3f} seconds.\")\n",
      "\n",
      "    print(\"Verifying sorted order...\")\n",
      "    t4 = time.perf_counter()\n",
      "    ok = np.all(np.diff(data) >= 0)\n",
      "    t5 = time.perf_counter()\n",
      "    print(f\"Verification took {t5 - t4:.3f} seconds. Sorted: {bool(ok)}\")\n",
      "\n",
      "    # Example: print first/last 3 values\n",
      "    print(\"First 3:\", data[:3])\n",
      "    print(\"Last 3:\", data[-3:])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "Notes, tips, and expected behavior\n",
      "- Speed: NumPy will typically be faster for generation and use much less memory, because it stores numbers in a contiguous C array (8 bytes per float64). Pure-Python lists have per-object overhead (tens of bytes per float), and list generation + sorting will incur more Python-level overhead.\n",
      "- Sorting complexity: both approaches use comparison-based sorts (Timsort for list.sort, quicksort/mergesort/heap variants in NumPy depending on algorithm choice) with typical O(n log n) runtime.\n",
      "- If you only need a few smallest/largest values (e.g., top-k), consider heapq.nsmallest/nlargest or numpy.partition which can be faster than a full sort.\n",
      "- If you want reproducible results, pass a fixed seed (see --seed).\n",
      "- If memory becomes an issue and you only need to produce sorted output, consider external sorting methods (e.g., sort chunks and merge on disk) or using array.array('d') or memory-mapped files via numpy.memmap.\n",
      "\n",
      "If you want, I can:\n",
      "- Provide a version that writes/reads from disk and performs an external merge sort to handle arbitrarily large arrays with limited memory.\n",
      "- Provide a version that finds only the k smallest or k largest items more efficiently than sorting the whole list.\n",
      "Tokens => input: 21 | output: 2176\n"
     ]
    }
   ],
   "source": [
    "ask_with_verbosity(\"high\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bac4a4",
   "metadata": {},
   "source": [
    "High verbosity yielded additional details and explanations. \n",
    "\n",
    "### 1.3 Takeaways \n",
    "\n",
    "The new verbosity parameter reliably scales both the length and depth of the model’s output while preserving correctness and reasoning quality - **without changing the underlying prompt**.\n",
    "In this example:\n",
    "\n",
    "- **Low verbosity** produces a minimal, functional script with no extra comments or structure.\n",
    "- **Medium verbosity** adds explanatory comments, function structure, and reproducibility controls.\n",
    "- **High verbosity** yields a comprehensive, production-ready script with argument parsing, multiple sorting methods, timing/verification, usage notes, and best-practice tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aae97",
   "metadata": {},
   "source": [
    "## 2. Free‑Form Function Calling\n",
    "\n",
    "### 2.1 Overview \n",
    "GPT‑5 can now send raw text payloads - anything from Python scripts to SQL queries - to your custom tool without wrapping the data in JSON using the new tool `\"type\": \"custom\"`. This differs from classic structured function calls, giving you greater flexibility when interacting with external runtimes such as:\n",
    "\n",
    "- code_exec with sandboxes (Python, C++, Java, …)\n",
    "- SQL databases\n",
    "- Shell environments\n",
    "- Configuration generators\n",
    "\n",
    "**Note that custom tool type does NOT support parallel tool calling.**\n",
    "\n",
    "### 2.2 Quick Start Example - Compute the Area of a Circle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d3e73",
   "metadata": {},
   "source": [
    "The code below produces a simple python code to calculate area of a circle, and instruct the model to use the free-form tool call to output the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d3f9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseReasoningItem(id='rs_6894d0c323d481a2b727907746def8ec03e38603225fe1bd', summary=[], type='reasoning', content=[], encrypted_content=None, status=None), ResponseOutputMessage(id='ctc_6894d0c4917881a29923bb525509b34003e38603225fe1bd', content=None, role=None, status='completed', type='custom_tool_call', call_id='call_1ACilrk0d1DISLvW4Q2iE0jc', input='# Calculate the area of a circle where radius = number of \\'r\\'s in \"strawberry\"\\nimport math\\nradius = \"strawberry\".count(\\'r\\')\\narea = math.pi * radius**2\\n{\"radius\": radius, \"area\": area, \"area_exact\": f\"{radius**2}*pi\"}', name='code_exec')]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"Please use the code_exec tool to calculate the area of a circle with radius equal to the number of 'r's in strawberry\",\n",
    "    text={\"format\": {\"type\": \"text\"}},\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"custom\",\n",
    "            \"name\": \"code_exec\",\n",
    "            \"description\": \"Executes arbitrary python code\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d6a2c",
   "metadata": {},
   "source": [
    "The model emits a `tool call` containing raw Python. You execute that code server‑side, capture the printed result, and send it back in a follow‑up responses.create call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6c39c",
   "metadata": {},
   "source": [
    "### 2.3 Mini‑Benchmark – Sorting an Array in Three Languages\n",
    "To illustrate the use of free form tool calling, we will ask GPT‑5 to:\n",
    "- Generate Python, C++, and Java code that sorts a fixed array 10 times.\n",
    "- Print only the time (in ms) taken for each iteration in the code. \n",
    "- Call all three functions, and then stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9ca32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- tool name ---\n",
      "code_exec_python\n",
      "--- tool call argument (generated code) ---\n",
      "arr_orig = [448, 986, 255, 884, 632, 623, 246, 439, 936, 925, 644, 159, 777, 986, 706, 723, 534, 862, 195, 686, 846, 880, 970, 276, 613, 736, 329, 622, 870, 284, 945, 708, 267, 327, 678, 807, 687, 890, 907, 645, 364, 333, 385, 262, 730, 603, 945, 358, 923, 930, 761, 504, 870, 561, 517, 928, 994, 949, 233, 137, 670, 555, 149, 870, 997, 809, 180, 498, 914, 508, 411, 378, 394, 368, 766, 486, 757, 319, 338, 159, 585, 934, 654, 194, 542, 188, 934, 163, 889, 736, 792, 737, 667, 772, 198, 971, 459, 402, 989, 949]\n",
      "\n",
      "import time\n",
      "\n",
      "start = time.perf_counter_ns()\n",
      "for _ in range(10):\n",
      "    arr = arr_orig.copy()\n",
      "    arr.sort()\n",
      "elapsed_ms = (time.perf_counter_ns() - start) // 1_000_000\n",
      "print(elapsed_ms)\n",
      "--- tool name ---\n",
      "code_exec_cpp\n",
      "--- tool call argument (generated code) ---\n",
      "#include <algorithm>\n",
      "#include <vector>\n",
      "#include <chrono>\n",
      "#include <iostream>\n",
      "int main() {\n",
      "    std::vector<int> orig = {448, 986, 255, 884, 632, 623, 246, 439, 936, 925, 644, 159, 777, 986, 706, 723, 534, 862, 195, 686, 846, 880, 970, 276, 613, 736, 329, 622, 870, 284, 945, 708, 267, 327, 678, 807, 687, 890, 907, 645, 364, 333, 385, 262, 730, 603, 945, 358, 923, 930, 761, 504, 870, 561, 517, 928, 994, 949, 233, 137, 670, 555, 149, 870, 997, 809, 180, 498, 914, 508, 411, 378, 394, 368, 766, 486, 757, 319, 338, 159, 585, 934, 654, 194, 542, 188, 934, 163, 889, 736, 792, 737, 667, 772, 198, 971, 459, 402, 989, 949};\n",
      "    auto start = std::chrono::steady_clock::now();\n",
      "    for (int i = 0; i < 10; ++i) {\n",
      "        auto arr = orig;\n",
      "        std::sort(arr.begin(), arr.end());\n",
      "    }\n",
      "    auto end = std::chrono::steady_clock::now();\n",
      "    auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n",
      "    std::cout << ms << std::endl;\n",
      "    return 0;\n",
      "}\n",
      "--- tool name ---\n",
      "code_exec_java\n",
      "--- tool call argument (generated code) ---\n",
      "import java.util.Arrays;\n",
      "public class Main {\n",
      "    public static void main(String[] args) {\n",
      "        int[] orig = new int[] {448, 986, 255, 884, 632, 623, 246, 439, 936, 925, 644, 159, 777, 986, 706, 723, 534, 862, 195, 686, 846, 880, 970, 276, 613, 736, 329, 622, 870, 284, 945, 708, 267, 327, 678, 807, 687, 890, 907, 645, 364, 333, 385, 262, 730, 603, 945, 358, 923, 930, 761, 504, 870, 561, 517, 928, 994, 949, 233, 137, 670, 555, 149, 870, 997, 809, 180, 498, 914, 508, 411, 378, 394, 368, 766, 486, 757, 319, 338, 159, 585, 934, 654, 194, 542, 188, 934, 163, 889, 736, 792, 737, 667, 772, 198, 971, 459, 402, 989, 949};\n",
      "        long start = System.nanoTime();\n",
      "        for (int i = 0; i < 10; i++) {\n",
      "            int[] arr = Arrays.copyOf(orig, orig.length);\n",
      "            Arrays.sort(arr);\n",
      "        }\n",
      "        long elapsedMs = (System.nanoTime() - start) / 1_000_000;\n",
      "        System.out.println(elapsedMs);\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List, Optional\n",
    "\n",
    "MODEL_NAME = \"gpt-5\"\n",
    "\n",
    "# Tools that will be passed to every model invocation. They are defined once so\n",
    "# that the configuration lives in a single place.\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"custom\",\n",
    "        \"name\": \"code_exec_python\",\n",
    "        \"description\": \"Executes python code\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"custom\",\n",
    "        \"name\": \"code_exec_cpp\",\n",
    "        \"description\": \"Executes c++ code\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"custom\",\n",
    "        \"name\": \"code_exec_java\",\n",
    "        \"description\": \"Executes java code\",\n",
    "    },\n",
    "]\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def create_response(\n",
    "    input_messages: List[dict],\n",
    "    previous_response_id: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Wrapper around ``client.responses.create``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_messages: List[dict]\n",
    "        The running conversation history to feed to the model.\n",
    "    previous_response_id: str | None\n",
    "        Pass the ``response.id`` from the *previous* call so the model can keep\n",
    "        the thread of the conversation.  Omit on the very first request.\n",
    "    \"\"\"\n",
    "    kwargs = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"input\": input_messages,\n",
    "        \"text\": {\"format\": {\"type\": \"text\"}},\n",
    "        \"tools\": TOOLS,\n",
    "    }\n",
    "    if previous_response_id:\n",
    "        kwargs[\"previous_response_id\"] = previous_response_id\n",
    "\n",
    "    return client.responses.create(**kwargs)\n",
    "\n",
    "# Recursive \n",
    "def run_conversation(\n",
    "    input_messages: List[dict],\n",
    "    previous_response_id: Optional[str] = None,\n",
    "):\n",
    "  \n",
    "    response = create_response(input_messages, previous_response_id)\n",
    "\n",
    "    # ``response.output`` is expected to be a list where element 0 is the model\n",
    "    # message.  Element 1 (if present) denotes a tool call.  When the model is\n",
    "    # done with tool calls, that element is omitted.\n",
    "    tool_call = response.output[1] if len(response.output) > 1 else None\n",
    "\n",
    "    if tool_call and tool_call.type == \"custom_tool_call\":\n",
    "        print(\"--- tool name ---\")\n",
    "        print(tool_call.name)\n",
    "        print(\"--- tool call argument (generated code) ---\")\n",
    "        print(tool_call.input)\n",
    "        \n",
    "        # Add a synthetic *tool result* so the model can continue the thread.\n",
    "        \n",
    "        input_messages.append(\n",
    "            {\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": tool_call.call_id,\n",
    "                \"output\": \"done\", # <-- replace with the result of the tool call\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Recurse with updated conversation and track the response id so the\n",
    "        # model is aware of the prior turn.\n",
    "        return run_conversation(input_messages, previous_response_id=response.id)\n",
    "    else:\n",
    "        # Base-case: no further tool call - return. \n",
    "        return \n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write code to sort the array of numbers in three languages: C++, Python and Java (10 times each)using code_exec functions.\n",
    "\n",
    "ALWAYS CALL THESE THREE FUNCTIONS EXACTLY ONCE: code_exec_python, code_exec_cpp and code_exec_java tools to sort the array in each language. Stop once you've called these three functions in each language once.\n",
    "\n",
    "Print only the time it takes to sort the array in milliseconds. \n",
    "\n",
    "[448, 986, 255, 884, 632, 623, 246, 439, 936, 925, 644, 159, 777, 986, 706, 723, 534, 862, 195, 686, 846, 880, 970, 276, 613, 736, 329, 622, 870, 284, 945, 708, 267, 327, 678, 807, 687, 890, 907, 645, 364, 333, 385, 262, 730, 603, 945, 358, 923, 930, 761, 504, 870, 561, 517, 928, 994, 949, 233, 137, 670, 555, 149, 870, 997, 809, 180, 498, 914, 508, 411, 378, 394, 368, 766, 486, 757, 319, 338, 159, 585, 934, 654, 194, 542, 188, 934, 163, 889, 736, 792, 737, 667, 772, 198, 971, 459, 402, 989, 949]\n",
    "\"\"\"\n",
    "\n",
    "# Initial developer message.\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": prompt,\n",
    "    }\n",
    "]\n",
    "\n",
    "run_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ffea8",
   "metadata": {},
   "source": [
    "The model output three code blocks in Python, C++ and Java for the same algorithm. The output of the function call was chained back into the model as input to allow model to keep going until all the functions have been called exactly once. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12057763",
   "metadata": {},
   "source": [
    "### 2.4 Takeaways \n",
    "\n",
    "Free-form tool calling in GPT-5 lets you send raw text payloads—such as Python scripts, SQL queries, or config files—directly to custom tools without JSON wrapping. This provides greater flexibility for interacting with external runtimes and allows the model to generate code or text in the exact format your tool expects. It’s ideal when structured JSON is unnecessary and natural text output improves usability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99fc436",
   "metadata": {},
   "source": [
    "## 3. Context‑Free Grammar (CFG)\n",
    "\n",
    "### 3.1 Overview \n",
    "A context‑free grammar is a collection of production rules that define which strings belong to a language. Each rule rewrites a non‑terminal symbol into a sequence of terminals (literal tokens) and/or other non‑terminals, independent of surrounding context—hence context‑free. CFGs can capture the syntax of most programming languages and, in OpenAI custom tools, serve as contracts that force the model to emit only strings that the grammar accepts.\n",
    "\n",
    "### 3.2 Grammar Fundamentals\n",
    "\n",
    "**Supported Grammar Syntax** \n",
    "- Lark - https://lark-parser.readthedocs.io/en/stable/\n",
    "- Regex - https://docs.rs/regex/latest/regex/#syntax\n",
    "\n",
    "We use LLGuidance under the hood to constrain model sampling: https://github.com/guidance-ai/llguidance.\n",
    "\n",
    "**Unsupported Lark Features** \n",
    "- Lookaround in regexes (`(?=...)`, `(?!...)`, etc.)\n",
    "- Lazy modifier (`*?`, `+?`, `??`) in regexes.\n",
    "- Terminal priorities, templates, %declares, %import (except %import common).\n",
    "\n",
    "\n",
    "**Terminals vs Rules & Greedy Lexing** \n",
    "\n",
    "| Concept          | Take-away                                                                    |\n",
    "|------------------|------------------------------------------------------------------------------|\n",
    "| Terminals (UPPER)| Matched first by the lexer – longest match wins.                             |\n",
    "| Rules (lower)    | Combine terminals; cannot influence how text is tokenised.                   |\n",
    "| Greedy lexer     | Never try to “shape” free text across multiple terminals – you’ll lose control. |\n",
    "\n",
    "** Correct vs Incorrect Pattern Design\n",
    "\n",
    "✅ **One bounded terminal handles free‑text between anchors**  \n",
    "start: SENTENCE  \n",
    "SENTENCE: /[A-Za-z, ]*(the hero|a dragon)[A-Za-z, ]*(fought|saved)[A-Za-z, ]*(a treasure|the kingdom)[A-Za-z, ]*\\./  \n",
    "\n",
    "❌ **Don’t split free‑text across multiple terminals/rules**  \n",
    "start: sentence  \n",
    "sentence: /[A-Za-z, ]+/ subject /[A-Za-z, ]+/ verb /[A-Za-z, ]+/ object /[A-Za-z, ]+/  \n",
    "\n",
    "\n",
    "### 3.3 Example - SQL Dialect — MS SQL vs PostgreSQL\n",
    "\n",
    "The following code example is now the canonical reference for building multi‑dialect SQL tools with CFGs. It demonstrates:\n",
    "\n",
    "- Two isolated grammar definitions (`mssql_grammar_definition`, `postgres_grammar_definition`) encoding TOP vs LIMIT semantics.\n",
    "- How to prompt, invoke, and inspect tool calls in a single script.\n",
    "- A side‑by‑side inspection of the assistant’s responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b27f06",
   "metadata": {},
   "source": [
    "Define the LARK grammars for different SQL dialects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e7f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# ----------------- grammars for MS SQL dialect -----------------\n",
    "mssql_grammar = textwrap.dedent(r\"\"\"\n",
    "            // ---------- Punctuation & operators ----------\n",
    "            SP: \" \"\n",
    "            COMMA: \",\"\n",
    "            GT: \">\"\n",
    "            EQ: \"=\"\n",
    "            SEMI: \";\"\n",
    "\n",
    "            // ---------- Start ----------\n",
    "            start: \"SELECT\" SP \"TOP\" SP NUMBER SP select_list SP \"FROM\" SP table SP \"WHERE\" SP amount_filter SP \"AND\" SP date_filter SP \"ORDER\" SP \"BY\" SP sort_cols SEMI\n",
    "\n",
    "            // ---------- Projections ----------\n",
    "            select_list: column (COMMA SP column)*\n",
    "            column: IDENTIFIER\n",
    "\n",
    "            // ---------- Tables ----------\n",
    "            table: IDENTIFIER\n",
    "\n",
    "            // ---------- Filters ----------\n",
    "            amount_filter: \"total_amount\" SP GT SP NUMBER\n",
    "            date_filter: \"order_date\" SP GT SP DATE\n",
    "\n",
    "            // ---------- Sorting ----------\n",
    "            sort_cols: \"order_date\" SP \"DESC\"\n",
    "\n",
    "            // ---------- Terminals ----------\n",
    "            IDENTIFIER: /[A-Za-z_][A-Za-z0-9_]*/\n",
    "            NUMBER: /[0-9]+/\n",
    "            DATE: /'[0-9]{4}-[0-9]{2}-[0-9]{2}'/\n",
    "    \"\"\")\n",
    "\n",
    "# ----------------- grammars for PostgreSQL dialect -----------------\n",
    "postgres_grammar = textwrap.dedent(r\"\"\"\n",
    "            // ---------- Punctuation & operators ----------\n",
    "            SP: \" \"\n",
    "            COMMA: \",\"\n",
    "            GT: \">\"\n",
    "            EQ: \"=\"\n",
    "            SEMI: \";\"\n",
    "\n",
    "            // ---------- Start ----------\n",
    "            start: \"SELECT\" SP select_list SP \"FROM\" SP table SP \"WHERE\" SP amount_filter SP \"AND\" SP date_filter SP \"ORDER\" SP \"BY\" SP sort_cols SP \"LIMIT\" SP NUMBER SEMI\n",
    "\n",
    "            // ---------- Projections ----------\n",
    "            select_list: column (COMMA SP column)*\n",
    "            column: IDENTIFIER\n",
    "\n",
    "            // ---------- Tables ----------\n",
    "            table: IDENTIFIER\n",
    "\n",
    "            // ---------- Filters ----------\n",
    "            amount_filter: \"total_amount\" SP GT SP NUMBER\n",
    "            date_filter: \"order_date\" SP GT SP DATE\n",
    "\n",
    "            // ---------- Sorting ----------\n",
    "            sort_cols: \"order_date\" SP \"DESC\"\n",
    "\n",
    "            // ---------- Terminals ----------\n",
    "            IDENTIFIER: /[A-Za-z_][A-Za-z0-9_]*/\n",
    "            NUMBER: /[0-9]+/\n",
    "            DATE: /'[0-9]{4}-[0-9]{2}-[0-9]{2}'/\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24814e5",
   "metadata": {},
   "source": [
    "### 3.4 Generate specific SQL dialect \n",
    "Let's define the prompt, and call the function to produce MS SQL dialect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e316744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MS SQL Query ---\n",
      "SELECT TOP 5 customer_id, order_id, order_date, total_amount FROM orders WHERE total_amount > 500 AND order_date > '2025-01-01' ORDER BY order_date DESC;\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "sql_prompt_mssql = (\n",
    "    \"Call the mssql_grammar to generate a query for Microsoft SQL Server that retrieve the \"\n",
    "    \"five most recent orders per customer, showing customer_id, order_id, order_date, and total_amount, \"\n",
    "    \"where total_amount > 500 and order_date is after '2025-01-01'. \"\n",
    ")\n",
    "\n",
    "response_mssql = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=sql_prompt_mssql,\n",
    "    text={\"format\": {\"type\": \"text\"}},\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"custom\",\n",
    "            \"name\": \"mssql_grammar\",\n",
    "            \"description\": \"Executes read-only Microsoft SQL Server queries limited to SELECT statements with TOP and basic WHERE/ORDER BY. YOU MUST REASON HEAVILY ABOUT THE QUERY AND MAKE SURE IT OBEYS THE GRAMMAR.\",\n",
    "            \"format\": {\n",
    "                \"type\": \"grammar\",\n",
    "                \"syntax\": \"lark\",\n",
    "                \"definition\": mssql_grammar\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    parallel_tool_calls=False\n",
    ")\n",
    "\n",
    "print(\"--- MS SQL Query ---\")\n",
    "print(response_mssql.output[1].input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93f4fb",
   "metadata": {},
   "source": [
    "The output SQL accurately uses \"SELECT TOP\" construct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PG SQL Query ---\n",
      "SELECT customer_id, order_id, order_date, total_amount FROM orders WHERE total_amount > 500 AND order_date > '2025-01-01' ORDER BY order_date DESC LIMIT 5;\n"
     ]
    }
   ],
   "source": [
    "sql_prompt_pg = (\n",
    "    \"Call the postgres_grammar to generate a query for PostgreSQL that retrieve the \"\n",
    "    \"five most recent orders per customer, showing customer_id, order_id, order_date, and total_amount, \"\n",
    "    \"where total_amount > 500 and order_date is after '2025-01-01'. \"\n",
    ")\n",
    "\n",
    "response_pg = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=sql_prompt_pg,\n",
    "    text={\"format\": {\"type\": \"text\"}},\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"custom\",\n",
    "            \"name\": \"postgres_grammar\",\n",
    "            \"description\": \"Executes read-only PostgreSQL queries limited to SELECT statements with LIMIT and basic WHERE/ORDER BY. YOU MUST REASON HEAVILY ABOUT THE QUERY AND MAKE SURE IT OBEYS THE GRAMMAR.\",\n",
    "            \"format\": {\n",
    "                \"type\": \"grammar\",\n",
    "                \"syntax\": \"lark\",\n",
    "                \"definition\": postgres_grammar\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "print(\"--- PG SQL Query ---\")\n",
    "print(response_pg.output[1].input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f14ce3",
   "metadata": {},
   "source": [
    "Output highlights the same logical query - different physical syntax. Supply distinct grammars so the model can only produce valid statements for the chosen dialect.\n",
    "\n",
    "| Dialect       | Generated Query                                              | Key Difference                          |\n",
    "|---------------|--------------------------------------------------------------|------------------------------------------|\n",
    "| MS SQL Server | SELECT TOP 5 customer_id, … ORDER BY order_date DESC;         | Uses `TOP N` clause before column list.  |\n",
    "| PostgreSQL    | SELECT customer_id, … ORDER BY order_date DESC LIMIT 5;       | Uses `LIMIT N` after `ORDER BY`.         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27dc7cc",
   "metadata": {},
   "source": [
    "### 3.5 Example - Regex CFG Syntax\n",
    "\n",
    "The following code example demonstrates using the Regex CFG syntax to constrain the free-form tool call to a certain timestamp pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9e2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Timestamp ---\n",
      "2025-08-07 10:00\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "timestamp_grammar_definition = r\"^\\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01]) (?:[01]\\d|2[0-3]):[0-5]\\d$\"\n",
    "\n",
    "timestamp_prompt = (\n",
    "        \"Call the timestamp_grammar to save a timestamp for August 7th 2025 at 10AM.\"\n",
    ")\n",
    "\n",
    "response_mssql = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=timestamp_prompt,\n",
    "    text={\"format\": {\"type\": \"text\"}},\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"custom\",\n",
    "            \"name\": \"timestamp_grammar\",\n",
    "            \"description\": \"Saves a timestamp in date + time in 24-hr format.\",\n",
    "            \"format\": {\n",
    "                \"type\": \"grammar\",\n",
    "                \"syntax\": \"regex\",\n",
    "                \"definition\": timestamp_grammar_definition\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    parallel_tool_calls=False\n",
    ")\n",
    "\n",
    "print(\"--- Timestamp ---\")\n",
    "print(response_mssql.output[1].input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2b86a",
   "metadata": {},
   "source": [
    "### 3.5 Best Practices\n",
    "\n",
    "Lark grammars can be tricky to perfect. While simple grammars perform most reliably, complex grammars often require iteration on the grammar definition itself, the prompt, and the tool description to ensure that the model does not go out of distribution.\n",
    "\n",
    "- Keep terminals bounded – use `/[^.\\n]{0,10}*\\./` rather than `/.*\\./`. Limit matches both by content (negated character class) and by length (`{M,N}` quantifier). \n",
    "- Prefer explicit char‑classes over `.` wildcards.\n",
    "- Thread whitespace explicitly, e.g. using `SP = \" \"`, instead of a global `%ignore`.\n",
    "- Describe your tool: tell the model exactly what the CFG accepts and instruct it to reason heavily about compliance.\n",
    "\n",
    "**Troubleshooting**\n",
    "- API rejects the grammar because it is too complex ➜ Simplify rules and terminals, remove `%ignore.*`.\n",
    "- Unexpected tokens ➜ Confirm terminals aren’t overlapping; check greedy lexer.\n",
    "- When the model drifts \"out‑of‑distribution\" (shows up as the model producing excessively long or repetitive outputs, it is syntactically valid but is semantically wrong):\n",
    "    - Tighten the grammar.\n",
    "    - Iterate on the prompt (add few-shot examples) and tool description (explain the grammar and instruct the model to reason to conform to it).\n",
    "    - Experiment with a higher reasoning effort (e.g, bump from medium to high).\n",
    "\n",
    "**Resources:**  \n",
    "- Lark Docs – https://lark-parser.readthedocs.io/en/stable/\n",
    "- Lark IDE – https://www.lark-parser.org/ide/\n",
    "- LLGuidance Syntax – https://github.com/guidance-ai/llguidance/blob/main/docs/syntax.md\n",
    "- Regex (Rust crate) – https://docs.rs/regex/latest/regex/#syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ef909",
   "metadata": {},
   "source": [
    "### 3.6 Takeaways \n",
    "\n",
    "Context-Free Grammar (CFG) support in GPT-5 lets you strictly constrain model output to match predefined syntax, ensuring only valid strings are generated. This is especially useful for enforcing programming language rules or custom formats, reducing post-processing and errors. By providing a precise grammar and clear tool description, you can make the model reliably stay within your target output structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
