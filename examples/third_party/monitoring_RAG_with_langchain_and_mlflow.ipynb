{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montioring a RAG chain with OpenAI, LangChain, and MLflow\n",
    "\n",
    "This notebook is a quick tutorial on how to use [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html) to improve observability in your Retrieval Augmented Generation (RAG) application. RAG chains can be complex with many steps involved, and when failures or unexpected responses happen, it can be difficult to pinpoint what exactly went wrong. MLflow Tracing helps by allowing you to view the inputs and outputs of each intermediate step in your workflow, which enables more effective debugging and iteration.\n",
    "\n",
    "We'll be building a simple question answering app in this notebook. For convenience, we're using [LangChain](https://www.langchain.com/) here (as MLflow has a built-in integration with it), but traces can be instrumented manually to suit any use-case. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "The following cells simply set up our dev environment, installing the necessary libraries, and setting our OpenAI key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37f22b58-df54-4edf-828b-9b5a73bc2c59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -Uqq mlflow langchain langchain-chroma langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "def774e0-018a-45a5-b946-b1716b34748c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling tracing\n",
    "\n",
    "When using LangChain, tracing is enabled automatically by simply calling `mlflow.langchain.autolog()`. Manual trace instrumentation is also possible via the `@mlflow.trace()` function decorator. For more details, please check out the [MLflow Docs](https://mlflow.org/docs/latest/llms/tracing/index.html#trace-decorator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c06d675c-7f12-4fda-aabf-80deed153f9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/05 13:55:08 INFO mlflow.tracking.fluent: Experiment with name 'openai-rag-demo' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"openai-rag-demo\")\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our vector store\n",
    "\n",
    "The first step when building a RAG app is embedding our documents. Here, we'll be using OpenAI's `text-embedding-3-small` model to generate the embeddings, and storing them in an in-memory [Chroma](https://docs.trychroma.com/) instance. We'll be querying this vector store later to fetch documents that are relevant to the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c189e01-aaab-4e68-baeb-84b8a99b9b9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"NumPy is a powerful Python library used for numerical computing. It provides support for large multidimensional arrays and matrices along with a collection of high-level mathematical functions.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Pandas is a Python library primarily used for data manipulation and analysis. It provides data structures like DataFrame, which makes working with structured data intuitive and efficient.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"PyTorch is an open-source machine learning library. It is widely used for deep learning applications and provides dynamic computational graphs for flexibility.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Langchain is an open-source library designed to build applications powered by language models. It provides a flexible interface to chain together components like prompts, memory, and tools.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Provide the `persist_directory` argument to save the vector store to disk\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our chain\n",
    "\n",
    "Our full RAG chain has the following steps:\n",
    "\n",
    "1. Embed the question and fetch relevant documents\n",
    "2. Construct a prompt using the fetched documents\n",
    "3. Feed the prompt to the chat model (in this case, we'll be using OpenAI's `gpt-4o-mini`)\n",
    "\n",
    "The following cell sets each of these steps up, and links them together to produce the final chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29626f0c-2b1d-4511-b8c6-3851fafb0574",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# This handles Step #1. The retriever will be invoked using the user's question,\n",
    "# and will perform a similarity search over the embedded documents to retrieve\n",
    "# the top 3 most relevant ones.\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# This handles Step #2. Placeholders are used to inject\n",
    "# both the user's question and the retrieved context.\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question using the provided context. If the information\n",
    "required to answer the question is not contained within the context, simply\n",
    "respond that you do not know.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "# This handles Step #3. Feel free to change the\n",
    "# parameters of the modelto whatever you wish!\n",
    "chat_model = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0,\n",
    "  max_tokens=50,\n",
    ")\n",
    "\n",
    "# Finally, we link them all together using LangChain Expression Language's pipe operator \n",
    "chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65551fad-e8e7-4f43-86fa-6b78ef672a96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 156, 'total_tokens': 188}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-38b81240-02a0-42ee-8d23-26c3460b7c7f-0', usage_metadata={'input_tokens': 156, 'output_tokens': 32, 'total_tokens': 188})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can simply invoke the chain with our question,\n",
    "# and the full pipeline will be executed!\n",
    "chain.invoke(\"What is MLflow?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the trace\n",
    "\n",
    "After invoking the chain, MLflow will have automatically captured a trace of the execution. In order to view the trace, you can visit the MLflow UI. To start the MLflow UI, simply run the `mlflow ui` command in the working directory containing this notebook.\n",
    "\n",
    "The trace will be contained in the \"openai-rag-demo\" experiment, under the \"Traces\" tab:\n",
    "\n",
    "![MLflow Trace UI](../../images/mlflow_trace.png)\n",
    "\n",
    "This visualization allows you to easily step through the various intermediate steps in the chain's execution, and to see the inputs and outputs at a glance. The UI also supports searching through spans to make it easy to debug unexpected responses even in very large and complex applications.\n",
    "\n",
    "Of course, the trace data is accessible via the python client as well. Simply call `mlflow.get_last_active_trace()`, and call `.to_dict()` on the result to convert it to a python dictionary. The `mlflow.search_traces()` and `mlflow.get_trace()` [APIs](https://mlflow.org/docs/latest/llms/tracing/index.html#searching-and-retrieving-traces) are also available to retrieve traces given certain filter conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0a95ced-fbaa-4c87-9f39-039b5875a16d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'request_id': '82bce1ed74b84701906de60ce1a2003b',\n",
       "  'experiment_id': '871370117864542956',\n",
       "  'timestamp_ms': 1725515725835,\n",
       "  'execution_time_ms': 1032,\n",
       "  'status': 'OK',\n",
       "  'request_metadata': {'mlflow.trace_schema.version': '2',\n",
       "   'mlflow.traceInputs': '\"What is MLflow?\"',\n",
       "   'mlflow.traceOutputs': '{\"content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"additional_kwargs\": {\"refusal\": null}, \"response...'},\n",
       "  'tags': {'mlflow.source.name': '/Users/daniel.lok/miniconda3/envs/dev/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       "   'mlflow.source.type': 'LOCAL',\n",
       "   'mlflow.traceName': 'RunnableSequence',\n",
       "   'mlflow.artifactLocation': 'file:///Users/daniel.lok/openai-cookbook/examples/third_party/mlruns/871370117864542956/traces/82bce1ed74b84701906de60ce1a2003b/artifacts'}},\n",
       " 'data': {'spans': [{'name': 'RunnableSequence',\n",
       "    'context': {'span_id': '0x7f0ed06df406464e',\n",
       "     'trace_id': '0x7d9eb5f7ad9ef0c437891051d01ce025'},\n",
       "    'parent_id': None,\n",
       "    'start_time': 1725515725835949000,\n",
       "    'end_time': 1725515726868545000,\n",
       "    'status_code': 'OK',\n",
       "    'status_message': '',\n",
       "    'attributes': {'mlflow.traceRequestId': '\"82bce1ed74b84701906de60ce1a2003b\"',\n",
       "     'mlflow.spanType': '\"CHAIN\"',\n",
       "     'mlflow.spanInputs': '\"What is MLflow?\"',\n",
       "     'mlflow.spanOutputs': '{\"content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 32, \"prompt_tokens\": 156, \"total_tokens\": 188}, \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_f33667828e\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"name\": null, \"id\": \"run-38b81240-02a0-42ee-8d23-26c3460b7c7f-0\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": {\"input_tokens\": 156, \"output_tokens\": 32, \"total_tokens\": 188}}'},\n",
       "    'events': []},\n",
       "   {'name': 'RunnableParallel<context,question>',\n",
       "    'context': {'span_id': '0x010119b4ab14613f',\n",
       "     'trace_id': '0x7d9eb5f7ad9ef0c437891051d01ce025'},\n",
       "    'parent_id': '0x7f0ed06df406464e',\n",
       "    'start_time': 1725515725836845000,\n",
       "    'end_time': 1725515726136285000,\n",
       "    'status_code': 'OK',\n",
       "    'status_message': '',\n",
       "    'attributes': {'mlflow.traceRequestId': '\"82bce1ed74b84701906de60ce1a2003b\"',\n",
       "     'mlflow.spanType': '\"CHAIN\"',\n",
       "     'mlflow.spanInputs': '\"What is MLflow?\"',\n",
       "     'mlflow.spanOutputs': '{\"context\": [{\"id\": null, \"metadata\": {}, \"page_content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {}, \"page_content\": \"Langchain is an open-source library designed to build applications powered by language models. It provides a flexible interface to chain together components like prompts, memory, and tools.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {}, \"page_content\": \"PyTorch is an open-source machine learning library. It is widely used for deep learning applications and provides dynamic computational graphs for flexibility.\", \"type\": \"Document\"}], \"question\": \"What is MLflow?\"}'},\n",
       "    'events': []},\n",
       "   {'name': 'VectorStoreRetriever',\n",
       "    'context': {'span_id': '0x0a9b083a91cc6676',\n",
       "     'trace_id': '0x7d9eb5f7ad9ef0c437891051d01ce025'},\n",
       "    'parent_id': '0x010119b4ab14613f',\n",
       "    'start_time': 1725515725837351000,\n",
       "    'end_time': 1725515726135965000,\n",
       "    'status_code': 'OK',\n",
       "    'status_message': '',\n",
       "    'attributes': {'mlflow.traceRequestId': '\"82bce1ed74b84701906de60ce1a2003b\"',\n",
       "     'mlflow.spanType': '\"RETRIEVER\"',\n",
       "     'metadata': '{\"ls_retriever_name\": \"vectorstore\", \"ls_vector_store_provider\": \"Chroma\", \"ls_embedding_provider\": \"OpenAIEmbeddings\"}',\n",
       "     'mlflow.spanInputs': '\"What is MLflow?\"',\n",
       "     'mlflow.spanOutputs': '[{\"id\": null, \"metadata\": {}, \"page_content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {}, \"page_content\": \"Langchain is an open-source library designed to build applications powered by language models. It provides a flexible interface to chain together components like prompts, memory, and tools.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {}, \"page_content\": \"PyTorch is an open-source machine learning library. It is widely used for deep learning applications and provides dynamic computational graphs for flexibility.\", \"type\": \"Document\"}]'},\n",
       "    'events': []},\n",
       "   {'name': 'RunnablePassthrough',\n",
       "    'context': {'span_id': '0xf980a8695f8a21c6',\n",
       "     'trace_id': '0x7d9eb5f7ad9ef0c437891051d01ce025'},\n",
       "    'parent_id': '0x010119b4ab14613f',\n",
       "    'start_time': 1725515725837775000,\n",
       "    'end_time': 1725515725837891000,\n",
       "    'status_code': 'OK',\n",
       "    'status_message': '',\n",
       "    'attributes': {'mlflow.traceRequestId': '\"82bce1ed74b84701906de60ce1a2003b\"',\n",
       "     'mlflow.spanType': '\"CHAIN\"',\n",
       "     'mlflow.spanInputs': '\"What is MLflow?\"',\n",
       "     'mlflow.spanOutputs': '\"What is MLflow?\"'},\n",
       "    'events': []},\n",
       "   {'name': 'ChatPromptTemplate',\n",
       "    'context': {'span_id': '0x7e112b8c1864cdf9',\n",
       "     'trace_id': '0x7d9eb5f7ad9ef0c437891051d01ce025'},\n",
       "    'parent_id': '0x7f0ed06df406464e',\n",
       "    'start_time': 1725515726137398000,\n",
       "    'end_time': 1725515726137944000,\n",
       "    'status_code': 'OK',\n",
       "    'status_message': '',\n",
       "    'attributes': {'mlflow.traceRequestId': '\"82bce1ed74b84701906de60ce1a2003b\"',\n",
       "     'mlflow.spanType': '\"CHAIN\"',\n",
       "     'mlflow.spanInputs': '{\"context\": [{\"id\": null, \"metadata\": {}, \"page_content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {}, \"page_content\": \"Langchain is an open-source library designed to build applications powered by language models. It provides a flexible interface to chain together components like prompts, memory, and tools.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {}, \"page_content\": \"PyTorch is an open-source machine learning library. It is widely used for deep learning applications and provides dynamic computational graphs for flexibility.\", \"type\": \"Document\"}], \"question\": \"What is MLflow?\"}',\n",
       "     'mlflow.spanOutputs': '{\"messages\": [{\"content\": \"\\\\nAnswer the following question using the provided context. If the information\\\\nrequired to answer the question is not contained within the context, simply\\\\nrespond that you do not know.\\\\n\\\\nWhat is MLflow?\\\\n\\\\nContext:\\\\n[Document(page_content=\\'MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\\'), Document(page_content=\\'Langchain is an open-source library designed to build applications powered by language models. It provides a flexible interface to chain together components like prompts, memory, and tools.\\'), Document(page_content=\\'PyTorch is an open-source machine learning library. It is widely used for deep learning applications and provides dynamic computational graphs for flexibility.\\')]\\\\n\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null, \"example\": false}]}'},\n",
       "    'events': []},\n",
       "   {'name': 'ChatOpenAI',\n",
       "    'context': {'span_id': '0x6d660496b23240cb',\n",
       "     'trace_id': '0x7d9eb5f7ad9ef0c437891051d01ce025'},\n",
       "    'parent_id': '0x7f0ed06df406464e',\n",
       "    'start_time': 1725515726138593000,\n",
       "    'end_time': 1725515726868398000,\n",
       "    'status_code': 'OK',\n",
       "    'status_message': '',\n",
       "    'attributes': {'mlflow.traceRequestId': '\"82bce1ed74b84701906de60ce1a2003b\"',\n",
       "     'mlflow.spanType': '\"CHAT_MODEL\"',\n",
       "     'invocation_params': '{\"model\": \"gpt-4o-mini\", \"model_name\": \"gpt-4o-mini\", \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"max_tokens\": 50, \"_type\": \"openai-chat\", \"stop\": null}',\n",
       "     'options': '{\"stop\": null}',\n",
       "     'batch_size': '1',\n",
       "     'metadata': '{\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4o-mini\", \"ls_model_type\": \"chat\", \"ls_temperature\": 0.0, \"ls_max_tokens\": 50}',\n",
       "     'mlflow.spanInputs': '[[{\"content\": \"\\\\nAnswer the following question using the provided context. If the information\\\\nrequired to answer the question is not contained within the context, simply\\\\nrespond that you do not know.\\\\n\\\\nWhat is MLflow?\\\\n\\\\nContext:\\\\n[Document(page_content=\\'MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\\'), Document(page_content=\\'Langchain is an open-source library designed to build applications powered by language models. It provides a flexible interface to chain together components like prompts, memory, and tools.\\'), Document(page_content=\\'PyTorch is an open-source machine learning library. It is widely used for deep learning applications and provides dynamic computational graphs for flexibility.\\')]\\\\n\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null, \"example\": false}]]',\n",
       "     'mlflow.spanOutputs': '{\"generations\": [[{\"text\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 32, \"prompt_tokens\": 156, \"total_tokens\": 188}, \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_f33667828e\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"name\": null, \"id\": \"run-38b81240-02a0-42ee-8d23-26c3460b7c7f-0\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": {\"input_tokens\": 156, \"output_tokens\": 32, \"total_tokens\": 188}}}]], \"llm_output\": {\"token_usage\": {\"completion_tokens\": 32, \"prompt_tokens\": 156, \"total_tokens\": 188}, \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_f33667828e\"}, \"run\": null}'},\n",
       "    'events': []}],\n",
       "  'request': '\"What is MLflow?\"',\n",
       "  'response': '{\"content\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It supports tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 32, \"prompt_tokens\": 156, \"total_tokens\": 188}, \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_f33667828e\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"name\": null, \"id\": \"run-38b81240-02a0-42ee-8d23-26c3460b7c7f-0\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": {\"input_tokens\": 156, \"output_tokens\": 32, \"total_tokens\": 188}}'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_last_active_trace().to_dict()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "openai cookbook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
