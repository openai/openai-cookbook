{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfed8d7",
   "metadata": {},
   "source": [
    "# Semantic Search and Q&A using KDB.AI and OpenAI\n",
    "\n",
    "This guide demonstrates how to use KDB.AI to run fast and scalable semantic vector search on unstructured text documents using OpenAI API to generate embeddings.\n",
    "\n",
    "Semantic search allows users to perform searches based on the meaning or similarity of the data rather than exact matches. It works by converting the query into a vector representation and then finding similar vectors in the database. This way, even if the query and the data in the database are not identical, the system can identify and retrieve the most relevant results based on their semantic meaning.\n",
    "\n",
    "### Aim\n",
    "In this tutorial, we'll walk you through the process of performing semantic search on documents, taking PDFs as example, using KDB.AI as the vector store and Open AI for language embeddings. We will cover the following topics:\n",
    "\n",
    "1. Setup\n",
    "2. Load PDF Data\n",
    "3. Create Sentence Vector Embeddings\n",
    "4. Store Embeddings in KDB.AI\n",
    "5. Run similarity search on KDB.AI\n",
    "6. Setup Q&A using ChatGPT and KDB.AI\n",
    "7. Delete the KDB.AI Table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b968f5",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc202289",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "In order to successfully run this sample, the [Setup](https://github.com/KxSystems/kdbai-samples/blob/main/README.md#setup) steps in the repository's `README.md` file must be completed.\n",
    "This will ensure that you have installed all of the relevant packages and versions needed for this sample.\n",
    "If you have not completed these setup steps, please navigate to the repositories `README.md` file and follow the steps detailed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8ec1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pypdf\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59e7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector DB\n",
    "import os\n",
    "import tiktoken\n",
    "import getpass\n",
    "import openai\n",
    "import kdbai_client as kdbai\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f0a9d1",
   "metadata": {},
   "source": [
    "## 2. Load PDF Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39847b96",
   "metadata": {},
   "source": [
    "### Read Text From PDF Document\n",
    "\n",
    "We leverage the power of PyPDF2 for PDF processing and `nltk` for advanced natural language processing. The code below extracts content from each page of the PDF and processes it to identify sentences.\n",
    "\n",
    "The PDF we are using is [this research paper](https://arxiv.org/pdf/2308.05801.pdf) presenting information on the formation of Interstellar Objects in the Milky Way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6d6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PDF file\n",
    "with open(\"data/research_paper.pdf\", \"rb\") as pdf_file:\n",
    "    pdf_pages = pypdf.PdfReader(pdf_file).pages\n",
    "    page_list = [page.extract_text() for page in pdf_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291e6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate text from each page\n",
    "full_pdf_text = \"\".join(page_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d79d9",
   "metadata": {},
   "source": [
    "### Split The Text Into Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51abca",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note: </b>\n",
    "    Before running the following line of code, please ensure that you have installed the English sentence tokenizer as stated in the `README.md` file in this repository.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda06666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the PDF into sentences\n",
    "pdf_sentences = sent_tokenize(full_pdf_text)\n",
    "len (pdf_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9a507",
   "metadata": {},
   "source": [
    "#### Error-Tip\n",
    "\n",
    "In case you skipped steps from `README.md` and encounter an error on resource 'punkt' not found, use below:\n",
    "- import nltk\n",
    "- nltk.download ('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f4b1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Draft version August 14, 2023\\nTypeset using L ATEX default style in AASTeX631\\nThe Galactic Interstellar Object Population: A Framework for Prediction and Inference\\nMatthew J. Hopkins\\n ,1Chris Lintott\\n ,1Michele T. Bannister\\n ,2J.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the content\n",
    "pdf_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0130abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Draft version August 14, 2023\\nTypeset using L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We define a novel framework: firstly to predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We predict the spatial and compositional distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selecting ISO water mass\\nfraction as an examp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0  Draft version August 14, 2023\\nTypeset using L...\n",
       "1  Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...\n",
       "2  We define a novel framework: firstly to predic...\n",
       "3  We predict the spatial and compositional distr...\n",
       "4  Selecting ISO water mass\\nfraction as an examp..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe and verify\n",
    "df = pd.DataFrame({'Sentences': pdf_sentences})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0cd31f",
   "metadata": {},
   "source": [
    "## 3. Create Vector Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc54fc",
   "metadata": {},
   "source": [
    "Next, we use the OpenAI API to create embeddings for our collection of sentences.\n",
    "\n",
    "### Selecting an OpenAI Embedding Model\n",
    "\n",
    "There are different types of Embedding models available. We will be using the OpenAI model - see [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings) for the details. The diversity among these primarily stems from variations in their training data. Selecting the ideal model for your needs involves matching the domain and task closely, while also considering the benefits of incorporating larger datasets to enhance scale.\n",
    "\n",
    "This tutorial will use the `text-embedding-ada-002` pre-trained model. This embedding model can create sentence and document embeddings that can be used for a wide variety of tasks including semantic search which makes it a good choice for our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67544a3",
   "metadata": {},
   "source": [
    "### Define OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc68dec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note: </b>\n",
    "    You'll need an OpenAI account and associated API key to proceed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8e29a",
   "metadata": {},
   "source": [
    "Click here to ([create a free account](https://beta.openai.com/signup)). For OpenAI code details:\n",
    " \n",
    "> Navigate at [cookbook.openai.com](https://cookbook.openai.com)\n",
    "\n",
    "Example code and guides for accomplishing common tasks with the - [OpenAI API](https://platform.openai.com/docs/introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4359329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "# Setup OpenAI and input the API keys created on your OpenAI account\n",
    "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d98c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define OpenAI Client\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bd2e8",
   "metadata": {},
   "source": [
    "### Define Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e24e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556199f4",
   "metadata": {},
   "source": [
    "### Generate Embeddings using this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8cdc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Embeddings Function\n",
    "def get_embedding_vec(input):\n",
    "  \"\"\"Returns the embeddings vector for a given input\"\"\"\n",
    "  return client.embeddings.create(input=input,model=emb_model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "08f955c6",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 13,
   "id": "08f955c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> origin/main
   "source": [
    "# Create and Verify Embeddings\n",
    "df['Embeddings']= df['Sentences'].apply(get_embedding_vec)\n",
    "len (df['Embeddings'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab6ec7",
   "metadata": {},
   "source": [
    "#### Error-Tip\n",
    "\n",
    "In case there is an error on Rate limit reached, you would need to make very small dataset requests or make a payment on OpenAI to increase rate limit. Alternatively we have shared this df as csv and you can use below to load and check it:\n",
    "- df = pd.read_csv ('data/openai_embedded_data.csv')\n",
    "- df['Embeddings'] = df['Embeddings'].apply(json.loads)\n",
    "- len (df['Embeddings'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "760059b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Draft version August 14, 2023\\nTypeset using L...</td>\n",
       "      <td>[-0.00248929625377059, 0.006371329538524151, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...</td>\n",
       "      <td>[0.006372543051838875, 0.002492946805432439, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We define a novel framework: firstly to predic...</td>\n",
       "      <td>[0.0013814108679071069, 0.0014908972661942244,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We predict the spatial and compositional distr...</td>\n",
       "      <td>[0.014146137051284313, -0.0005565343308262527,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selecting ISO water mass\\nfraction as an examp...</td>\n",
       "      <td>[0.01576417125761509, 0.004918665625154972, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0  Draft version August 14, 2023\\nTypeset using L...   \n",
       "1  Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...   \n",
       "2  We define a novel framework: firstly to predic...   \n",
       "3  We predict the spatial and compositional distr...   \n",
       "4  Selecting ISO water mass\\nfraction as an examp...   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [-0.00248929625377059, 0.006371329538524151, -...  \n",
       "1  [0.006372543051838875, 0.002492946805432439, -...  \n",
       "2  [0.0013814108679071069, 0.0014908972661942244,...  \n",
       "3  [0.014146137051284313, -0.0005565343308262527,...  \n",
       "4  [0.01576417125761509, 0.004918665625154972, 0....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Embedded DF to CSV\n",
    "df_store = df.copy()\n",
    "df_store['Embeddings'] = df_store['Embeddings'].apply(json.dumps)\n",
    "df_store.to_csv('output/openai_embedded_data.csv', index=False)\n",
    "del df_store\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec1030",
   "metadata": {},
   "source": [
    "## 4. Store Embeddings in KDB.AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35777b3",
   "metadata": {},
   "source": [
    "With the embeddings created, we need to store them in a vector database to enable efficient searching.\n",
    "\n",
    "### Define KDB.AI Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7716be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note: </b>\n",
    "    You'll need an KDB.AI account and associated API key to proceed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4906f0",
   "metadata": {},
   "source": [
    "KDB.AI comes in two offerings:\n",
    "\n",
    "> - [KDB.AI Cloud](https://trykdb.kx.com/kdbai/signup/) - For experimenting with smaller generative AI projects with a vector database in our cloud.\n",
    "> - [KDB.AI Server](https://trykdb.kx.com/kdbaiserver/signup/) - For evaluating large scale generative AI applications on-premises or on your own cloud provider.\n",
    "\n",
    "Depending on which you use there will be different setup steps and connection details required.\n",
    "\n",
    "##### Option 1. KDB.AI Cloud\n",
    "\n",
    "To use KDB.AI Cloud, you will need two session details - a URL endpoint and an API key.\n",
    "To get these you can sign up for free [here](https://trykdb.kx.com/kdbai/signup).\n",
    "\n",
    "You can connect to a KDB.AI Cloud session using `kdbai.Session` and passing the session URL endpoint and API key details from your KDB.AI Cloud portal.\n",
    "\n",
    "If the environment variables `KDBAI_ENDPOINTS` and `KDBAI_API_KEY` exist on your system containing your KDB.AI Cloud portal details, these variables will automatically be used to connect.\n",
    "If these do not exist, it will prompt you to enter your KDB.AI Cloud portal session URL endpoint and API key details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cb58a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDB.AI endpoint: ········\n",
      "KDB.AI API key: ········\n"
     ]
    }
   ],
   "source": [
    "# Input details of KDB.AI Endpoint and API Keys from your account \n",
    "KDBAI_ENDPOINT = (\n",
    "    os.environ[\"KDBAI_ENDPOINT\"]\n",
    "    if \"KDBAI_ENDPOINT\" in os.environ\n",
    "    else getpass.getpass(\"KDB.AI endpoint: \")\n",
    ")\n",
    "KDBAI_API_KEY = (\n",
    "    os.environ[\"KDBAI_API_KEY\"]\n",
    "    if \"KDBAI_API_KEY\" in os.environ\n",
    "    else getpass.getpass(\"KDB.AI API key: \")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abf025e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KDB.AI Session\n",
    "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9217cd",
   "metadata": {},
   "source": [
    "##### Option 2. KDB.AI Server\n",
    "\n",
    "To use KDB.AI Server, you will need download and run your own container.\n",
    "To do this, you will first need to sign up for free [here](https://trykdb.kx.com/kdbaiserver/signup/). \n",
    "\n",
    "You will receive an email with the required license file and bearer token needed to download your instance.\n",
    "Follow instructions in the signup email to get your session up and running.\n",
    "\n",
    "Once the [setup steps](https://code.kx.com/kdbai/gettingStarted/kdb-ai-server-setup.html) are complete you can then connect to your KDB.AI Server session using `kdbai.Session` and passing your local endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26131b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the session for above case\n",
    "# session = kdbai.Session(endpoint=\"http://localhost:8082\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f3f3ad",
   "metadata": {},
   "source": [
    "### Define Vector DB Table Schema\n",
    "\n",
    "The next step is to define a schema for our KDB.AI table where we will store our embeddings. Our table will have two columns.\n",
    "\n",
    "At this point you will select the index and metric you want to use for searching.\n",
    "\n",
    "With KDB.AI we have the choice between HNSW (Hierarchical Navigable Small World), IVF, IVFPQ and Flat indexing methods. Generally, for semantic search of documents, the HNSW indexing method might be more suitable. Here's why:\n",
    "\n",
    "- **Search Speed and Approximation**: HNSW is designed for fast approximate nearest neighbor searches. It can efficiently handle high-dimensional data, which is common in natural language processing tasks involving text documents.\n",
    "- **Semantic Representation**: The Sentence Transformers library, used in this example, generates embeddings that capture semantic meaning. HNSW is well-suited for indexing such embeddings and performing semantic searches.\n",
    "- **Scalability**: HNSW is scalable and can handle large datasets effectively, making it suitable for applications with a vast number of documents.\n",
    "\n",
    "HNSW provides approximate search results, meaning that the nearest neighbors might not be exact matches but are close in terms of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e991e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Schema\n",
    "openai_pdf_schema = {\n",
    "    \"columns\": [\n",
    "        {\"name\": \"Sentences\", \"pytype\": \"str\"},\n",
    "        {\n",
    "            \"name\": \"Embeddings\",\n",
    "            \"vectorIndex\": {\"dims\": 1536, \"metric\": \"L2\", \"type\": \"hnsw\"},\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30938a",
   "metadata": {},
   "source": [
    "### Create Vector DB Table\n",
    "\n",
    "Use the KDB.AI `create_table` function to create a table that matches the defined schema in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50278d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ensure the table does not already exist in database\n",
    "try:\n",
    "    session.table(\"openai_pdf\").drop()\n",
    "    time.sleep(5)\n",
    "except kdbai.KDBAIException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdaa5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty table openai_pdf\n",
    "table = session.create_table(\"openai_pdf\", openai_pdf_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5582a0",
   "metadata": {},
   "source": [
    "We can use `query` to see our table exists but is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a510b418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sentences, Embeddings]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that table exists and is empty after creation\n",
    "table.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf06d4",
   "metadata": {},
   "source": [
    "### Add Embedded Data to KDB.AI Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6cca32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert dataframe into KDB.AI table\n",
    "table.insert(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656923f",
   "metadata": {},
   "source": [
    "### Verify Data Has Been Inserted\n",
    "\n",
    "Running `table.query()` should show us that data has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aa0933a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Draft version August 14, 2023\\nTypeset using L...</td>\n",
       "      <td>[-0.00248929625377059, 0.006371329538524151, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...</td>\n",
       "      <td>[0.006372543051838875, 0.002492946805432439, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We define a novel framework: firstly to predic...</td>\n",
       "      <td>[0.0013814108679071069, 0.0014908972661942244,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We predict the spatial and compositional distr...</td>\n",
       "      <td>[0.014146137051284313, -0.0005565343308262527,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selecting ISO water mass\\nfraction as an examp...</td>\n",
       "      <td>[0.01576417125761509, 0.004918665625154972, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2021, ApJ, 922, 189,\\ndoi: 10.3847/1538-4357/a...</td>\n",
       "      <td>[-0.00573846697807312, -0.006318436004221439, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2020,\\nNature Methods, 17, 261, doi: 10.1038/s...</td>\n",
       "      <td>[0.0037363762967288494, -0.0014329071855172515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>A., Frinchaboy, P. M., et al.</td>\n",
       "      <td>[0.0008434861665591598, -0.01327595580369234, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2013, AJ, 146, 81, doi: 10.1088/0004-6256/146/...</td>\n",
       "      <td>[-0.01480394322425127, 0.0031033621635288, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>2017,\\nAJ, 154, 198, doi: 10.3847/1538-3881/aa...</td>\n",
       "      <td>[-0.017208511009812355, 0.0005549969500862062,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentences  \\\n",
       "0    Draft version August 14, 2023\\nTypeset using L...   \n",
       "1    Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...   \n",
       "2    We define a novel framework: firstly to predic...   \n",
       "3    We predict the spatial and compositional distr...   \n",
       "4    Selecting ISO water mass\\nfraction as an examp...   \n",
       "..                                                 ...   \n",
       "586  2021, ApJ, 922, 189,\\ndoi: 10.3847/1538-4357/a...   \n",
       "587  2020,\\nNature Methods, 17, 261, doi: 10.1038/s...   \n",
       "588                      A., Frinchaboy, P. M., et al.   \n",
       "589  2013, AJ, 146, 81, doi: 10.1088/0004-6256/146/...   \n",
       "590  2017,\\nAJ, 154, 198, doi: 10.3847/1538-3881/aa...   \n",
       "\n",
       "                                            Embeddings  \n",
       "0    [-0.00248929625377059, 0.006371329538524151, -...  \n",
       "1    [0.006372543051838875, 0.002492946805432439, -...  \n",
       "2    [0.0013814108679071069, 0.0014908972661942244,...  \n",
       "3    [0.014146137051284313, -0.0005565343308262527,...  \n",
       "4    [0.01576417125761509, 0.004918665625154972, 0....  \n",
       "..                                                 ...  \n",
       "586  [-0.00573846697807312, -0.006318436004221439, ...  \n",
       "587  [0.0037363762967288494, -0.0014329071855172515...  \n",
       "588  [0.0008434861665591598, -0.01327595580369234, ...  \n",
       "589  [-0.01480394322425127, 0.0031033621635288, -0....  \n",
       "590  [-0.017208511009812355, 0.0005549969500862062,...  \n",
       "\n",
       "[591 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm if table has the data just inserted\n",
    "table.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdcc31",
   "metadata": {},
   "source": [
    "## 5. Run similarity search on KDB.AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf567771",
   "metadata": {},
   "source": [
    "Now that the embeddings are stored in KDB.AI, we can perform semantic search using `search`. \n",
    "\n",
    "First, we embed our search term using the OpenAI model as before. Then we search our index to return the three most similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5734809",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term1 = \"number of interstellar objects in the milky way\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f3f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding of the search term\n",
    "vec_search_term1 = get_embedding_vec(search_term1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8a849",
   "metadata": {},
   "source": [
    "### Searching with number of nearest neighbours set to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1481778a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>__nn_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...</td>\n",
       "      <td>[0.006372543051838875, 0.002492946805432439, -...</td>\n",
       "      <td>0.210837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this work, we develop\\nthis method and appl...</td>\n",
       "      <td>[0.009463178925216198, 0.020949233323335648, -...</td>\n",
       "      <td>0.296038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keywords: Interstellar objects (52), Small Sol...</td>\n",
       "      <td>[-0.002602155553176999, -0.00834919698536396, ...</td>\n",
       "      <td>0.303887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0  Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...   \n",
       "1  In this work, we develop\\nthis method and appl...   \n",
       "2  Keywords: Interstellar objects (52), Small Sol...   \n",
       "\n",
       "                                          Embeddings  __nn_distance  \n",
       "0  [0.006372543051838875, 0.002492946805432439, -...       0.210837  \n",
       "1  [0.009463178925216198, 0.020949233323335648, -...       0.296038  \n",
       "2  [-0.002602155553176999, -0.00834919698536396, ...       0.303887  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching Results with n=3\n",
    "results1 = table.search([vec_search_term1], n=3)\n",
    "results1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71740e1c",
   "metadata": {},
   "source": [
    "### Searching the closest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9854524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...\n",
       "Name: Sentences, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching Results with default n\n",
    "results2 = table.search([vec_search_term1])\n",
    "results2[0]['Sentences']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcdcab",
   "metadata": {},
   "source": [
    "### Printing sentences alongside scores for the search results within n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c9f2028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Ted Mackereth\n",
      " ,3, 4, 5, ∗and\n",
      "John C. Forbes\n",
      "2\n",
      "1Department of Physics, University of Oxford, Denys Wilkinson Building, Keble Road, Oxford, OX1 3RH, UK\n",
      "2School of Physical and Chemical Sciences—Te Kura Mat¯ u, University of Canterbury, Private Bag 4800, Christchurch 8140, New Zealand\n",
      "3Just Group plc, Enterprise House, Bancroft road, Reigate, Surrey RH2 7RP, UK\n",
      "4Canadian Institute for Theoretical Astrophysics, University of Toronto, 60 St. George Street, Toronto, ON, M5S 3H8, Canada\n",
      "5Dunlap Institute for Astronomy and Astrophysics, University of Toronto, 50 St. George Street, Toronto, ON M5S 3H4, Canada\n",
      "ABSTRACT\n",
      "The Milky Way is thought to host a huge population of interstellar objects (ISOs), numbering\n",
      "approximately 1015pc−3around the Sun, which are formed and shaped by a diverse set of processes\n",
      "ranging from planet formation to galactic dynamics. (Score: 0.211)\n",
      "2. In this work, we develop\n",
      "this method and apply it to the stellar population of the Milky Way, estimated with data from the APOGEE survey, to\n",
      "predict a broader set of properties of our own Galaxy’s population of interstellar objects. (Score: 0.296)\n",
      "3. Keywords: Interstellar objects (52), Small Solar System bodies(1469), Galaxy Evolution (594)\n",
      "1.INTRODUCTION\n",
      "1I/‘Oumuamua (Meech et al. (Score: 0.304)\n"
     ]
    }
   ],
   "source": [
    "for index, row in results1[0].iterrows():\n",
    "    sentence = row['Sentences']\n",
    "    nn_distance = row['__nn_distance']\n",
    "    print(f\"{index + 1}. {sentence} (Score: {nn_distance:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b4599",
   "metadata": {},
   "source": [
    "## 6. Setup Q&A using ChatGPT and KDB.AI\n",
    "\n",
    "This section depicts the implementation of a Question Answering system with ChatGPT, KDB.AI and OpenAI Embeddings.\n",
    "First we start with ChatGPT to answer independetly, then use the query to be answered from PDF text using ChatGPT and then replicate the same using KDB.AI and OpenAI Embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0477bd",
   "metadata": {},
   "source": [
    "### Define a query\n",
    "\n",
    "We define our query to be asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5cf5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is Milky Way thought to host?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503638a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note: </b>\n",
    "    This can also be taken as an user input but we have taken a specific case to simplify results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd8f49",
   "metadata": {},
   "source": [
    "### Using ChatGPT to answer\n",
    "\n",
    "First we try calling OpenAI API using ChatGPT model to answer the above query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8ed91",
   "metadata": {},
   "source": [
    "#### Define ChatGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "375e2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f4266",
   "metadata": {},
   "source": [
    "#### Fetching result using the above ChatGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9e52e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Milky Way is thought to host a variety of astronomical objects and phenomena. These include:\n",
      "\n",
      "1. Stars: The Milky Way is home to billions of stars, including our own Sun. These stars vary in size, age, and composition.\n",
      "\n",
      "2. Planets: The Milky Way is believed to host numerous planets, both within our own solar system and around other stars. These exoplanets may have diverse characteristics and potential for habitability.\n",
      "\n",
      "3. Nebulae: Nebulae are vast clouds of gas and dust. The Milky Way contains various types of nebulae, such as emission nebulae (e.g., the Orion Nebula) and reflection nebulae (e.g., the Pleiades).\n",
      "\n",
      "4. Star clusters: The Milky Way contains both open star clusters (e.g., the Pleiades) and globular star clusters (e.g., Omega Centauri). These clusters are groups of stars that formed together and are gravitationally bound.\n",
      "\n",
      "5. Black holes: The Milky Way is believed to harbor a supermassive black hole at its center, known as Sagittarius A*. Additionally, there may be numerous smaller black holes scattered throughout the galaxy.\n",
      "\n",
      "6. Pulsars: Pulsars are highly magnetized, rotating neutron stars that emit beams of electromagnetic radiation. The Milky Way is known to host many pulsars, which are remnants of massive stars that have undergone supernova explosions.\n",
      "\n",
      "7. Dark matter: Although not directly observable, it is widely believed that the Milky Way, like other galaxies, contains a significant amount of dark matter. Dark matter is a mysterious form of matter that does not interact with light but exerts gravitational influence.\n",
      "\n",
      "These are just a few examples of the objects and phenomena thought to be hosted by the Milky Way. The galaxy is a complex and dynamic system with much more to explore and understand.\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You answer questions about scientific papers.'},\n",
    "        {'role': 'user', 'content': query},\n",
    "    ],\n",
    "    model=GPT_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6b973",
   "metadata": {},
   "source": [
    "### Creating chunks of data from the stored PDF text\n",
    "\n",
    "We first use the earlier stored PDF text and break it into chunks to be processed by ChatGPT separately.\n",
    "This will be used to create different queries to fetch the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b614bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to split text into chunks\n",
    "def split_text_into_chunks(text, max_tokens_per_chunk=4096):\n",
    "    chunks = []\n",
    "    words = text.split()\n",
    "\n",
    "    current_chunk = words[0]\n",
    "    for word in words[1:]:\n",
    "        if len(current_chunk) + len(word) + 1 <= max_tokens_per_chunk:  # +1 for the space between words\n",
    "            current_chunk += ' ' + word\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = word\n",
    "\n",
    "    chunks.append(current_chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e528a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into chunks with a maximum of 4096 tokens per chunk\n",
    "chunks = split_text_into_chunks(full_pdf_text, max_tokens_per_chunk=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4a749f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the chunks if needed using below:\n",
    "# for i, chunk in enumerate(chunks, start=1):\n",
    "#     print(f\"Chunk {i}: {chunk}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3f48d",
   "metadata": {},
   "source": [
    "### Using chunked data with ChatGPT to fetch answers\n",
    "\n",
    "We now use the same ChatGPT model and function to fetch the answer to the query from the data chunks created from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f4fee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Milky Way is thought to host a huge population of interstellar objects (ISOs).\n"
     ]
    }
   ],
   "source": [
    "# Finding Answer of a Question from a pre-selected chunk\n",
    "# You can query all chunks in a loop as well but we have limited it for the example\n",
    "query = f\"\"\"Use the below (chunk of) article to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n",
    "\n",
    "Article:\n",
    "\\\"\\\"\\\"\n",
    "{chunks[0]}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Question: What is Milky Way thought to host?\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "messages=[\n",
    "    {'role': 'system', 'content': 'You answer questions about scientific papers.'},\n",
    "    {'role': 'user', 'content': query},\n",
    "],\n",
    "model=GPT_MODEL,\n",
    "temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1f370",
   "metadata": {},
   "source": [
    "### Using KDB.AI to fetch answer from closest record\n",
    "\n",
    "Now we demonstrate the use of KDB.AI to fetch the answer of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f611d55",
   "metadata": {},
   "source": [
    "#### Define the search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4fd7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term2 = \"What is Milky Way thought to host?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b559c0",
   "metadata": {},
   "source": [
    "#### Create embedding of the search term and then search the KDB.AI table for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "456fe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_search_term2=get_embedding_vec(search_term2)\n",
    "results3 = table.search([vec_search_term2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d7ce9",
   "metadata": {},
   "source": [
    "#### Finding answer for the Question using ChatGPT model fetching results from KDB.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f542a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Milky Way is thought to host a huge population of interstellar objects (ISOs).\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"Use the below (chunk of) article to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n",
    "\n",
    "Article:\n",
    "\\\"\\\"\\\"\n",
    "{results3[0]['Sentences'].str.cat(sep=' ')}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Question: What is Milky Way though to host?\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "messages=[\n",
    "    {'role': 'system', 'content': 'You answer questions about scientific papers.'},\n",
    "    {'role': 'user', 'content': query},\n",
    "],\n",
    "model=GPT_MODEL,\n",
    "temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cad935",
   "metadata": {},
   "source": [
    "#### Showing query results directly from the KDB.AI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81415e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...</td>\n",
       "      <td>[0.006372543051838875, 0.002492946805432439, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this work, we develop\\nthis method and appl...</td>\n",
       "      <td>[0.009463178925216198, 0.020949233323335648, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.APOGEE AND STELLAR DENSITY MODELLING\\nTo pre...</td>\n",
       "      <td>[-0.005855499301105738, -0.0030739670619368553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>While APOGEE’s main sample is not representati...</td>\n",
       "      <td>[-0.006474930793046951, 0.012832699343562126, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APOGEE is a near-infrared,\\nhigh-resolution ( ...</td>\n",
       "      <td>[0.013261232525110245, -0.0006685049156658351,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To restrict our sample to the Milky Way’s disk...</td>\n",
       "      <td>[0.006987773813307285, 0.01712271198630333, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Density Modelling of Red Giants across the Gal...</td>\n",
       "      <td>[-0.00954350270330906, 0.004846843425184488, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>To build our model of the Milky Way disk betwe...</td>\n",
       "      <td>[0.004540927708148956, 0.020696885883808136, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The two main distinct chemodynamical populatio...</td>\n",
       "      <td>[0.008082730695605278, 0.01970331184566021, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This approach gives us simple but accurate mod...</td>\n",
       "      <td>[-0.008088158443570137, 0.025545835494995117, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Sine Morte Stellar Population\\nHaving obta...</td>\n",
       "      <td>[0.00375589681789279, 0.0007511793519370258, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Instead, we must consider what the stellar pop...</td>\n",
       "      <td>[-0.0027440034318715334, -0.007568961009383202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.PREDICTING THE INTERSTELLAR OBJECT DISTRIBUT...</td>\n",
       "      <td>[0.006404532119631767, 0.0008935550577007234, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>−2.0−1.5−1.0−0.5 0.0 0.5\\n[Fe/H]0.00.20.40.60....</td>\n",
       "      <td>[-0.006964315660297871, 0.0054080248810350895,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The normalised mass-weighted sine morte stella...</td>\n",
       "      <td>[0.006962645798921585, 0.0037554835435003042, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In this work we predict the distribution of IS...</td>\n",
       "      <td>[0.01092113833874464, -0.010962531901896, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018; Bennett &amp; Bovy 2019), and the distributi...</td>\n",
       "      <td>[0.0113859623670578, -0.01343272440135479, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Primary prediction for the fraction of ISOs in...</td>\n",
       "      <td>[0.013438784517347813, -0.00878086220473051, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3, both at the position of the Sun and over th...</td>\n",
       "      <td>[0.012247860431671143, 0.002532300539314747, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1 0.2 0.3 0.4 0.5\\nfH2O0.00.51.01.52.02.5p(f...</td>\n",
       "      <td>[0.012736896052956581, -0.010779479518532753, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Primary prediction for the distribution of ISO...</td>\n",
       "      <td>[0.009828190319240093, -0.012012232095003128, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Figure 4 shows both the population of ISOs aro...</td>\n",
       "      <td>[0.008194087073206902, -0.007264725398272276, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The different shapes\\nof the two metallicity d...</td>\n",
       "      <td>[-0.00450296001508832, 0.0011966658057644963, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The distributions of ISOs around the Sun and a...</td>\n",
       "      <td>[0.009972188621759415, -0.013183129020035267, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The resulting water mass fraction distribution...</td>\n",
       "      <td>[0.003850735956802964, -0.005235008895397186, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ISOfH2Orange Fraction of ISOs around Sun Fract...</td>\n",
       "      <td>[0.03336752951145172, -0.015349064022302628, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Alternate prediction for fraction of ISOs in e...</td>\n",
       "      <td>[0.013715134002268314, -0.014454110525548458, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>This means that the low metallicity tails ofTh...</td>\n",
       "      <td>[-0.004002938512712717, -0.0025022667832672596...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Alternate prediction for the distribution of I...</td>\n",
       "      <td>[0.004296127241104841, -0.018478112295269966, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>theρsm([Fe/H]) distributions in Figure 3 now c...</td>\n",
       "      <td>[0.0018594865687191486, 0.0010346460621804, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The Milky Way stellar population is broadly di...</td>\n",
       "      <td>[-0.009802711196243763, 0.020372942090034485, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Here, the Milky Way metallicity gradient means...</td>\n",
       "      <td>[0.0008432237082161009, 0.00961619894951582, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(2022) made a prediction of the ISO population...</td>\n",
       "      <td>[-0.0012439858401194215, -0.023293744772672653...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>There are expected reasons for the difference ...</td>\n",
       "      <td>[0.002673599636182189, 0.011643646284937859, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The EAGLE Galaxy\\nhas a much wider [Fe /H] dis...</td>\n",
       "      <td>[-0.00589609844610095, 0.0009447578922845423, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Therefore the results of this work, based on t...</td>\n",
       "      <td>[-0.0001349077356280759, 0.007918029092252254,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Distinguishing Local and Galactic Populations ...</td>\n",
       "      <td>[0.016985921189188957, 0.010122385807335377, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>For example, radial migration, caused by the n...</td>\n",
       "      <td>[-0.0359172597527504, 0.0006014446262270212, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.1 0.2 0.3 0.4 0.5\\nfH2O0.00.51.01.52.02.53.0...</td>\n",
       "      <td>[0.013478799723088741, -0.011529809795320034, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Distribution of ISO water mass fractions, eval...</td>\n",
       "      <td>[0.008756319060921669, -0.005910344887524843, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>At fH2O= 0.3 a vertical line marks the measure...</td>\n",
       "      <td>[0.013547314330935478, -0.0033817202784121037,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>This is due to the fact that we expect\\ncompos...</td>\n",
       "      <td>[0.016121570020914078, 0.003582950448617339, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.CONCLUSION\\nIn advance of the Vera C. Rubin ...</td>\n",
       "      <td>[0.0218886137008667, -0.006388773676007986, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>By considering the distribution of ISOs over t...</td>\n",
       "      <td>[0.017039833590388298, -0.0036417939700186253,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>This causes the ISO water mass fraction\\ndistr...</td>\n",
       "      <td>[-0.00016734022938180715, -0.00465108314529061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Since we also predict\\nhigher-metallicity star...</td>\n",
       "      <td>[0.010145746171474457, -0.008178782649338245, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Encoded in the population of ISOs we observe i...</td>\n",
       "      <td>[0.0043590981513261795, -0.000574662524741143,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences  \\\n",
       "0   Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes...   \n",
       "1   In this work, we develop\\nthis method and appl...   \n",
       "2   2.APOGEE AND STELLAR DENSITY MODELLING\\nTo pre...   \n",
       "3   While APOGEE’s main sample is not representati...   \n",
       "4   APOGEE is a near-infrared,\\nhigh-resolution ( ...   \n",
       "5   To restrict our sample to the Milky Way’s disk...   \n",
       "6   Density Modelling of Red Giants across the Gal...   \n",
       "7   To build our model of the Milky Way disk betwe...   \n",
       "8   The two main distinct chemodynamical populatio...   \n",
       "9   This approach gives us simple but accurate mod...   \n",
       "10  The Sine Morte Stellar Population\\nHaving obta...   \n",
       "11  Instead, we must consider what the stellar pop...   \n",
       "12  3.PREDICTING THE INTERSTELLAR OBJECT DISTRIBUT...   \n",
       "13  −2.0−1.5−1.0−0.5 0.0 0.5\\n[Fe/H]0.00.20.40.60....   \n",
       "14  The normalised mass-weighted sine morte stella...   \n",
       "15  In this work we predict the distribution of IS...   \n",
       "16  2018; Bennett & Bovy 2019), and the distributi...   \n",
       "17  Primary prediction for the fraction of ISOs in...   \n",
       "18  3, both at the position of the Sun and over th...   \n",
       "19  0.1 0.2 0.3 0.4 0.5\\nfH2O0.00.51.01.52.02.5p(f...   \n",
       "20  Primary prediction for the distribution of ISO...   \n",
       "21  Figure 4 shows both the population of ISOs aro...   \n",
       "22  The different shapes\\nof the two metallicity d...   \n",
       "23  The distributions of ISOs around the Sun and a...   \n",
       "24  The resulting water mass fraction distribution...   \n",
       "25  ISOfH2Orange Fraction of ISOs around Sun Fract...   \n",
       "26  Alternate prediction for fraction of ISOs in e...   \n",
       "27  This means that the low metallicity tails ofTh...   \n",
       "28  Alternate prediction for the distribution of I...   \n",
       "29  theρsm([Fe/H]) distributions in Figure 3 now c...   \n",
       "30  The Milky Way stellar population is broadly di...   \n",
       "31  Here, the Milky Way metallicity gradient means...   \n",
       "32  (2022) made a prediction of the ISO population...   \n",
       "33  There are expected reasons for the difference ...   \n",
       "34  The EAGLE Galaxy\\nhas a much wider [Fe /H] dis...   \n",
       "35  Therefore the results of this work, based on t...   \n",
       "36  Distinguishing Local and Galactic Populations ...   \n",
       "37  For example, radial migration, caused by the n...   \n",
       "38  0.1 0.2 0.3 0.4 0.5\\nfH2O0.00.51.01.52.02.53.0...   \n",
       "39  Distribution of ISO water mass fractions, eval...   \n",
       "40  At fH2O= 0.3 a vertical line marks the measure...   \n",
       "41  This is due to the fact that we expect\\ncompos...   \n",
       "42  7.CONCLUSION\\nIn advance of the Vera C. Rubin ...   \n",
       "43  By considering the distribution of ISOs over t...   \n",
       "44  This causes the ISO water mass fraction\\ndistr...   \n",
       "45  Since we also predict\\nhigher-metallicity star...   \n",
       "46  Encoded in the population of ISOs we observe i...   \n",
       "\n",
       "                                           Embeddings  \n",
       "0   [0.006372543051838875, 0.002492946805432439, -...  \n",
       "1   [0.009463178925216198, 0.020949233323335648, -...  \n",
       "2   [-0.005855499301105738, -0.0030739670619368553...  \n",
       "3   [-0.006474930793046951, 0.012832699343562126, ...  \n",
       "4   [0.013261232525110245, -0.0006685049156658351,...  \n",
       "5   [0.006987773813307285, 0.01712271198630333, 0....  \n",
       "6   [-0.00954350270330906, 0.004846843425184488, -...  \n",
       "7   [0.004540927708148956, 0.020696885883808136, -...  \n",
       "8   [0.008082730695605278, 0.01970331184566021, -0...  \n",
       "9   [-0.008088158443570137, 0.025545835494995117, ...  \n",
       "10  [0.00375589681789279, 0.0007511793519370258, 0...  \n",
       "11  [-0.0027440034318715334, -0.007568961009383202...  \n",
       "12  [0.006404532119631767, 0.0008935550577007234, ...  \n",
       "13  [-0.006964315660297871, 0.0054080248810350895,...  \n",
       "14  [0.006962645798921585, 0.0037554835435003042, ...  \n",
       "15  [0.01092113833874464, -0.010962531901896, -0.0...  \n",
       "16  [0.0113859623670578, -0.01343272440135479, 0.0...  \n",
       "17  [0.013438784517347813, -0.00878086220473051, -...  \n",
       "18  [0.012247860431671143, 0.002532300539314747, -...  \n",
       "19  [0.012736896052956581, -0.010779479518532753, ...  \n",
       "20  [0.009828190319240093, -0.012012232095003128, ...  \n",
       "21  [0.008194087073206902, -0.007264725398272276, ...  \n",
       "22  [-0.00450296001508832, 0.0011966658057644963, ...  \n",
       "23  [0.009972188621759415, -0.013183129020035267, ...  \n",
       "24  [0.003850735956802964, -0.005235008895397186, ...  \n",
       "25  [0.03336752951145172, -0.015349064022302628, -...  \n",
       "26  [0.013715134002268314, -0.014454110525548458, ...  \n",
       "27  [-0.004002938512712717, -0.0025022667832672596...  \n",
       "28  [0.004296127241104841, -0.018478112295269966, ...  \n",
       "29  [0.0018594865687191486, 0.0010346460621804, -0...  \n",
       "30  [-0.009802711196243763, 0.020372942090034485, ...  \n",
       "31  [0.0008432237082161009, 0.00961619894951582, -...  \n",
       "32  [-0.0012439858401194215, -0.023293744772672653...  \n",
       "33  [0.002673599636182189, 0.011643646284937859, -...  \n",
       "34  [-0.00589609844610095, 0.0009447578922845423, ...  \n",
       "35  [-0.0001349077356280759, 0.007918029092252254,...  \n",
       "36  [0.016985921189188957, 0.010122385807335377, 0...  \n",
       "37  [-0.0359172597527504, 0.0006014446262270212, 0...  \n",
       "38  [0.013478799723088741, -0.011529809795320034, ...  \n",
       "39  [0.008756319060921669, -0.005910344887524843, ...  \n",
       "40  [0.013547314330935478, -0.0033817202784121037,...  \n",
       "41  [0.016121570020914078, 0.003582950448617339, 0...  \n",
       "42  [0.0218886137008667, -0.006388773676007986, -0...  \n",
       "43  [0.017039833590388298, -0.0036417939700186253,...  \n",
       "44  [-0.00016734022938180715, -0.00465108314529061...  \n",
       "45  [0.010145746171474457, -0.008178782649338245, ...  \n",
       "46  [0.0043590981513261795, -0.000574662524741143,...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.query(filter=[(\"like\", \"Sentences\", \"*Milky Way*\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60913d",
   "metadata": {},
   "source": [
    "## 7. Delete the KDB.AI Table\n",
    "\n",
    "Once finished with the table, it is best practice to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8be019ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0bdc9",
   "metadata": {},
   "source": [
    "### We hope you found this sample helpful !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
