{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using Valkey as a Vector Database with OpenAI\n",
    "\n",
    "This notebook provides an introduction to using Valkey as a vector database with OpenAI embeddings. Valkey is scalable, real-time database that can be used as a vector database when using Valkey Search module. The Search module allows to index and search for vectors in Valkey. This notebook will show you how to use the ValkeySearch module to index and search for vectors created by using the OpenAI API and stored in Redis.\n",
    "\n",
    "### What is Valkey?\n",
    "\n",
    "Valkey is an open‑source key–value store that originated as a Redis fork under the Linux Foundation. It maintains full compatibility with Redis protocols and APIs while being developed under transparent, community‑driven governance. Developers choose Valkey because it delivers the same fast, reliable performance as Redis with a strong commitment to open‑source principles.\n",
    "\n",
    "Valkey supports all standard Redis data types and commands, making it a seamless, drop‑in replacement for existing Redis applications.\n",
    "\n",
    "### What is Valkey Search?\n",
    "\n",
    "Valkey‑Search is a high‑performance, open‑source Valkey module that adds native vector similarity search and secondary indexing capabilities to Valkey. It is optimized for AI workloads, delivering single‑digit millisecond latency and the ability to handle billions of vectors with over 99% recall. It supports both Approximate Nearest Neighbor (HNSW) and exact K‑Nearest Neighbors (KNN) search, along with complex filtering over Valkey Hash and Valkey‑JSON data. While its current focus is vector search, Valkey‑Search is evolving toward a full search engine with planned support for full‑text search and broader indexing features.\n",
    "\n",
    "### Deployment options\n",
    "\n",
    "There are several ways to deploy Valkey with vector search capabilities. For local development, the quickest method is to use the valkey-bundle which we will use here. valkey-bundle contains a number of Valkey modules that can be used together to create a fast data store and query emgine.\n",
    "\n",
    "For production use cases, you can deploy Valkey on your own infrastructure, use container orchestration with Kubernetes, or deploy on cloud providers.\n",
    "\n",
    "Since Valkey maintains Redis compatibility, existing Redis deployment patterns and tools work seamlessly with Valkey.\n"
   ],
   "id": "c922431c43d657f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start this project, we need to set up the following:\n",
    "\n",
    "* Start a Valkey database with Search module\n",
    "* Install required libraries\n",
    "    * [valkey-glide](https://github.com/valkey-io/valkey-glide)\n",
    "* Get your [OpenAI API key](https://platform.openai.com/account/api-keys)\n",
    "\n",
    "===========================================================\n",
    "\n",
    "### Start Valkey\n",
    "\n",
    "For this example, we'll use Docker with valkey-bundle, which contains Search module. We can start docker container as follows:\n",
    "\n",
    "```bash\n",
    "$ docker-compose up -d\n",
    "```\n",
    "\n",
    "You're ready to go! Next, we'll create our client for communicating with the Valkey database."
   ],
   "id": "f138559c5bc2661d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Install Requirements\n",
    "\n",
    "valkey-glide has a Python client for communicating with Valkey. We'll use this to communicate with our Valkey database."
   ],
   "id": "7ff252fc24d6ed28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! pip install valkey-glide openai wget pandas numpy jupyter",
   "id": "636e9b925342b0e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "===========================================================\n",
    "## Prepare your OpenAI API key\n",
    "\n",
    "The OpenAI API key is used for vectorization of query data.\n",
    "\n",
    "If you don't have an OpenAI API key, you can get one from [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys).\n",
    "\n",
    "Once you get your key, add it to your environment variables as `OPENAI_API_KEY`:"
   ],
   "id": "323ea9a8f8a61873"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:40:14.532681Z",
     "start_time": "2026-01-05T20:40:14.229498Z"
    }
   },
   "cell_type": "code",
   "source": "! export OPENAI_API_KEY=\"your API key\"",
   "id": "7df7b5c89bc9dd32",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:57:46.891087Z",
     "start_time": "2026-01-05T20:57:46.774569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test that your OpenAI API key is correctly set as an environment variable\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Note: alternatively you can set a temporary env variable like this:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ],
   "id": "45a0bbd7655270d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Data\n",
    "\n",
    "In this section we'll load embedded data that has already been converted into vectors. We'll use this data to create an index in Valkey and then search for similar vectors."
   ],
   "id": "fe06b8e96d30c91e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:47:56.046913Z",
     "start_time": "2026-01-05T20:40:49.053155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# Use helper function in nbutils.py to download and read the data\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "import nbutils\n",
    "\n",
    "nbutils.download_wikipedia_data()\n",
    "data = nbutils.read_wikipedia_data()\n",
    "\n",
    "print(f\"Loaded {len(data)} articles with embeddings\")\n",
    "data.head()"
   ],
   "id": "54c55ec23811b1a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Downloaded\n",
      "Loaded 25000 articles with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   id                                       url   title  \\\n",
       "0   1   https://simple.wikipedia.org/wiki/April   April   \n",
       "1   2  https://simple.wikipedia.org/wiki/August  August   \n",
       "2   6     https://simple.wikipedia.org/wiki/Art     Art   \n",
       "3   8       https://simple.wikipedia.org/wiki/A       A   \n",
       "4   9     https://simple.wikipedia.org/wiki/Air     Air   \n",
       "\n",
       "                                                text  \\\n",
       "0  April is the fourth month of the year in the J...   \n",
       "1  August (Aug.) is the eighth month of the year ...   \n",
       "2  Art is a creative activity that expresses imag...   \n",
       "3  A or a is the first letter of the English alph...   \n",
       "4  Air refers to the Earth's atmosphere. Air is a...   \n",
       "\n",
       "                                        title_vector  \\\n",
       "0  [0.001009464613161981, -0.020700545981526375, ...   \n",
       "1  [0.0009286514250561595, 0.000820168002974242, ...   \n",
       "2  [0.003393713850528002, 0.0061537534929811954, ...   \n",
       "3  [0.0153952119871974, -0.013759135268628597, 0....   \n",
       "4  [0.02224554680287838, -0.02044147066771984, -0...   \n",
       "\n",
       "                                      content_vector vector_id  \n",
       "0  [-0.011253940872848034, -0.013491976074874401,...         0  \n",
       "1  [0.0003609954728744924, 0.007262262050062418, ...         1  \n",
       "2  [-0.004959689453244209, 0.015772193670272827, ...         2  \n",
       "3  [0.024894846603274345, -0.022186409682035446, ...         3  \n",
       "4  [0.021524671465158463, 0.018522677943110466, -...         4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>title_vector</th>\n",
       "      <th>content_vector</th>\n",
       "      <th>vector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/April</td>\n",
       "      <td>April</td>\n",
       "      <td>April is the fourth month of the year in the J...</td>\n",
       "      <td>[0.001009464613161981, -0.020700545981526375, ...</td>\n",
       "      <td>[-0.011253940872848034, -0.013491976074874401,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/August</td>\n",
       "      <td>August</td>\n",
       "      <td>August (Aug.) is the eighth month of the year ...</td>\n",
       "      <td>[0.0009286514250561595, 0.000820168002974242, ...</td>\n",
       "      <td>[0.0003609954728744924, 0.007262262050062418, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>Art is a creative activity that expresses imag...</td>\n",
       "      <td>[0.003393713850528002, 0.0061537534929811954, ...</td>\n",
       "      <td>[-0.004959689453244209, 0.015772193670272827, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/A</td>\n",
       "      <td>A</td>\n",
       "      <td>A or a is the first letter of the English alph...</td>\n",
       "      <td>[0.0153952119871974, -0.013759135268628597, 0....</td>\n",
       "      <td>[0.024894846603274345, -0.022186409682035446, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Air</td>\n",
       "      <td>Air</td>\n",
       "      <td>Air refers to the Earth's atmosphere. Air is a...</td>\n",
       "      <td>[0.02224554680287838, -0.02044147066771984, -0...</td>\n",
       "      <td>[0.021524671465158463, 0.018522677943110466, -...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Connect to Valkey\n",
    "\n",
    "Now that we have our Valkey database running, we can connect to it using the valkey-glide client. We will use the default host and port for the Valkey database which is `localhost:6379`"
   ],
   "id": "b0ca8c86c7977fdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:49:20.246133Z",
     "start_time": "2026-01-05T20:49:18.483458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from glide import GlideClientConfiguration, NodeAddress, GlideClient\n",
    "\n",
    "async def connect_to_valkey():\n",
    "    VALKEY_HOST = \"localhost\"\n",
    "    VALKEY_PORT = 6379\n",
    "\n",
    "    addresses = [NodeAddress(VALKEY_HOST, VALKEY_PORT)]\n",
    "    config = GlideClientConfiguration(\n",
    "        addresses,\n",
    "        request_timeout=60000\n",
    "    )\n",
    "    client = await GlideClient.create(config)\n",
    "\n",
    "    # Test connection\n",
    "    ping_result = await client.ping()\n",
    "    print(f\"Connected to Valkey: {ping_result}\")\n",
    "    return client\n",
    "\n",
    "# Connect to Valkey\n",
    "valkey_client = await connect_to_valkey()"
   ],
   "id": "921ca1eeb6ae77a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Valkey: b'PONG'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a Search Index in Valkey\n",
    "\n",
    "The following cells show how to specify and create a search index in Valkey. We will:\n",
    "\n",
    "1. Set constants for defining our index (distance metric, index name, etc.)\n",
    "2. Define the index schema\n",
    "3. Create the index in Valkey"
   ],
   "id": "e310b6b17b9fbcec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:49:25.075603Z",
     "start_time": "2026-01-05T20:49:25.033135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from glide import ft, glide_json\n",
    "from glide_shared.commands.server_modules.ft_options.ft_create_options import (\n",
    "    DataType,\n",
    "    DistanceMetricType,\n",
    "    FtCreateOptions,\n",
    "    TagField,\n",
    "    VectorAlgorithm,\n",
    "    VectorField,\n",
    "    VectorFieldAttributesHnsw,\n",
    "    VectorFieldAttributesFlat,\n",
    "    VectorType,\n",
    ")\n",
    "# Constants\n",
    "VECTOR_DIM = len(data['title_vector'][0])    # length of the vectors\n",
    "VECTOR_NUMBER = len(data)                    # initial number of vectors\n",
    "INDEX_NAME = \"valkey-embeddings-index\"       # name of the search index\n",
    "PREFIX = \"doc\"                               # prefix for the document keys\n",
    "DISTANCE_METRIC = DistanceMetricType.COSINE  # distance metric for vectors (COSINE, IP, L2)\n",
    "\n",
    "print(f\"Vector dimensions: {VECTOR_DIM}\")\n",
    "print(f\"Number of vectors: {VECTOR_NUMBER}\")"
   ],
   "id": "72b1c6f6218e8010",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector dimensions: 1536\n",
      "Number of vectors: 25000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:49:29.006999Z",
     "start_time": "2026-01-05T20:49:28.968681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define fields for each column in the dataset\n",
    "fields = [\n",
    "    TagField(\"$.title\", alias=\"title\"),\n",
    "    TagField(\"$.url\", alias=\"url\"),\n",
    "    TagField(\"$.text\", alias=\"text\"),\n",
    "    VectorField(\n",
    "        name=\"title_vector\",\n",
    "        algorithm=VectorAlgorithm.FLAT,\n",
    "        attributes=VectorFieldAttributesFlat(\n",
    "            dimensions=VECTOR_DIM,\n",
    "            distance_metric=DISTANCE_METRIC,\n",
    "            type=VectorType.FLOAT32\n",
    "        )\n",
    "    ),\n",
    "    VectorField(\n",
    "        name=\"content_vector\",\n",
    "        algorithm=VectorAlgorithm.FLAT,\n",
    "        attributes=VectorFieldAttributesFlat(\n",
    "            dimensions=VECTOR_DIM,\n",
    "            distance_metric=DISTANCE_METRIC,\n",
    "            type=VectorType.FLOAT32\n",
    "        )\n",
    "    )\n",
    "]\n",
    "print(\"Index schema defined\")"
   ],
   "id": "e6ac308776111a8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index schema defined\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:49:34.386427Z",
     "start_time": "2026-01-05T20:49:34.359058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if index exists\n",
    "async def has_index(index_name: str) -> bool:\n",
    "    try:\n",
    "        await ft.info(valkey_client, index_name)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "async def create_index(index_name: str):\n",
    "    try:\n",
    "        if await has_index(index_name):\n",
    "            print(\"Index already exists\")\n",
    "            return\n",
    "        options = FtCreateOptions(\n",
    "            data_type=DataType.JSON,\n",
    "            prefixes=[PREFIX]\n",
    "        )\n",
    "        await ft.create(valkey_client, index_name, fields, options)\n",
    "        print(f\"Created index: {index_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "        raise e\n",
    "\n",
    "await create_index(INDEX_NAME)"
   ],
   "id": "f568db6f3da6bd52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Documents into the Index\n",
    "\n",
    "Now that we have a search index, we can load documents into it. We will use the same documents we used in the previous examples. In Valkey, either the HASH or JSON data types can be used to store documents. We will use the JSON data type in this example. The below cells will show how to load documents into the index."
   ],
   "id": "adef2ef2456b0c2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:49:38.631271Z",
     "start_time": "2026-01-05T20:49:38.592759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "async def index_documents(prefix: str, documents: pd.DataFrame):\n",
    "    records = documents.to_dict(\"records\")\n",
    "    for i, doc in enumerate(records):\n",
    "        key = f\"{prefix}:{str(doc['id'])}\"\n",
    "        await glide_json.set(valkey_client, key, \"$\", json.dumps(doc))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Indexed {i} documents\")"
   ],
   "id": "c7dcb04a374562db",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cd26770930b6c5a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:50:28.725523Z",
     "start_time": "2026-01-05T20:49:41.116711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Index all documents in Valkey\n",
    "await index_documents(PREFIX, data.head(5000))\n",
    "info_result = await valkey_client.info()\n",
    "print(f\"Loaded documents in Valkey search index: {INDEX_NAME}\")\n",
    "db_size = await valkey_client.dbsize()\n",
    "print(f\"Total keys in database: {db_size}\")"
   ],
   "id": "91bb34d048100f2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 0 documents\n",
      "Indexed 100 documents\n",
      "Indexed 200 documents\n",
      "Indexed 300 documents\n",
      "Indexed 400 documents\n",
      "Indexed 500 documents\n",
      "Indexed 600 documents\n",
      "Indexed 700 documents\n",
      "Indexed 800 documents\n",
      "Indexed 900 documents\n",
      "Indexed 1000 documents\n",
      "Indexed 1100 documents\n",
      "Indexed 1200 documents\n",
      "Indexed 1300 documents\n",
      "Indexed 1400 documents\n",
      "Indexed 1500 documents\n",
      "Indexed 1600 documents\n",
      "Indexed 1700 documents\n",
      "Indexed 1800 documents\n",
      "Indexed 1900 documents\n",
      "Indexed 2000 documents\n",
      "Indexed 2100 documents\n",
      "Indexed 2200 documents\n",
      "Indexed 2300 documents\n",
      "Indexed 2400 documents\n",
      "Indexed 2500 documents\n",
      "Indexed 2600 documents\n",
      "Indexed 2700 documents\n",
      "Indexed 2800 documents\n",
      "Indexed 2900 documents\n",
      "Indexed 3000 documents\n",
      "Indexed 3100 documents\n",
      "Indexed 3200 documents\n",
      "Indexed 3300 documents\n",
      "Indexed 3400 documents\n",
      "Indexed 3500 documents\n",
      "Indexed 3600 documents\n",
      "Indexed 3700 documents\n",
      "Indexed 3800 documents\n",
      "Indexed 3900 documents\n",
      "Indexed 4000 documents\n",
      "Indexed 4100 documents\n",
      "Indexed 4200 documents\n",
      "Indexed 4300 documents\n",
      "Indexed 4400 documents\n",
      "Indexed 4500 documents\n",
      "Indexed 4600 documents\n",
      "Indexed 4700 documents\n",
      "Indexed 4800 documents\n",
      "Indexed 4900 documents\n",
      "Loaded documents in Valkey search index: valkey-embeddings-index\n",
      "Total keys in database: 5000\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vector Search Queries with OpenAI Embeddings\n",
    "\n",
    "Now that we have a search index and documents loaded into Valkey, we can run search queries. The following function runs vector similarity searches using OpenAI embeddings as queries."
   ],
   "id": "f0fa9dc82b0b566a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:58:01.719473Z",
     "start_time": "2026-01-05T20:58:01.694657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from glide_shared.commands.server_modules.ft_options.ft_search_options import (\n",
    "    FtSearchOptions,\n",
    "    ReturnField,\n",
    ")\n",
    "\n",
    "# Convert bytes or bytearray to a UTF-8 string if possible\n",
    "def _b2s(x: bytes | bytearray | str) -> str:\n",
    "    if isinstance(x, (bytes, bytearray)):\n",
    "        try:\n",
    "            return x.decode(\"utf-8\")\n",
    "        except Exception:\n",
    "            return str(x)\n",
    "    return x\n",
    "\n",
    "async def search_valkey(\n",
    "    user_query: str,\n",
    "    index_name: str = \"valkey-embeddings-index\",\n",
    "    vector_field: str = \"title_vector\",\n",
    "    hybrid_fields=\"*\",\n",
    "    k: int = 20,\n",
    "    print_results: bool = True,\n",
    ") -> List[dict]:\n",
    "    # Creates embedding vector from user query\n",
    "    response = client.embeddings.create(\n",
    "        input=user_query,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embedded_query = response.data[0].embedding\n",
    "    query_bytes = np.array(embedded_query).astype(dtype=np.float32).tobytes()\n",
    "\n",
    "    return_fields = [\n",
    "        ReturnField(\"$.title\", alias=\"title\"),\n",
    "        ReturnField(\"$.url\", alias=\"url\"),\n",
    "        ReturnField(\"$.text\", alias=\"text\"),\n",
    "        ReturnField(f\"vector_score\", alias=\"score\")\n",
    "    ]\n",
    "\n",
    "    # Prepare the search query\n",
    "    vector = \"query_vector\"\n",
    "    query = f'{hybrid_fields}=>[KNN {k} @{vector_field} ${vector} AS vector_score]'\n",
    "    query_options = FtSearchOptions(\n",
    "        params={vector: query_bytes},\n",
    "        return_fields=return_fields\n",
    "    )\n",
    "\n",
    "    # Perform vector search in Valkey\n",
    "    results = await ft.search(client=valkey_client, index_name=index_name, query=query, options=query_options)\n",
    "\n",
    "    parsed_results = []\n",
    "    if results[0] >= 1 and results[1]:\n",
    "        for key_bytes, fields in results[1].items():\n",
    "            doc = {\n",
    "                \"key\": _b2s(key_bytes),\n",
    "                \"title\": _b2s(fields.get(b\"title\", b\"\")),\n",
    "                \"url\": _b2s(fields.get(b\"url\", b\"\")),\n",
    "                \"text\": _b2s(fields.get(b\"text\", b\"\")),\n",
    "                \"score\": float(fields.get(b\"vector_score\", 0)) if fields.get(b\"vector_score\") else None\n",
    "            }\n",
    "            parsed_results.append(doc)\n",
    "\n",
    "            if print_results:\n",
    "                score_str = f\"(Score: {round(1-doc['score'], 3)})\" if doc['score'] else \"(No score)\"\n",
    "                print(f\"{doc['key']}: {doc['title']} {score_str}\")\n",
    "    else:\n",
    "        print(\"No results found\")\n",
    "\n",
    "    return parsed_results"
   ],
   "id": "de4d92ba1631d7fa",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:58:12.543487Z",
     "start_time": "2026-01-05T20:58:05.071378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search for articles about modern art in Europe\n",
    "results = await search_valkey('modern art in Europe', k=10)"
   ],
   "id": "d852a338ef22e637",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc:4462: Wolfgang Amadeus Mozart (Score: 0.022)\n",
      "doc:12372: Taylor Dayne (Score: 0.021)\n",
      "doc:4639: GNU General Public License (Score: 0.021)\n",
      "doc:13507: Lionel Richie (Score: 0.02)\n",
      "doc:10602: Lenny Kravitz (Score: 0.019)\n",
      "doc:4995: GNU (Score: 0.019)\n",
      "doc:10862: Grand Theft Auto: San Andreas (Score: 0.019)\n",
      "doc:13757: MP3 (Score: 0.018)\n",
      "doc:4708: Cessna (Score: 0.018)\n",
      "doc:14629: Jordan (Score: 0.018)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:13:05.105993Z",
     "start_time": "2026-01-05T21:13:03.491860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using content vectors for more detailed matching\n",
    "results = await search_valkey(\n",
    "    'modern art in Europe',\n",
    "    vector_field='content_vector', \n",
    "    k=10\n",
    ")"
   ],
   "id": "60451651ce01e9e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc:14502: Boeing 767 (Score: 0.036)\n",
      "doc:15095: Sublime (Score: 0.036)\n",
      "doc:14076: Eagles (band) (Score: 0.036)\n",
      "doc:12363: Duane Eddy (Score: 0.036)\n",
      "doc:14392: Charlie Christian (Score: 0.035)\n",
      "doc:10602: Lenny Kravitz (Score: 0.033)\n",
      "doc:4708: Cessna (Score: 0.032)\n",
      "doc:12461: Nat King Cole (Score: 0.032)\n",
      "doc:4714: Jazz (Score: 0.032)\n",
      "doc:7443: Elvis Presley (Score: 0.028)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hybrid Queries with Valkey\n",
    "\n",
    "The previous examples showed vector search queries with Valkey. In this section, we will show how to combine vector search with other fields for hybrid search. In the below example, we will combine vector search with full text search."
   ],
   "id": "82fa0748ccafa0f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:13:40.968193Z",
     "start_time": "2026-01-05T21:13:40.046064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_hybrid_field(field_name: str, value: str) -> str:\n",
    "    return f'@{field_name}:{{{value}}}'\n",
    "\n",
    "# Search for Scottish history articles with \"Scottish\" in the title\n",
    "results = await search_valkey(\n",
    "    \"modern art in Europe\",\n",
    "    vector_field=\"title_vector\",\n",
    "    k=5,\n",
    "    hybrid_fields=create_hybrid_field(\"title\", \"Jazz\")\n",
    ")"
   ],
   "id": "597c243a4a1149d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc:4714: Jazz (Score: 0.011)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## HNSW Index for Improved Performance\n",
    "\n",
    "So far we've used the FLAT (brute-force) index. Valkey also supports the HNSW (Hierarchical Navigable Small World) index, which provides faster approximate search for large datasets.\n",
    "\n",
    "HNSW takes longer to build and uses more memory than FLAT, but provides faster query performance, especially for large datasets.\n",
    "\n",
    "The following cells demonstrate creating and using an HNSW index in Valkey."
   ],
   "id": "e010b2eb85119b69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:14:03.848477Z",
     "start_time": "2026-01-05T21:14:03.809552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Redefine fields to use HNSW index\n",
    "hnsw_fields = [\n",
    "    TagField(\"$.title\", alias=\"title\"),\n",
    "    TagField(\"$.url\", alias=\"url\"),\n",
    "    TagField(\"$.text\", alias=\"text\"),\n",
    "    VectorField(\n",
    "        name=\"title_vector\",\n",
    "        algorithm=VectorAlgorithm.HNSW,\n",
    "        attributes=VectorFieldAttributesHnsw(\n",
    "            dimensions=VECTOR_DIM,\n",
    "            distance_metric=DISTANCE_METRIC,\n",
    "            type=VectorType.FLOAT32\n",
    "        )\n",
    "    ),\n",
    "    VectorField(\n",
    "        name=\"content_vector\",\n",
    "        algorithm=VectorAlgorithm.HNSW,\n",
    "        attributes=VectorFieldAttributesHnsw(\n",
    "            dimensions=VECTOR_DIM,\n",
    "            distance_metric=DISTANCE_METRIC,\n",
    "            type=VectorType.FLOAT32\n",
    "        )\n",
    "    )\n",
    "]\n",
    "print(\"HNSW index schema defined\")"
   ],
   "id": "cf449195890f8eba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW index schema defined\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:15:26.506108Z",
     "start_time": "2026-01-05T21:15:26.459555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def create_hnsw_index(index_name: str):\n",
    "    try:\n",
    "        if await has_index(index_name):\n",
    "            print(\"Index already exists\")\n",
    "            return\n",
    "        options = FtCreateOptions(DataType.JSON, prefixes=[PREFIX])\n",
    "        await ft.create(valkey_client, index_name, hnsw_fields, options)\n",
    "        print(f\"Created index: {index_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Create HNSW index\n",
    "HNSW_INDEX_NAME = INDEX_NAME + \"_HNSW\"\n",
    "await create_hnsw_index(HNSW_INDEX_NAME)"
   ],
   "id": "ae890dbf8daf71cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:15:01.402978Z",
     "start_time": "2026-01-05T21:14:16.698752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Index all documents in Valkey\n",
    "await index_documents(PREFIX, data.head(5000))\n",
    "info_result = await valkey_client.info()\n",
    "print(f\"Loaded documents in Valkey search index: {HNSW_INDEX_NAME}\")\n",
    "db_size = await valkey_client.dbsize()\n",
    "print(f\"Total keys in database: {db_size}\")"
   ],
   "id": "3cdc7d7b00c527d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 0 documents\n",
      "Indexed 100 documents\n",
      "Indexed 200 documents\n",
      "Indexed 300 documents\n",
      "Indexed 400 documents\n",
      "Indexed 500 documents\n",
      "Indexed 600 documents\n",
      "Indexed 700 documents\n",
      "Indexed 800 documents\n",
      "Indexed 900 documents\n",
      "Indexed 1000 documents\n",
      "Indexed 1100 documents\n",
      "Indexed 1200 documents\n",
      "Indexed 1300 documents\n",
      "Indexed 1400 documents\n",
      "Indexed 1500 documents\n",
      "Indexed 1600 documents\n",
      "Indexed 1700 documents\n",
      "Indexed 1800 documents\n",
      "Indexed 1900 documents\n",
      "Indexed 2000 documents\n",
      "Indexed 2100 documents\n",
      "Indexed 2200 documents\n",
      "Indexed 2300 documents\n",
      "Indexed 2400 documents\n",
      "Indexed 2500 documents\n",
      "Indexed 2600 documents\n",
      "Indexed 2700 documents\n",
      "Indexed 2800 documents\n",
      "Indexed 2900 documents\n",
      "Indexed 3000 documents\n",
      "Indexed 3100 documents\n",
      "Indexed 3200 documents\n",
      "Indexed 3300 documents\n",
      "Indexed 3400 documents\n",
      "Indexed 3500 documents\n",
      "Indexed 3600 documents\n",
      "Indexed 3700 documents\n",
      "Indexed 3800 documents\n",
      "Indexed 3900 documents\n",
      "Indexed 4000 documents\n",
      "Indexed 4100 documents\n",
      "Indexed 4200 documents\n",
      "Indexed 4300 documents\n",
      "Indexed 4400 documents\n",
      "Indexed 4500 documents\n",
      "Indexed 4600 documents\n",
      "Indexed 4700 documents\n",
      "Indexed 4800 documents\n",
      "Indexed 4900 documents\n",
      "Loaded documents in Valkey search index: valkey-embeddings-index_HNSW\n",
      "Total keys in database: 5000\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:15:08.452354Z",
     "start_time": "2026-01-05T21:15:07.214399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Test HNSW index performance\n",
    "results = await search_valkey(\n",
    "    'modern art in Europe',\n",
    "    index_name=HNSW_INDEX_NAME,\n",
    "    k=10\n",
    ")"
   ],
   "id": "6fd69aaa8b1f9d41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m2026-01-05T21:15:08.108359Z\u001B[0m \u001B[33m WARN\u001B[0m \u001B[2mlogger_core\u001B[0m\u001B[2m:\u001B[0m received error - Index: field `title_vector` not exists\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "Index: field `title_vector` not exists",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRequestError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Test HNSW index performance\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m results = \u001B[38;5;28;01mawait\u001B[39;00m search_valkey(\n\u001B[32m      3\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmodern art in Europe\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m      4\u001B[39m     index_name=HNSW_INDEX_NAME,\n\u001B[32m      5\u001B[39m     k=\u001B[32m10\u001B[39m\n\u001B[32m      6\u001B[39m )\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 47\u001B[39m, in \u001B[36msearch_valkey\u001B[39m\u001B[34m(user_query, index_name, vector_field, hybrid_fields, k, print_results)\u001B[39m\n\u001B[32m     41\u001B[39m query_options = FtSearchOptions(\n\u001B[32m     42\u001B[39m     params={vector: query_bytes},\n\u001B[32m     43\u001B[39m     return_fields=return_fields\n\u001B[32m     44\u001B[39m )\n\u001B[32m     46\u001B[39m \u001B[38;5;66;03m# Perform vector search in Valkey\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m results = \u001B[38;5;28;01mawait\u001B[39;00m ft.search(client=valkey_client, index_name=index_name, query=query, options=query_options)\n\u001B[32m     49\u001B[39m parsed_results = []\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m results[\u001B[32m0\u001B[39m] >= \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m results[\u001B[32m1\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workplace/openai/openai-cookbook/examples/vector_databases/valkey/.venv/lib/python3.13/site-packages/glide/async_commands/ft.py:159\u001B[39m, in \u001B[36msearch\u001B[39m\u001B[34m(client, index_name, query, options)\u001B[39m\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m options:\n\u001B[32m    158\u001B[39m     args.extend(options.to_args())\n\u001B[32m--> \u001B[39m\u001B[32m159\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(FtSearchResponse, \u001B[38;5;28;01mawait\u001B[39;00m client.custom_command(args))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workplace/openai/openai-cookbook/examples/vector_databases/valkey/.venv/lib/python3.13/site-packages/glide/async_commands/standalone_commands.py:51\u001B[39m, in \u001B[36mStandaloneCommands.custom_command\u001B[39m\u001B[34m(self, command_args)\u001B[39m\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcustom_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, command_args: List[TEncodable]) -> TResult:\n\u001B[32m     30\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[33;03m    Executes a single command, without checking inputs.\u001B[39;00m\n\u001B[32m     32\u001B[39m \u001B[33;03m    See the [Valkey GLIDE Wiki](https://github.com/valkey-io/valkey-glide/wiki/General-Concepts#custom-command)\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     49\u001B[39m \n\u001B[32m     50\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._execute_command(RequestType.CustomCommand, command_args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workplace/openai/openai-cookbook/examples/vector_databases/valkey/.venv/lib/python3.13/site-packages/glide/glide_client.py:440\u001B[39m, in \u001B[36mBaseClient._execute_command\u001B[39m\u001B[34m(self, request_type, args, route)\u001B[39m\n\u001B[32m    437\u001B[39m     request.root_span_ptr = span\n\u001B[32m    439\u001B[39m set_protobuf_route(request, route)\n\u001B[32m--> \u001B[39m\u001B[32m440\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._write_request_await_response(request)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workplace/openai/openai-cookbook/examples/vector_databases/valkey/.venv/lib/python3.13/site-packages/glide/glide_client.py:644\u001B[39m, in \u001B[36mBaseClient._write_request_await_response\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    642\u001B[39m response_future = \u001B[38;5;28mself\u001B[39m._get_future(request.callback_idx)\n\u001B[32m    643\u001B[39m \u001B[38;5;28mself\u001B[39m._create_write_task(request)\n\u001B[32m--> \u001B[39m\u001B[32m644\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m response_future\n\u001B[32m    645\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m response_future.result()\n",
      "\u001B[31mRequestError\u001B[39m: Index: field `title_vector` not exists"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use Valkey as a vector database with OpenAI embeddings. Key takeaways:\n",
    "\n",
    "1. **Valkey High Performance, Compatibility**: Valkey delivers fast, efficient in‑memory data handling and fully supports the Redis protocol, allowing it to function as a seamless drop‑in replacement for Redis while offering strong native performance.\n",
    "\n",
    "2. **Vector Search Capabilities**: Combined with Search module, Valkey provides powerful vector similarity search with support for multiple distance metrics.\n",
    "\n",
    "3. **Hybrid Search**: You can combine vector search with traditional text search for more precise results.\n",
    "\n",
    "4. **Performance Options**: Choose between FLAT (exact) and HNSW (approximate) indexes based on your accuracy and performance requirements.\n",
    "\n",
    "5. **Open Source**: As an openly developed project under the Linux Foundation, Valkey provides transparent governance and long‑term community‑driven stewardship.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Valkey Documentation](https://valkey.io/)\n",
    "- [Valkey Search Module Documentation](https://valkey.io/topics/search/)\n",
    "- [Valkey-Glide Documentation](https://github.com/valkey-io/valkey-glide/tree/main)\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)"
   ],
   "id": "5ab10ebe2b768282"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
